{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.externals import joblib\n",
    "from data_preprocessing import get_data_sets\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My two best methods are a random forest and model averaging of a set of neural nets. Here I compare their results, trying to get a sense for how they could possibly be combined to produce an even better method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "test_data, test_labels, valid_data, valid_labels, train_data, train_labels = get_data_sets(seed = 1234)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load('models/random_forest_1000_balanced_seed-1234.pkl') \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(valid_data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.argmax(preds, axis=1)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(valid_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ...,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong = np.argmax(valid_labels, axis=1)==classes\n",
    "wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     6,    12, ..., 99939, 99948, 99956])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_indices = np.where(~wrong)[0]\n",
    "wrong_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94722"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- len(wrong_indices)/len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded.\n"
     ]
    }
   ],
   "source": [
    "models_list = []\n",
    "for i in np.arange(10):\n",
    "    models_list.append(load_model('models/ground_cover_classifier_natural_deep_batch_size_100000_seed-1234_{}.h5'.format(i)))\n",
    "print('Models loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 2s 22us/step\n",
      "100000/100000 [==============================] - 1s 6us/step\n",
      "100000/100000 [==============================] - 0s 5us/step\n",
      "100000/100000 [==============================] - 0s 5us/step\n",
      "100000/100000 [==============================] - 0s 5us/step\n",
      "100000/100000 [==============================] - 0s 5us/step\n",
      "100000/100000 [==============================] - 0s 5us/step\n",
      "100000/100000 [==============================] - 0s 5us/step\n",
      "100000/100000 [==============================] - 0s 5us/step\n",
      "100000/100000 [==============================] - 0s 5us/step\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for i in np.arange(10):\n",
    "    pred_list.append(models_list[i].predict(valid_data, batch_size = 100000, verbose=1))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "avg_preds = pred_list[0]\n",
    "for i in np.arange(1,10):\n",
    "    avg_preds = avg_preds + pred_list[i]\n",
    "avg_preds = avg_preds/10\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_class = np.argmax(avg_preds, axis = 1)\n",
    "avg_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ...,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_nn = np.argmax(valid_labels, axis=1)==avg_class\n",
    "wrong_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,    14,    18, ..., 99929, 99939, 99956])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_nn_indices = np.where(~wrong_nn)[0]\n",
    "wrong_nn_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest got 5278 wrong.\n",
      "Model averaged neural net got 3712 wrong.\n",
      "The number that they both got wrong was 2619.\n"
     ]
    }
   ],
   "source": [
    "print('Random forest got {} wrong.'.format(len(wrong_indices)))\n",
    "print('Model averaged neural net got {} wrong.'.format(len(wrong_nn_indices)))\n",
    "print('The number that they both got wrong was {}.'.format(len(np.intersect1d(wrong_indices, wrong_nn_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.07797095e-01,   7.91988492e-01,   3.14677709e-06,\n",
       "         2.22000926e-05,   4.10419525e-05,   5.58351821e-05,\n",
       "         9.21781029e-05], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_preds_nn= avg_preds[wrong_nn_indices]\n",
    "wrong_preds_nn[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
