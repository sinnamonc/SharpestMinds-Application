{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from data_preprocessing import get_data_sets\n",
    "import numpy as np\n",
    "import time\n",
    "# import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "print('Imports Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to try out decision trees for our problem of ground cover classification.\n",
    "First, a basic tree with all default parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "test_data, test_labels, valid_data, valid_labels, train_data, train_labels = get_data_sets()\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 10.11 seconds.\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 93.11%\n",
      "Mean accuracy on testing set = 93.23%\n"
     ]
    }
   ],
   "source": [
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Even with something this fast and simple we acheived 93% accuracy. Let's see if we can knock the accuracy up a notch.\n",
    "Notice that we are overfitting a bit here since our training accuracy is 100% while our validation accuracy is only 93%. So we could afford to loosen up the tree structure here so that it generalizes a bit better. Let's experiment with the parameters in the decision tree, like max_depth, and min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 0.98 seconds.\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=1)\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training set = 63.41%\n",
      "Mean accuracy on validation set = 63.50%\n",
      "Mean accuracy on testing set = 63.05%\n"
     ]
    }
   ],
   "source": [
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of max_depth 1 constructed in 3.29 seconds.  \n",
      "Mean accuracy on training set = 63.42%  \n",
      "Mean accuracy on validation set = 63.10%\n",
      "Tree of max_depth 2 constructed in 5.21 seconds.  \n",
      "Mean accuracy on training set = 67.09%  \n",
      "Mean accuracy on validation set = 66.77%\n",
      "Tree of max_depth 3 constructed in 7.46 seconds.  \n",
      "Mean accuracy on training set = 67.59%  \n",
      "Mean accuracy on validation set = 67.36%\n",
      "Tree of max_depth 4 constructed in 9.47 seconds.  \n",
      "Mean accuracy on training set = 69.75%  \n",
      "Mean accuracy on validation set = 69.53%\n",
      "Tree of max_depth 5 constructed in 11.83 seconds.  \n",
      "Mean accuracy on training set = 69.59%  \n",
      "Mean accuracy on validation set = 69.29%\n",
      "Tree of max_depth 6 constructed in 13.45 seconds.  \n",
      "Mean accuracy on training set = 71.22%  \n",
      "Mean accuracy on validation set = 70.93%\n",
      "Tree of max_depth 7 constructed in 15.40 seconds.  \n",
      "Mean accuracy on training set = 72.21%  \n",
      "Mean accuracy on validation set = 71.94%\n",
      "Tree of max_depth 8 constructed in 17.14 seconds.  \n",
      "Mean accuracy on training set = 74.14%  \n",
      "Mean accuracy on validation set = 73.82%\n",
      "Tree of max_depth 9 constructed in 20.01 seconds.  \n",
      "Mean accuracy on training set = 76.43%  \n",
      "Mean accuracy on validation set = 76.00%\n",
      "Tree of max_depth 10 constructed in 19.51 seconds.  \n",
      "Mean accuracy on training set = 76.62%  \n",
      "Mean accuracy on validation set = 76.19%\n",
      "Tree of max_depth 11 constructed in 23.37 seconds.  \n",
      "Mean accuracy on training set = 78.42%  \n",
      "Mean accuracy on validation set = 77.89%\n",
      "Tree of max_depth 12 constructed in 23.52 seconds.  \n",
      "Mean accuracy on training set = 79.89%  \n",
      "Mean accuracy on validation set = 78.91%\n",
      "Tree of max_depth 13 constructed in 25.64 seconds.  \n",
      "Mean accuracy on training set = 83.03%  \n",
      "Mean accuracy on validation set = 81.75%\n",
      "Tree of max_depth 14 constructed in 27.21 seconds.  \n",
      "Mean accuracy on training set = 84.23%  \n",
      "Mean accuracy on validation set = 82.74%\n",
      "Tree of max_depth 15 constructed in 28.74 seconds.  \n",
      "Mean accuracy on training set = 86.09%  \n",
      "Mean accuracy on validation set = 84.30%\n",
      "Tree of max_depth 16 constructed in 29.94 seconds.  \n",
      "Mean accuracy on training set = 88.01%  \n",
      "Mean accuracy on validation set = 85.78%\n",
      "Tree of max_depth 17 constructed in 31.73 seconds.  \n",
      "Mean accuracy on training set = 89.53%  \n",
      "Mean accuracy on validation set = 86.71%\n",
      "Tree of max_depth 18 constructed in 32.45 seconds.  \n",
      "Mean accuracy on training set = 90.97%  \n",
      "Mean accuracy on validation set = 87.81%\n",
      "Tree of max_depth 19 constructed in 33.24 seconds.  \n",
      "Mean accuracy on training set = 92.61%  \n",
      "Mean accuracy on validation set = 89.04%\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for i in np.arange(1, 20):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    t = time.time()\n",
    "    clf = clf.fit(train_data, train_labels)\n",
    "    elapsed = time.time() - t\n",
    "    print('Tree of max_depth {} constructed in {:0.2f} seconds.'.format(i, elapsed), end=' ')\n",
    "    train_acc.append(clf.score(train_data, train_labels))\n",
    "    val_acc.append(clf.score(valid_data, valid_labels))\n",
    "    print('train_acc = {:0.2f}%'.format(train_acc[-1]*100), end=' ')\n",
    "    print('val_acc = {:0.2f}%'.format(val_acc[-1]*100))\n",
    "    if val_acc[-1]>best_val_acc:\n",
    "        best_max_depth = i\n",
    "        best_clf = clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEXCAYAAABcRGizAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npP8HdFkliJmhKtUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2899f7c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('max_depth')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 43.40 seconds.\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 93.01%\n",
      "Mean accuracy on testing set = 92.99%\n"
     ]
    }
   ],
   "source": [
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try out some random forests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 66.37 seconds.\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 62.48 seconds.\n",
      "Mean accuracy on training set = 99.50%\n",
      "Mean accuracy on validation set = 91.34%\n",
      "Mean accuracy on testing set = 91.50%\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier()\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 606.30 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 94.42%\n",
      "Mean accuracy on testing set = 94.38%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 100 trees works a little bit better, up to 94% accuracy.\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 32.20 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 94.45%\n",
      "Mean accuracy on testing set = 94.36%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 100 trees works a little bit better, up to 94% accuracy. \n",
    "# Q:How much faster is it with n_jobs = -1? \n",
    "# A: Way faster!    \n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 288.74 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 94.75%\n",
      "Mean accuracy on testing set = 94.65%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 1000 trees? A minor improvement, about .3%...\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=1000, n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/random_forest_1000_balanced.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'models/random_forest_1000_balanced.pkl')\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 305.55 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 94.68%\n",
      "Mean accuracy on testing set = 94.62%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 5000 trees? No improvement\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=1000, n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 35.83 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 94.58%\n",
      "Mean accuracy on testing set = 94.59%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 100 trees using entropy instead of gini - slight improvement\n",
    "  \n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 133.24 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 96.36%\n",
      "Mean accuracy on testing set = 96.35%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 100 trees using entropy instead of gini and max_features=None\n",
    "  \n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100, criterion='entropy', max_features=None,\n",
    "                                      n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 1290.47 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 96.53%\n",
      "Mean accuracy on testing set = 96.50%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 1000 trees using entropy instead of gini and max_features=None - another .18%\n",
    "  \n",
    "clf = ensemble.RandomForestClassifier(n_estimators=1000, criterion='entropy', max_features=None,\n",
    "                                      n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 119.22 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 95.95%\n",
      "Mean accuracy on testing set = 95.93%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 100 trees using gini and max_features=None - not better than entropy\n",
    "  \n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100, criterion='gini', max_features=None,\n",
    "                                      n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(valid_data, valid_labels)*100))\n",
    "print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(test_data, test_labels)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try adding some new features to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This should really be vectorized\n",
    "def add_features(dat):\n",
    "    ind=np.array(np.append(np.arange(1,10), [0]))\n",
    "    feats = dat[:10]\n",
    "    new_feats = []\n",
    "    for _ in np.arange(10):\n",
    "        new_feats.extend(np.multiply(feats, feats[ind]))\n",
    "        ind = ind[ind]\n",
    "    return new_feats\n",
    "# print(add_features(np.array([1,2,3,4,5,6,7,8,9,9,9,9,9])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.arange(9, -1, -1)\n",
    "# print(a)\n",
    "a = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "len(add_features(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "extended_train_data = []\n",
    "for dat in train_data:\n",
    "    extended_train_data.append(add_features(dat))\n",
    "extended_train_data = np.array(extended_train_data)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "extended_valid_data = []\n",
    "for dat in valid_data:\n",
    "    extended_valid_data.append(add_features(dat))\n",
    "extended_valid_data = np.array(extended_valid_data)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 669.81 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 92.37%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 100 trees trained on the extended training set!\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(extended_train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(extended_train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(extended_valid_data, valid_labels)*100))\n",
    "#  Adding all products doesn't seem to help. In fact, it's a bit worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# What if we apply PCA first?\n",
    "PCA = decomposition.PCA(n_components=30)\n",
    "reduced_train_data = PCA.fit_transform(train_data)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree constructed in 434.76 seconds.\n",
      "Mean accuracy on training set = 100.00%\n",
      "Mean accuracy on validation set = 93.97%\n"
     ]
    }
   ],
   "source": [
    "# A random forest with 100 trees and reduced training data\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight=\"balanced\")\n",
    "t = time.time()\n",
    "clf = clf.fit(reduced_train_data, train_labels)\n",
    "elapsed = time.time() - t\n",
    "print('Tree constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(clf.score(reduced_train_data, train_labels)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(clf.score(PCA.transform(valid_data), valid_labels)*100))\n",
    "# print('Mean accuracy on testing set = {:0.2f}%'.format(clf.score(PCA.transform(test_data), test_labels)*100))\n",
    "# Doesn't help, need a way to reduce the overfitting a bit? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      563542.4792            9.46m\n",
      "         2      508997.0991            8.88m\n",
      "         3      467136.7308            8.65m\n",
      "         4      433791.1797            8.51m\n",
      "         5      406595.8590            8.38m\n",
      "         6      384172.4962            8.29m\n",
      "         7      365321.4034            8.14m\n",
      "         8      349335.5655            8.01m\n",
      "         9      335750.7403            7.96m\n",
      "        10      324002.5375            7.88m\n",
      "        20      261629.7138            6.89m\n",
      "        30      237821.3670            5.94m\n",
      "        40      225390.8112            5.03m\n",
      "        50      217968.8370            4.13m\n",
      "        60      212059.2071            3.26m\n",
      "        70      207642.8291            2.42m\n",
      "        80      203756.3191            1.60m\n",
      "        90      200786.2447           47.74s\n",
      "       100      198068.2708            0.00s\n",
      "GBC constructed in 476.52 seconds.\n",
      "Mean accuracy on training set = 77.50%\n",
      "Mean accuracy on validation set = 77.34%\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier(n_estimators=100, verbose=1)\n",
    "t = time.time()\n",
    "train_labels_num = np.argmax(train_labels, axis=1)\n",
    "gbc.fit(train_data,train_labels_num)\n",
    "elapsed = time.time() - t\n",
    "print('GBC constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(gbc.score(train_data, train_labels_num)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(gbc.score(valid_data, np.argmax(valid_labels, axis=1))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      540807.4149          172.23m\n",
      "         2      472165.3968          172.38m\n",
      "         3      420940.9257          171.11m\n",
      "         4      380271.8236          170.46m\n",
      "         5      347200.7551          169.11m\n",
      "         6      319124.8231          168.26m\n",
      "         7      295733.1317          167.37m\n",
      "         8      276538.9233          165.57m\n",
      "         9      259813.2405          164.32m\n",
      "        10      245533.1722          162.65m\n",
      "        20      166780.8228          146.67m\n",
      "        30      136020.1724          127.19m\n",
      "        40      119399.8068          107.60m\n",
      "        50      107252.1182           88.83m\n",
      "        60       99236.5864           69.81m\n",
      "        70       92848.1058           51.35m\n",
      "        80       86303.5140           33.84m\n",
      "        90       80453.2463           16.78m\n",
      "       100       75795.2570            0.00s\n",
      "GBC constructed in 10014.71 seconds.\n",
      "Mean accuracy on training set = 93.56%\n",
      "Mean accuracy on validation set = 91.43%\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier(n_estimators=100, verbose=1, max_depth=8)\n",
    "t = time.time()\n",
    "train_labels_num = np.argmax(train_labels, axis=1)\n",
    "gbc.fit(train_data, train_labels_num)\n",
    "elapsed = time.time() - t\n",
    "print('GBC constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(gbc.score(train_data, train_labels_num)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(gbc.score(valid_data, np.argmax(valid_labels, axis=1))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      530259.7625          351.51m\n",
      "         2      456507.4796          361.19m\n",
      "         3      401027.1144          366.97m\n",
      "         4      356809.3868          370.84m\n",
      "         5      321015.9635          372.60m\n",
      "         6      290996.6464          373.51m\n",
      "         7      265734.1014          374.79m\n",
      "         8      244479.4435          377.32m\n",
      "         9      226349.4404          380.08m\n",
      "        10      210521.4514          381.00m\n",
      "        20      125229.3486          382.07m\n",
      "        30       95713.3282          370.54m\n",
      "        40       80188.6859          355.48m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5d9f9bc4a163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_labels_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GBC constructed in {:0.2f} seconds.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier(n_estimators=500, verbose=1, max_depth=10)\n",
    "t = time.time()\n",
    "train_labels_num = np.argmax(train_labels, axis=1)\n",
    "gbc.fit(train_data, train_labels_num)\n",
    "elapsed = time.time() - t\n",
    "print('GBC constructed in {:0.2f} seconds.'.format(elapsed))\n",
    "print('Mean accuracy on training set = {:0.2f}%'.format(gbc.score(train_data, train_labels_num)*100))\n",
    "print('Mean accuracy on validation set = {:0.2f}%'.format(gbc.score(valid_data, np.argmax(valid_labels, axis=1))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd like to try some data augmentation to try to pump up this accuracy. \n",
    "Data description:\n",
    "Name                                     Data Type    Measurement                       Description\n",
    "\n",
    "Elevation                               quantitative    meters                       Elevation in meters\n",
    "Aspect                                  quantitative    azimuth                      Aspect in degrees azimuth\n",
    "Slope                                   quantitative    degrees                      Slope in degrees\n",
    "Horizontal_Distance_To_Hydrology        quantitative    meters                       Horz Dist to nearest surface water features\n",
    "Vertical_Distance_To_Hydrology          quantitative    meters                       Vert Dist to nearest surface water features\n",
    "Horizontal_Distance_To_Roadways         quantitative    meters                       Horz Dist to nearest roadway\n",
    "Hillshade_9am                           quantitative    0 to 255 index               Hillshade index at 9am, summer solstice\n",
    "Hillshade_Noon                          quantitative    0 to 255 index               Hillshade index at noon, summer soltice\n",
    "Hillshade_3pm                           quantitative    0 to 255 index               Hillshade index at 3pm, summer solstice\n",
    "Horizontal_Distance_To_Fire_Points      quantitative    meters                       Horz Dist to nearest wildfire ignition points\n",
    "Wilderness_Area (4 binary columns)      qualitative     0 (absence) or 1 (presence)  Wilderness area designation\n",
    "Soil_Type (40 binary columns)           qualitative     0 (absence) or 1 (presence)  Soil Type designation\n",
    "\n",
    "So the first 10 fields should be good places to add some noise to the training data. I'll try to add some Gaussian noise to these fields and see how that impacts performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "augmented_train_data = []\n",
    "\n",
    "for k in np.arange(1, 8):\n",
    "    print(k)\n",
    "    inds = np.where(train_data[:, -1]==k)\n",
    "    scale = np.var(train_data[inds, :10]\n",
    "    for dat in train_data[inds]:\n",
    "        for _ in np.arange(1):\n",
    "            g = np.random.normal(loc = 0.0, scale = np.var(train_data[inds, :10], axis=0))\n",
    "            g = np.pad(g,pad_width=[0,44], mode = 'constant')\n",
    "            augmented_train_data.extend(dat+g)\n",
    "augmented_train_data.extend(train_data)\n",
    "augmented_train_data = np.array(augmented_train_data)\n",
    "print(len(train_data))                                                                     \n",
    "print(len(augmented_train_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
