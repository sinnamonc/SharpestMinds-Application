{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.initializers\n",
    "import keras.callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from data_preprocessing import import_data\n",
    "from utils import shuffle_in_unison\n",
    "from utils import percent_correct\n",
    "from utils import get_uniform_batch\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the data as a dataframe\n",
    "df = import_data()\n",
    "# print('Dataframe shape:',df.shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create test, validation, and training sets\n",
    "test_df = pd.DataFrame()\n",
    "valid_df = pd.DataFrame()\n",
    "train_df = pd.DataFrame()\n",
    "\n",
    "# take about 80% of the data for the training and validation sets\n",
    "train_df_size_per_index = 370000 # about 64% of the data\n",
    "valid_df_size_per_index = 100000 # about 16% of the data\n",
    "\n",
    "#Shuffle the dataframe df\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Put the first test_df_size into the test set\n",
    "train_df = df[:train_df_size_per_index]\n",
    "# Put the next valid_df_size into the validation set\n",
    "valid_df = df[train_df_size_per_index:train_df_size_per_index+valid_df_size_per_index]\n",
    "# Put the remainder into the training set\n",
    "test_df = df[train_df_size_per_index+valid_df_size_per_index:]\n",
    "\n",
    "# Extract the last columns, which corresponds to the labels\n",
    "test_labels = test_df.iloc[:,-1]\n",
    "valid_labels = valid_df.iloc[:,-1]\n",
    "train_labels = train_df.iloc[:,-1]\n",
    "\n",
    "# Remove the last columns, which corresponds to the labels\n",
    "test_df = test_df.drop(test_df.columns[-1],axis=1)\n",
    "valid_df = valid_df.drop(valid_df.columns[-1],axis=1)\n",
    "train_df = train_df.drop(train_df.columns[-1],axis=1)\n",
    "\n",
    "# Convert data from dataframes to np.arrays\n",
    "test_data = test_df.values\n",
    "valid_data = valid_df.values\n",
    "train_data = train_df.values\n",
    "test_labels = test_labels.values\n",
    "valid_labels = valid_labels.values\n",
    "train_labels = train_labels.values\n",
    "\n",
    "# Convert labels to one hot vectors\n",
    "test_labels = to_categorical(test_labels-1,7)\n",
    "valid_labels = to_categorical(valid_labels-1,7)\n",
    "train_labels = to_categorical(train_labels-1,7)\n",
    "\n",
    "# Shuffle the data and labels\n",
    "shuffle_in_unison(test_data, test_labels)\n",
    "shuffle_in_unison(valid_data, valid_labels)\n",
    "shuffle_in_unison(train_data, train_labels)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-8f306050411f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Delete existing model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model5' is not defined"
     ]
    }
   ],
   "source": [
    "# Delete existing model\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Build the model - this model acheived a validation loss of about 0.17 after about 600 epochs\n",
    "# print('Build model...')\n",
    "# model = Sequential()\n",
    "# model.add(Dense(240, activation='relu', input_dim=54))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(120, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(60, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# optimizer = RMSprop(lr=0.05)\n",
    "# # model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Build the model - this model acheived a validation loss of about 0.12 after about 250 epochs\n",
    "# print('Build model...')\n",
    "# model = Sequential()\n",
    "# model.add(Dense(500, activation='relu', input_dim=54))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(250, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(120, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(60, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# optimizer = RMSprop(lr=0.05)\n",
    "# # model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Build the model - validation loss of 0.12 (hits 0.1199 at some point) after 250 epochs, but should probably \n",
    "# stop a good bit sooner by \n",
    "# the look of the plot. Maybe averaging a bunch of these together will give some improvement. Also, look into\n",
    "# parameter optimization.\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=54))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "# model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "              kernel_initializer = keras.initializers.lecun_normal(seed = 451761), metrics=[\"accuracy\"])\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "num_epochs_trained = 0\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "print('Complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 370000 samples, validate on 100000 samples\n",
      "Epoch 1/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.4281 - acc: 0.8243 - val_loss: 0.4449 - val_acc: 0.8133\n",
      "Epoch 2/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.3636 - acc: 0.8512 - val_loss: 0.3428 - val_acc: 0.8593\n",
      "Epoch 3/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.3147 - acc: 0.8705 - val_loss: 0.3129 - val_acc: 0.8706\n",
      "Epoch 4/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2870 - acc: 0.8826 - val_loss: 0.2960 - val_acc: 0.8791\n",
      "Epoch 5/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2638 - acc: 0.8920 - val_loss: 0.2627 - val_acc: 0.8934\n",
      "Epoch 6/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2458 - acc: 0.8995 - val_loss: 0.2598 - val_acc: 0.8965\n",
      "Epoch 7/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2341 - acc: 0.9044 - val_loss: 0.2457 - val_acc: 0.8990\n",
      "Epoch 8/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2232 - acc: 0.9093 - val_loss: 0.2494 - val_acc: 0.8990\n",
      "Epoch 9/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2137 - acc: 0.9132 - val_loss: 0.2340 - val_acc: 0.9043\n",
      "Epoch 10/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2058 - acc: 0.9161 - val_loss: 0.2240 - val_acc: 0.9083\n",
      "Epoch 11/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1986 - acc: 0.9194 - val_loss: 0.2112 - val_acc: 0.9142\n",
      "Epoch 12/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1928 - acc: 0.9217 - val_loss: 0.2037 - val_acc: 0.9194\n",
      "Epoch 13/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1861 - acc: 0.9245 - val_loss: 0.1978 - val_acc: 0.9195\n",
      "Epoch 14/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1811 - acc: 0.9263 - val_loss: 0.1931 - val_acc: 0.9228\n",
      "Epoch 15/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1762 - acc: 0.9284 - val_loss: 0.2071 - val_acc: 0.9175\n",
      "Epoch 16/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1729 - acc: 0.9300 - val_loss: 0.1936 - val_acc: 0.9219\n",
      "Epoch 17/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1691 - acc: 0.9310 - val_loss: 0.1882 - val_acc: 0.9245\n",
      "Epoch 18/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1651 - acc: 0.9333 - val_loss: 0.1852 - val_acc: 0.9254\n",
      "Epoch 19/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1608 - acc: 0.9347 - val_loss: 0.1794 - val_acc: 0.9281\n",
      "Epoch 20/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1588 - acc: 0.9357 - val_loss: 0.1765 - val_acc: 0.9291\n",
      "Epoch 21/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1564 - acc: 0.9369 - val_loss: 0.1745 - val_acc: 0.9308\n",
      "Epoch 22/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1523 - acc: 0.9383 - val_loss: 0.1662 - val_acc: 0.9328\n",
      "Epoch 23/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1504 - acc: 0.9394 - val_loss: 0.1722 - val_acc: 0.9304\n",
      "Epoch 24/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1476 - acc: 0.9399 - val_loss: 0.1737 - val_acc: 0.9306\n",
      "Epoch 25/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1447 - acc: 0.9416 - val_loss: 0.1765 - val_acc: 0.9284\n",
      "Epoch 26/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1427 - acc: 0.9422 - val_loss: 0.1659 - val_acc: 0.9340\n",
      "Epoch 27/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1411 - acc: 0.9429 - val_loss: 0.1640 - val_acc: 0.9352\n",
      "Epoch 28/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1384 - acc: 0.9439 - val_loss: 0.1594 - val_acc: 0.9369\n",
      "Epoch 29/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1373 - acc: 0.9446 - val_loss: 0.1699 - val_acc: 0.9333\n",
      "Epoch 30/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1353 - acc: 0.9451 - val_loss: 0.1674 - val_acc: 0.9348\n",
      "Epoch 31/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1343 - acc: 0.9457 - val_loss: 0.1578 - val_acc: 0.9374\n",
      "Epoch 32/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1316 - acc: 0.9466 - val_loss: 0.1505 - val_acc: 0.9404\n",
      "Epoch 33/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1297 - acc: 0.9476 - val_loss: 0.1552 - val_acc: 0.9387\n",
      "Epoch 34/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1282 - acc: 0.9482 - val_loss: 0.1515 - val_acc: 0.9408\n",
      "Epoch 35/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1265 - acc: 0.9489 - val_loss: 0.1507 - val_acc: 0.9405\n",
      "Epoch 36/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1259 - acc: 0.9490 - val_loss: 0.1641 - val_acc: 0.9349\n",
      "Epoch 37/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1246 - acc: 0.9493 - val_loss: 0.1490 - val_acc: 0.9415\n",
      "Epoch 38/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1226 - acc: 0.9506 - val_loss: 0.1533 - val_acc: 0.9411\n",
      "Epoch 39/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1221 - acc: 0.9507 - val_loss: 0.1659 - val_acc: 0.9365\n",
      "Epoch 40/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1202 - acc: 0.9514 - val_loss: 0.1487 - val_acc: 0.9420\n",
      "Epoch 41/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1189 - acc: 0.9519 - val_loss: 0.1622 - val_acc: 0.9370\n",
      "Epoch 42/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1193 - acc: 0.9519 - val_loss: 0.1437 - val_acc: 0.9442\n",
      "Epoch 43/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1157 - acc: 0.9533 - val_loss: 0.1418 - val_acc: 0.9452\n",
      "Epoch 44/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1155 - acc: 0.9530 - val_loss: 0.1443 - val_acc: 0.9433\n",
      "Epoch 45/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1142 - acc: 0.9538 - val_loss: 0.1450 - val_acc: 0.9448\n",
      "Epoch 46/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1145 - acc: 0.9539 - val_loss: 0.1529 - val_acc: 0.9412\n",
      "Epoch 47/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1124 - acc: 0.9547 - val_loss: 0.1400 - val_acc: 0.9455\n",
      "Epoch 48/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1114 - acc: 0.9549 - val_loss: 0.1437 - val_acc: 0.9444\n",
      "Epoch 49/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1099 - acc: 0.9554 - val_loss: 0.1438 - val_acc: 0.9440\n",
      "Epoch 50/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1099 - acc: 0.9551 - val_loss: 0.1405 - val_acc: 0.9464\n",
      "Epoch 51/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1089 - acc: 0.9558 - val_loss: 0.1433 - val_acc: 0.9442\n",
      "Epoch 52/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1084 - acc: 0.9559 - val_loss: 0.1428 - val_acc: 0.9440\n",
      "Epoch 53/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1071 - acc: 0.9567 - val_loss: 0.1372 - val_acc: 0.9481\n",
      "Epoch 54/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1050 - acc: 0.9575 - val_loss: 0.1345 - val_acc: 0.9488\n",
      "Epoch 55/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1043 - acc: 0.9578 - val_loss: 0.1363 - val_acc: 0.9473\n",
      "Epoch 56/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1049 - acc: 0.9576 - val_loss: 0.1474 - val_acc: 0.9428\n",
      "Epoch 57/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1036 - acc: 0.9580 - val_loss: 0.1446 - val_acc: 0.9447\n",
      "Epoch 58/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1031 - acc: 0.9581 - val_loss: 0.1335 - val_acc: 0.9481\n",
      "Epoch 59/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1024 - acc: 0.9585 - val_loss: 0.1342 - val_acc: 0.9485\n",
      "Epoch 60/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1024 - acc: 0.9583 - val_loss: 0.1354 - val_acc: 0.9479\n",
      "Epoch 61/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1002 - acc: 0.9597 - val_loss: 0.1341 - val_acc: 0.9485\n",
      "Epoch 62/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0993 - acc: 0.9600 - val_loss: 0.1356 - val_acc: 0.9481\n",
      "Epoch 63/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0992 - acc: 0.9599 - val_loss: 0.1362 - val_acc: 0.9474\n",
      "Epoch 64/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0989 - acc: 0.9598 - val_loss: 0.1427 - val_acc: 0.9461\n",
      "Epoch 65/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0990 - acc: 0.9596 - val_loss: 0.1376 - val_acc: 0.9472\n",
      "Epoch 66/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0970 - acc: 0.9608 - val_loss: 0.1374 - val_acc: 0.9474\n",
      "Epoch 67/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0965 - acc: 0.9609 - val_loss: 0.1328 - val_acc: 0.9502\n",
      "Epoch 68/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0968 - acc: 0.9608 - val_loss: 0.1294 - val_acc: 0.9501\n",
      "Epoch 69/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0957 - acc: 0.9613 - val_loss: 0.1293 - val_acc: 0.9508\n",
      "Epoch 70/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0950 - acc: 0.9614 - val_loss: 0.1364 - val_acc: 0.9479\n",
      "Epoch 71/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0942 - acc: 0.9619 - val_loss: 0.1304 - val_acc: 0.9504\n",
      "Epoch 72/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0945 - acc: 0.9618 - val_loss: 0.1347 - val_acc: 0.9489\n",
      "Epoch 73/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0935 - acc: 0.9618 - val_loss: 0.1302 - val_acc: 0.9498\n",
      "Epoch 74/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0919 - acc: 0.9627 - val_loss: 0.1368 - val_acc: 0.9487\n",
      "Epoch 75/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0920 - acc: 0.9625 - val_loss: 0.1373 - val_acc: 0.9483\n",
      "Epoch 76/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0923 - acc: 0.9625 - val_loss: 0.1317 - val_acc: 0.9496\n",
      "Epoch 77/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0902 - acc: 0.9638 - val_loss: 0.1292 - val_acc: 0.9518\n",
      "Epoch 78/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0910 - acc: 0.9631 - val_loss: 0.1366 - val_acc: 0.9481\n",
      "Epoch 79/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0905 - acc: 0.9634 - val_loss: 0.1300 - val_acc: 0.9516\n",
      "Epoch 80/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0897 - acc: 0.9634 - val_loss: 0.1308 - val_acc: 0.9508\n",
      "Epoch 81/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0892 - acc: 0.9642 - val_loss: 0.1292 - val_acc: 0.9514\n",
      "Epoch 82/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0880 - acc: 0.9642 - val_loss: 0.1283 - val_acc: 0.9522\n",
      "Epoch 83/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0883 - acc: 0.9645 - val_loss: 0.1215 - val_acc: 0.9552\n",
      "Epoch 84/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0875 - acc: 0.9647 - val_loss: 0.1318 - val_acc: 0.9506\n",
      "Epoch 85/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0867 - acc: 0.9651 - val_loss: 0.1319 - val_acc: 0.9511\n",
      "Epoch 86/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0860 - acc: 0.9651 - val_loss: 0.1340 - val_acc: 0.9509\n",
      "Epoch 87/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0867 - acc: 0.9648 - val_loss: 0.1263 - val_acc: 0.9534\n",
      "Epoch 88/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0857 - acc: 0.9654 - val_loss: 0.1249 - val_acc: 0.9533\n",
      "Epoch 89/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0856 - acc: 0.9656 - val_loss: 0.1228 - val_acc: 0.9546\n",
      "Epoch 90/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0852 - acc: 0.9654 - val_loss: 0.1239 - val_acc: 0.9537\n",
      "Epoch 91/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0846 - acc: 0.9657 - val_loss: 0.1250 - val_acc: 0.9536\n",
      "Epoch 92/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0836 - acc: 0.9662 - val_loss: 0.1267 - val_acc: 0.9536\n",
      "Epoch 93/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0838 - acc: 0.9662 - val_loss: 0.1275 - val_acc: 0.9529\n",
      "Epoch 94/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0827 - acc: 0.9667 - val_loss: 0.1334 - val_acc: 0.9500\n",
      "Epoch 95/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0836 - acc: 0.9661 - val_loss: 0.1305 - val_acc: 0.9515\n",
      "Epoch 96/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0833 - acc: 0.9662 - val_loss: 0.1205 - val_acc: 0.9553\n",
      "Epoch 97/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0814 - acc: 0.9668 - val_loss: 0.1217 - val_acc: 0.9550\n",
      "Epoch 98/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0812 - acc: 0.9670 - val_loss: 0.1262 - val_acc: 0.9538\n",
      "Epoch 99/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0820 - acc: 0.9671 - val_loss: 0.1433 - val_acc: 0.9481\n",
      "Epoch 100/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0815 - acc: 0.9671 - val_loss: 0.1319 - val_acc: 0.9519\n",
      "Epoch 101/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0804 - acc: 0.9675 - val_loss: 0.1209 - val_acc: 0.9556\n",
      "Epoch 102/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0806 - acc: 0.9675 - val_loss: 0.1224 - val_acc: 0.9552\n",
      "Epoch 103/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0797 - acc: 0.9678 - val_loss: 0.1234 - val_acc: 0.9547\n",
      "Epoch 104/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0789 - acc: 0.9679 - val_loss: 0.1291 - val_acc: 0.9526\n",
      "Epoch 105/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0800 - acc: 0.9676 - val_loss: 0.1262 - val_acc: 0.9531\n",
      "Epoch 106/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0790 - acc: 0.9681 - val_loss: 0.1243 - val_acc: 0.9544\n",
      "Epoch 107/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0783 - acc: 0.9682 - val_loss: 0.1228 - val_acc: 0.9559\n",
      "Epoch 108/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0787 - acc: 0.9683 - val_loss: 0.1255 - val_acc: 0.9542\n",
      "Epoch 109/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0776 - acc: 0.9684 - val_loss: 0.1248 - val_acc: 0.9534\n",
      "Epoch 110/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0779 - acc: 0.9687 - val_loss: 0.1228 - val_acc: 0.9550\n",
      "Epoch 111/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0778 - acc: 0.9684 - val_loss: 0.1220 - val_acc: 0.9551\n",
      "Epoch 112/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0761 - acc: 0.9691 - val_loss: 0.1286 - val_acc: 0.9533\n",
      "Epoch 113/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0765 - acc: 0.9690 - val_loss: 0.1248 - val_acc: 0.9544\n",
      "Epoch 114/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0761 - acc: 0.9691 - val_loss: 0.1351 - val_acc: 0.9517\n",
      "Epoch 115/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0771 - acc: 0.9690 - val_loss: 0.1206 - val_acc: 0.9564\n",
      "Epoch 116/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0758 - acc: 0.9690 - val_loss: 0.1238 - val_acc: 0.9552\n",
      "Epoch 117/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0753 - acc: 0.9696 - val_loss: 0.1211 - val_acc: 0.9562\n",
      "Epoch 118/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0754 - acc: 0.9695 - val_loss: 0.1175 - val_acc: 0.9576\n",
      "Epoch 119/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0744 - acc: 0.9700 - val_loss: 0.1212 - val_acc: 0.9557\n",
      "Epoch 120/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0757 - acc: 0.9694 - val_loss: 0.1216 - val_acc: 0.9554\n",
      "Epoch 121/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0748 - acc: 0.9697 - val_loss: 0.1312 - val_acc: 0.9518\n",
      "Epoch 122/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0739 - acc: 0.9702 - val_loss: 0.1243 - val_acc: 0.9548\n",
      "Epoch 123/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0747 - acc: 0.9696 - val_loss: 0.1258 - val_acc: 0.9548\n",
      "Epoch 124/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0736 - acc: 0.9705 - val_loss: 0.1190 - val_acc: 0.9577\n",
      "Epoch 125/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0737 - acc: 0.9702 - val_loss: 0.1211 - val_acc: 0.9569\n",
      "Epoch 126/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0730 - acc: 0.9704 - val_loss: 0.1253 - val_acc: 0.9553\n",
      "Epoch 127/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0722 - acc: 0.9711 - val_loss: 0.1208 - val_acc: 0.9567\n",
      "Epoch 128/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0715 - acc: 0.9713 - val_loss: 0.1200 - val_acc: 0.9566\n",
      "Epoch 129/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0731 - acc: 0.9706 - val_loss: 0.1230 - val_acc: 0.9555\n",
      "Epoch 130/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0721 - acc: 0.9709 - val_loss: 0.1210 - val_acc: 0.9562\n",
      "Epoch 131/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0724 - acc: 0.9706 - val_loss: 0.1256 - val_acc: 0.9551\n",
      "Epoch 132/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0712 - acc: 0.9714 - val_loss: 0.1222 - val_acc: 0.9562\n",
      "Epoch 133/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0706 - acc: 0.9717 - val_loss: 0.1224 - val_acc: 0.9560\n",
      "Epoch 134/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0718 - acc: 0.9708 - val_loss: 0.1207 - val_acc: 0.9572\n",
      "Epoch 135/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0704 - acc: 0.9713 - val_loss: 0.1201 - val_acc: 0.9570\n",
      "Epoch 136/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0700 - acc: 0.9716 - val_loss: 0.1202 - val_acc: 0.9564\n",
      "Epoch 137/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0710 - acc: 0.9712 - val_loss: 0.1185 - val_acc: 0.9584\n",
      "Epoch 138/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0697 - acc: 0.9719 - val_loss: 0.1259 - val_acc: 0.9549\n",
      "Epoch 139/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0696 - acc: 0.9720 - val_loss: 0.1253 - val_acc: 0.9554\n",
      "Epoch 140/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0702 - acc: 0.9717 - val_loss: 0.1225 - val_acc: 0.9571\n",
      "Epoch 141/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0691 - acc: 0.9718 - val_loss: 0.1205 - val_acc: 0.9575\n",
      "Epoch 142/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0694 - acc: 0.9719 - val_loss: 0.1192 - val_acc: 0.9571\n",
      "Epoch 143/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0694 - acc: 0.9720 - val_loss: 0.1274 - val_acc: 0.9552\n",
      "Epoch 144/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0696 - acc: 0.9721 - val_loss: 0.1178 - val_acc: 0.9583\n",
      "Epoch 145/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0685 - acc: 0.9725 - val_loss: 0.1240 - val_acc: 0.9562\n",
      "Epoch 146/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0701 - acc: 0.9718 - val_loss: 0.1232 - val_acc: 0.9565\n",
      "Epoch 147/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0673 - acc: 0.9728 - val_loss: 0.1185 - val_acc: 0.9585\n",
      "Epoch 148/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0680 - acc: 0.9728 - val_loss: 0.1247 - val_acc: 0.9558\n",
      "Epoch 149/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0684 - acc: 0.9722 - val_loss: 0.1237 - val_acc: 0.9565\n",
      "Epoch 150/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0673 - acc: 0.9731 - val_loss: 0.1154 - val_acc: 0.9590\n",
      "Epoch 151/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0668 - acc: 0.9731 - val_loss: 0.1215 - val_acc: 0.9571\n",
      "Epoch 152/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0675 - acc: 0.9727 - val_loss: 0.1282 - val_acc: 0.9559\n",
      "Epoch 153/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0666 - acc: 0.9730 - val_loss: 0.1209 - val_acc: 0.9573\n",
      "Epoch 154/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0665 - acc: 0.9734 - val_loss: 0.1195 - val_acc: 0.9580\n",
      "Epoch 155/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0674 - acc: 0.9729 - val_loss: 0.1203 - val_acc: 0.9572\n",
      "Epoch 156/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0659 - acc: 0.9735 - val_loss: 0.1181 - val_acc: 0.9584\n",
      "Epoch 157/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0657 - acc: 0.9737 - val_loss: 0.1211 - val_acc: 0.9571\n",
      "Epoch 158/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0662 - acc: 0.9734 - val_loss: 0.1208 - val_acc: 0.9576\n",
      "Epoch 159/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0659 - acc: 0.9734 - val_loss: 0.1280 - val_acc: 0.9558\n",
      "Epoch 160/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0662 - acc: 0.9733 - val_loss: 0.1287 - val_acc: 0.9553\n",
      "Epoch 161/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0661 - acc: 0.9733 - val_loss: 0.1209 - val_acc: 0.9574\n",
      "Epoch 162/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0641 - acc: 0.9742 - val_loss: 0.1197 - val_acc: 0.9589\n",
      "Epoch 163/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0651 - acc: 0.9738 - val_loss: 0.1209 - val_acc: 0.9579\n",
      "Epoch 164/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0652 - acc: 0.9735 - val_loss: 0.1193 - val_acc: 0.9587\n",
      "Epoch 165/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0642 - acc: 0.9741 - val_loss: 0.1198 - val_acc: 0.9583\n",
      "Epoch 166/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0632 - acc: 0.9746 - val_loss: 0.1187 - val_acc: 0.9586\n",
      "Epoch 167/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0642 - acc: 0.9741 - val_loss: 0.1181 - val_acc: 0.9593\n",
      "Epoch 168/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0642 - acc: 0.9741 - val_loss: 0.1186 - val_acc: 0.9592\n",
      "Epoch 169/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0638 - acc: 0.9745 - val_loss: 0.1263 - val_acc: 0.9556\n",
      "Epoch 170/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0641 - acc: 0.9743 - val_loss: 0.1219 - val_acc: 0.9577\n",
      "Epoch 171/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0635 - acc: 0.9743 - val_loss: 0.1186 - val_acc: 0.9593\n",
      "Epoch 172/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0635 - acc: 0.9745 - val_loss: 0.1288 - val_acc: 0.9558\n",
      "Epoch 173/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0645 - acc: 0.9737 - val_loss: 0.1230 - val_acc: 0.9580\n",
      "Epoch 174/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0634 - acc: 0.9745 - val_loss: 0.1265 - val_acc: 0.9556\n",
      "Epoch 175/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0634 - acc: 0.9748 - val_loss: 0.1221 - val_acc: 0.9579\n",
      "Epoch 176/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0628 - acc: 0.9746 - val_loss: 0.1197 - val_acc: 0.9588\n",
      "Epoch 177/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0631 - acc: 0.9746 - val_loss: 0.1198 - val_acc: 0.9587\n",
      "Epoch 178/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0625 - acc: 0.9749 - val_loss: 0.1251 - val_acc: 0.9567\n",
      "Epoch 179/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0616 - acc: 0.9751 - val_loss: 0.1299 - val_acc: 0.9555\n",
      "Epoch 180/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0624 - acc: 0.9748 - val_loss: 0.1165 - val_acc: 0.9599\n",
      "Epoch 181/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0615 - acc: 0.9754 - val_loss: 0.1244 - val_acc: 0.9571\n",
      "Epoch 182/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0620 - acc: 0.9750 - val_loss: 0.1246 - val_acc: 0.9574\n",
      "Epoch 183/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0616 - acc: 0.9751 - val_loss: 0.1185 - val_acc: 0.9590\n",
      "Epoch 184/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0615 - acc: 0.9753 - val_loss: 0.1175 - val_acc: 0.9593\n",
      "Epoch 185/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0612 - acc: 0.9754 - val_loss: 0.1189 - val_acc: 0.9598\n",
      "Epoch 186/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0618 - acc: 0.9749 - val_loss: 0.1209 - val_acc: 0.9589\n",
      "Epoch 187/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0600 - acc: 0.9760 - val_loss: 0.1148 - val_acc: 0.9605\n",
      "Epoch 188/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0607 - acc: 0.9756 - val_loss: 0.1187 - val_acc: 0.9590\n",
      "Epoch 189/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0607 - acc: 0.9757 - val_loss: 0.1195 - val_acc: 0.9590\n",
      "Epoch 190/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0605 - acc: 0.9759 - val_loss: 0.1176 - val_acc: 0.9589\n",
      "Epoch 191/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0596 - acc: 0.9764 - val_loss: 0.1190 - val_acc: 0.9594\n",
      "Epoch 192/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0599 - acc: 0.9758 - val_loss: 0.1265 - val_acc: 0.9570\n",
      "Epoch 193/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0595 - acc: 0.9763 - val_loss: 0.1170 - val_acc: 0.9605\n",
      "Epoch 194/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0605 - acc: 0.9758 - val_loss: 0.1169 - val_acc: 0.9602\n",
      "Epoch 195/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0593 - acc: 0.9761 - val_loss: 0.1212 - val_acc: 0.9584\n",
      "Epoch 196/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0598 - acc: 0.9758 - val_loss: 0.1190 - val_acc: 0.9593\n",
      "Epoch 197/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0585 - acc: 0.9765 - val_loss: 0.1170 - val_acc: 0.9604\n",
      "Epoch 198/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0601 - acc: 0.9761 - val_loss: 0.1304 - val_acc: 0.9560\n",
      "Epoch 199/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0585 - acc: 0.9763 - val_loss: 0.1189 - val_acc: 0.9599\n",
      "Epoch 200/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0593 - acc: 0.9759 - val_loss: 0.1208 - val_acc: 0.9596\n",
      "Epoch 201/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0589 - acc: 0.9764 - val_loss: 0.1265 - val_acc: 0.9575\n",
      "Epoch 202/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0591 - acc: 0.9762 - val_loss: 0.1204 - val_acc: 0.9592\n",
      "Epoch 203/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0591 - acc: 0.9762 - val_loss: 0.1261 - val_acc: 0.9571\n",
      "Epoch 204/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0597 - acc: 0.9759 - val_loss: 0.1213 - val_acc: 0.9589\n",
      "Epoch 205/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0575 - acc: 0.9769 - val_loss: 0.1212 - val_acc: 0.9584\n",
      "Epoch 206/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0575 - acc: 0.9769 - val_loss: 0.1180 - val_acc: 0.9610\n",
      "Epoch 207/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0577 - acc: 0.9769 - val_loss: 0.1210 - val_acc: 0.9594\n",
      "Epoch 208/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0579 - acc: 0.9770 - val_loss: 0.1231 - val_acc: 0.9588\n",
      "Epoch 209/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0576 - acc: 0.9770 - val_loss: 0.1222 - val_acc: 0.9583\n",
      "Epoch 210/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0576 - acc: 0.9768 - val_loss: 0.1185 - val_acc: 0.9598\n",
      "Epoch 211/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0575 - acc: 0.9772 - val_loss: 0.1242 - val_acc: 0.9590\n",
      "Epoch 212/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0576 - acc: 0.9771 - val_loss: 0.1174 - val_acc: 0.9605\n",
      "Epoch 213/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0573 - acc: 0.9768 - val_loss: 0.1187 - val_acc: 0.9595\n",
      "Epoch 214/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0570 - acc: 0.9772 - val_loss: 0.1170 - val_acc: 0.9598\n",
      "Epoch 215/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0575 - acc: 0.9771 - val_loss: 0.1224 - val_acc: 0.9591\n",
      "Epoch 216/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0568 - acc: 0.9770 - val_loss: 0.1198 - val_acc: 0.9601\n",
      "Epoch 217/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0568 - acc: 0.9771 - val_loss: 0.1208 - val_acc: 0.9594\n",
      "Epoch 218/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0579 - acc: 0.9767 - val_loss: 0.1197 - val_acc: 0.9600\n",
      "Epoch 219/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0567 - acc: 0.9772 - val_loss: 0.1139 - val_acc: 0.9613\n",
      "Epoch 220/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0551 - acc: 0.9780 - val_loss: 0.1245 - val_acc: 0.9593\n",
      "Epoch 221/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0559 - acc: 0.9776 - val_loss: 0.1194 - val_acc: 0.9607\n",
      "Epoch 222/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0561 - acc: 0.9775 - val_loss: 0.1204 - val_acc: 0.9598\n",
      "Epoch 223/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0563 - acc: 0.9776 - val_loss: 0.1230 - val_acc: 0.9599\n",
      "Epoch 224/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0565 - acc: 0.9775 - val_loss: 0.1218 - val_acc: 0.9598\n",
      "Epoch 225/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0550 - acc: 0.9778 - val_loss: 0.1167 - val_acc: 0.9613\n",
      "Epoch 226/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0551 - acc: 0.9780 - val_loss: 0.1232 - val_acc: 0.9596\n",
      "Epoch 227/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0559 - acc: 0.9776 - val_loss: 0.1188 - val_acc: 0.9609\n",
      "Epoch 228/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0546 - acc: 0.9783 - val_loss: 0.1173 - val_acc: 0.9605\n",
      "Epoch 229/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0557 - acc: 0.9778 - val_loss: 0.1156 - val_acc: 0.9618\n",
      "Epoch 230/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0545 - acc: 0.9782 - val_loss: 0.1213 - val_acc: 0.9599\n",
      "Epoch 231/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0547 - acc: 0.9780 - val_loss: 0.1189 - val_acc: 0.9614\n",
      "Epoch 232/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0554 - acc: 0.9778 - val_loss: 0.1164 - val_acc: 0.9615\n",
      "Epoch 233/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0547 - acc: 0.9780 - val_loss: 0.1209 - val_acc: 0.9602\n",
      "Epoch 234/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0550 - acc: 0.9779 - val_loss: 0.1156 - val_acc: 0.9617\n",
      "Epoch 235/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0548 - acc: 0.9780 - val_loss: 0.1192 - val_acc: 0.9609\n",
      "Epoch 236/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0551 - acc: 0.9780 - val_loss: 0.1236 - val_acc: 0.9592\n",
      "Epoch 237/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0544 - acc: 0.9780 - val_loss: 0.1195 - val_acc: 0.9598\n",
      "Epoch 238/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0545 - acc: 0.9782 - val_loss: 0.1182 - val_acc: 0.9611\n",
      "Epoch 239/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0538 - acc: 0.9783 - val_loss: 0.1246 - val_acc: 0.9587\n",
      "Epoch 240/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0540 - acc: 0.9783 - val_loss: 0.1240 - val_acc: 0.9590\n",
      "Epoch 241/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0533 - acc: 0.9788 - val_loss: 0.1251 - val_acc: 0.9592\n",
      "Epoch 242/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0539 - acc: 0.9785 - val_loss: 0.1169 - val_acc: 0.9614\n",
      "Epoch 243/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0538 - acc: 0.9786 - val_loss: 0.1237 - val_acc: 0.9595\n",
      "Epoch 244/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0533 - acc: 0.9786 - val_loss: 0.1209 - val_acc: 0.9606\n",
      "Epoch 245/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0531 - acc: 0.9786 - val_loss: 0.1233 - val_acc: 0.9605\n",
      "Epoch 246/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0534 - acc: 0.9785 - val_loss: 0.1184 - val_acc: 0.9607\n",
      "Epoch 247/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0534 - acc: 0.9788 - val_loss: 0.1219 - val_acc: 0.9600\n",
      "Epoch 248/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0540 - acc: 0.9784 - val_loss: 0.1189 - val_acc: 0.9613\n",
      "Epoch 249/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0527 - acc: 0.9789 - val_loss: 0.1297 - val_acc: 0.9586\n",
      "Epoch 250/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0529 - acc: 0.9789 - val_loss: 0.1256 - val_acc: 0.9587\n",
      "Epoch 251/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0524 - acc: 0.9790 - val_loss: 0.1244 - val_acc: 0.9593\n",
      "Epoch 252/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0528 - acc: 0.9787 - val_loss: 0.1197 - val_acc: 0.9609\n",
      "Epoch 253/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0527 - acc: 0.9789 - val_loss: 0.1188 - val_acc: 0.9608\n",
      "Epoch 254/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0517 - acc: 0.9793 - val_loss: 0.1237 - val_acc: 0.9597\n",
      "Epoch 255/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0525 - acc: 0.9789 - val_loss: 0.1208 - val_acc: 0.9606\n",
      "Epoch 256/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0524 - acc: 0.9791 - val_loss: 0.1181 - val_acc: 0.9619\n",
      "Epoch 257/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0517 - acc: 0.9794 - val_loss: 0.1204 - val_acc: 0.9606\n",
      "Epoch 258/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0525 - acc: 0.9789 - val_loss: 0.1195 - val_acc: 0.9608\n",
      "Epoch 259/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0529 - acc: 0.9790 - val_loss: 0.1163 - val_acc: 0.9614\n",
      "Epoch 260/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0519 - acc: 0.9791 - val_loss: 0.1243 - val_acc: 0.9594\n",
      "Epoch 261/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0511 - acc: 0.9797 - val_loss: 0.1227 - val_acc: 0.9599\n",
      "Epoch 262/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0513 - acc: 0.9795 - val_loss: 0.1209 - val_acc: 0.9605\n",
      "Epoch 263/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0526 - acc: 0.9789 - val_loss: 0.1265 - val_acc: 0.9596\n",
      "Epoch 264/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0509 - acc: 0.9798 - val_loss: 0.1179 - val_acc: 0.9616\n",
      "Epoch 265/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0521 - acc: 0.9793 - val_loss: 0.1210 - val_acc: 0.9603\n",
      "Epoch 266/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0518 - acc: 0.9791 - val_loss: 0.1186 - val_acc: 0.9616\n",
      "Epoch 267/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0519 - acc: 0.9792 - val_loss: 0.1161 - val_acc: 0.9623\n",
      "Epoch 268/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0502 - acc: 0.9799 - val_loss: 0.1228 - val_acc: 0.9604\n",
      "Epoch 269/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0511 - acc: 0.9794 - val_loss: 0.1196 - val_acc: 0.9605\n",
      "Epoch 270/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0508 - acc: 0.9798 - val_loss: 0.1189 - val_acc: 0.9613\n",
      "Epoch 271/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0506 - acc: 0.9797 - val_loss: 0.1226 - val_acc: 0.9608\n",
      "Epoch 272/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0511 - acc: 0.9794 - val_loss: 0.1181 - val_acc: 0.9615\n",
      "Epoch 273/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0506 - acc: 0.9795 - val_loss: 0.1217 - val_acc: 0.9608\n",
      "Epoch 274/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0504 - acc: 0.9798 - val_loss: 0.1242 - val_acc: 0.9600\n",
      "Epoch 275/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0504 - acc: 0.9797 - val_loss: 0.1279 - val_acc: 0.9596\n",
      "Epoch 276/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0509 - acc: 0.9795 - val_loss: 0.1202 - val_acc: 0.9611\n",
      "Epoch 277/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0504 - acc: 0.9798 - val_loss: 0.1192 - val_acc: 0.9615\n",
      "Epoch 278/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0505 - acc: 0.9798 - val_loss: 0.1186 - val_acc: 0.9617\n",
      "Epoch 279/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0507 - acc: 0.9797 - val_loss: 0.1229 - val_acc: 0.9613\n",
      "Epoch 280/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0496 - acc: 0.9801 - val_loss: 0.1295 - val_acc: 0.9584\n",
      "Epoch 281/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0502 - acc: 0.9801 - val_loss: 0.1218 - val_acc: 0.9604\n",
      "Epoch 282/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0496 - acc: 0.9802 - val_loss: 0.1284 - val_acc: 0.9587\n",
      "Epoch 283/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0507 - acc: 0.9797 - val_loss: 0.1172 - val_acc: 0.9627\n",
      "Epoch 284/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0500 - acc: 0.9801 - val_loss: 0.1182 - val_acc: 0.9617\n",
      "Epoch 285/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0495 - acc: 0.9803 - val_loss: 0.1205 - val_acc: 0.9612\n",
      "Epoch 286/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0494 - acc: 0.9802 - val_loss: 0.1219 - val_acc: 0.9611\n",
      "Epoch 287/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0495 - acc: 0.9804 - val_loss: 0.1258 - val_acc: 0.9606\n",
      "Epoch 288/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0497 - acc: 0.9802 - val_loss: 0.1245 - val_acc: 0.9613\n",
      "Epoch 289/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0486 - acc: 0.9805 - val_loss: 0.1175 - val_acc: 0.9631\n",
      "Epoch 290/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0491 - acc: 0.9805 - val_loss: 0.1180 - val_acc: 0.9628\n",
      "Epoch 291/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0491 - acc: 0.9804 - val_loss: 0.1201 - val_acc: 0.9619\n",
      "Epoch 292/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0481 - acc: 0.9806 - val_loss: 0.1195 - val_acc: 0.9618\n",
      "Epoch 293/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0483 - acc: 0.9806 - val_loss: 0.1304 - val_acc: 0.9589\n",
      "Epoch 294/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0488 - acc: 0.9806 - val_loss: 0.1218 - val_acc: 0.9613\n",
      "Epoch 295/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0489 - acc: 0.9807 - val_loss: 0.1197 - val_acc: 0.9623\n",
      "Epoch 296/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0491 - acc: 0.9802 - val_loss: 0.1236 - val_acc: 0.9602\n",
      "Epoch 297/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0488 - acc: 0.9807 - val_loss: 0.1218 - val_acc: 0.9611\n",
      "Epoch 298/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0489 - acc: 0.9805 - val_loss: 0.1272 - val_acc: 0.9594\n",
      "Epoch 299/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0487 - acc: 0.9810 - val_loss: 0.1203 - val_acc: 0.9618\n",
      "Epoch 300/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0483 - acc: 0.9808 - val_loss: 0.1183 - val_acc: 0.9622\n",
      "Epoch 301/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0482 - acc: 0.9807 - val_loss: 0.1216 - val_acc: 0.9618\n",
      "Epoch 302/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0483 - acc: 0.9809 - val_loss: 0.1176 - val_acc: 0.9621\n",
      "Epoch 303/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0488 - acc: 0.9804 - val_loss: 0.1213 - val_acc: 0.9618\n",
      "Epoch 304/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0478 - acc: 0.9808 - val_loss: 0.1230 - val_acc: 0.9615\n",
      "Epoch 305/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0479 - acc: 0.9809 - val_loss: 0.1332 - val_acc: 0.9579\n",
      "Epoch 306/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0482 - acc: 0.9809 - val_loss: 0.1202 - val_acc: 0.9620\n",
      "Epoch 307/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0479 - acc: 0.9810 - val_loss: 0.1189 - val_acc: 0.9626\n",
      "Epoch 308/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0472 - acc: 0.9810 - val_loss: 0.1226 - val_acc: 0.9605\n",
      "Epoch 309/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0482 - acc: 0.9807 - val_loss: 0.1205 - val_acc: 0.9618\n",
      "Epoch 310/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0472 - acc: 0.9811 - val_loss: 0.1204 - val_acc: 0.9615\n",
      "Epoch 311/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0464 - acc: 0.9817 - val_loss: 0.1238 - val_acc: 0.9609\n",
      "Epoch 312/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0475 - acc: 0.9813 - val_loss: 0.1221 - val_acc: 0.9612\n",
      "Epoch 313/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0464 - acc: 0.9817 - val_loss: 0.1191 - val_acc: 0.9625\n",
      "Epoch 314/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0482 - acc: 0.9807 - val_loss: 0.1228 - val_acc: 0.9614\n",
      "Epoch 315/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0468 - acc: 0.9814 - val_loss: 0.1305 - val_acc: 0.9593\n",
      "Epoch 316/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0466 - acc: 0.9815 - val_loss: 0.1232 - val_acc: 0.9617\n",
      "Epoch 317/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0482 - acc: 0.9811 - val_loss: 0.1246 - val_acc: 0.9606\n",
      "Epoch 318/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0472 - acc: 0.9810 - val_loss: 0.1207 - val_acc: 0.9623\n",
      "Epoch 319/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0470 - acc: 0.9814 - val_loss: 0.1236 - val_acc: 0.9616\n",
      "Epoch 320/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0461 - acc: 0.9815 - val_loss: 0.1288 - val_acc: 0.9601\n",
      "Epoch 321/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0467 - acc: 0.9812 - val_loss: 0.1186 - val_acc: 0.9623\n",
      "Epoch 322/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0472 - acc: 0.9811 - val_loss: 0.1238 - val_acc: 0.9615\n",
      "Epoch 323/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0471 - acc: 0.9810 - val_loss: 0.1257 - val_acc: 0.9603\n",
      "Epoch 324/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0466 - acc: 0.9814 - val_loss: 0.1221 - val_acc: 0.9619\n",
      "Epoch 325/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0469 - acc: 0.9813 - val_loss: 0.1269 - val_acc: 0.9604\n",
      "Epoch 326/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0476 - acc: 0.9811 - val_loss: 0.1231 - val_acc: 0.9616\n",
      "Epoch 327/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0462 - acc: 0.9814 - val_loss: 0.1213 - val_acc: 0.9624\n",
      "Epoch 328/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0454 - acc: 0.9819 - val_loss: 0.1224 - val_acc: 0.9621\n",
      "Epoch 329/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0458 - acc: 0.9817 - val_loss: 0.1227 - val_acc: 0.9618\n",
      "Epoch 330/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0461 - acc: 0.9817 - val_loss: 0.1226 - val_acc: 0.9616\n",
      "Epoch 331/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0459 - acc: 0.9817 - val_loss: 0.1219 - val_acc: 0.9619\n",
      "Epoch 332/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0471 - acc: 0.9811 - val_loss: 0.1203 - val_acc: 0.9629\n",
      "Epoch 333/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0451 - acc: 0.9820 - val_loss: 0.1201 - val_acc: 0.9631\n",
      "Epoch 334/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0456 - acc: 0.9818 - val_loss: 0.1187 - val_acc: 0.9635\n",
      "Epoch 335/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0463 - acc: 0.9817 - val_loss: 0.1206 - val_acc: 0.9633\n",
      "Epoch 336/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0447 - acc: 0.9821 - val_loss: 0.1249 - val_acc: 0.9613\n",
      "Epoch 337/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0455 - acc: 0.9820 - val_loss: 0.1276 - val_acc: 0.9604\n",
      "Epoch 338/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0462 - acc: 0.9816 - val_loss: 0.1240 - val_acc: 0.9618\n",
      "Epoch 339/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0450 - acc: 0.9820 - val_loss: 0.1187 - val_acc: 0.9626\n",
      "Epoch 340/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0454 - acc: 0.9820 - val_loss: 0.1249 - val_acc: 0.9612\n",
      "Epoch 341/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0460 - acc: 0.9815 - val_loss: 0.1286 - val_acc: 0.9604\n",
      "Epoch 342/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0467 - acc: 0.9813 - val_loss: 0.1254 - val_acc: 0.9612\n",
      "Epoch 343/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0452 - acc: 0.9819 - val_loss: 0.1260 - val_acc: 0.9607\n",
      "Epoch 344/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0453 - acc: 0.9819 - val_loss: 0.1189 - val_acc: 0.9638\n",
      "Epoch 345/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0458 - acc: 0.9815 - val_loss: 0.1271 - val_acc: 0.9610\n",
      "Epoch 346/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0438 - acc: 0.9827 - val_loss: 0.1222 - val_acc: 0.9622\n",
      "Epoch 347/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0455 - acc: 0.9817 - val_loss: 0.1217 - val_acc: 0.9626\n",
      "Epoch 348/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0449 - acc: 0.9819 - val_loss: 0.1226 - val_acc: 0.9619\n",
      "Epoch 349/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0445 - acc: 0.9823 - val_loss: 0.1233 - val_acc: 0.9621\n",
      "Epoch 350/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0453 - acc: 0.9821 - val_loss: 0.1215 - val_acc: 0.9620\n",
      "Epoch 351/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0448 - acc: 0.9821 - val_loss: 0.1214 - val_acc: 0.9625\n",
      "Epoch 352/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0451 - acc: 0.9821 - val_loss: 0.1253 - val_acc: 0.9610\n",
      "Epoch 353/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0446 - acc: 0.9824 - val_loss: 0.1218 - val_acc: 0.9624\n",
      "Epoch 354/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0440 - acc: 0.9825 - val_loss: 0.1237 - val_acc: 0.9614\n",
      "Epoch 355/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0450 - acc: 0.9821 - val_loss: 0.1254 - val_acc: 0.9610\n",
      "Epoch 356/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0438 - acc: 0.9825 - val_loss: 0.1220 - val_acc: 0.9625\n",
      "Epoch 357/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0450 - acc: 0.9819 - val_loss: 0.1248 - val_acc: 0.9613\n",
      "Epoch 358/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0450 - acc: 0.9821 - val_loss: 0.1181 - val_acc: 0.9634\n",
      "Epoch 359/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0442 - acc: 0.9824 - val_loss: 0.1209 - val_acc: 0.9624\n",
      "Epoch 360/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0438 - acc: 0.9825 - val_loss: 0.1259 - val_acc: 0.9615\n",
      "Epoch 361/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0440 - acc: 0.9825 - val_loss: 0.1225 - val_acc: 0.9623\n",
      "Epoch 362/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0439 - acc: 0.9824 - val_loss: 0.1243 - val_acc: 0.9617\n",
      "Epoch 363/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0440 - acc: 0.9824 - val_loss: 0.1245 - val_acc: 0.9617\n",
      "Epoch 364/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0439 - acc: 0.9827 - val_loss: 0.1212 - val_acc: 0.9631\n",
      "Epoch 365/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0440 - acc: 0.9824 - val_loss: 0.1231 - val_acc: 0.9622\n",
      "Epoch 366/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0434 - acc: 0.9828 - val_loss: 0.1233 - val_acc: 0.9615\n",
      "Epoch 367/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0437 - acc: 0.9828 - val_loss: 0.1351 - val_acc: 0.9593\n",
      "Epoch 368/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0440 - acc: 0.9826 - val_loss: 0.1259 - val_acc: 0.9626\n",
      "Epoch 369/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0432 - acc: 0.9829 - val_loss: 0.1204 - val_acc: 0.9631\n",
      "Epoch 370/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0437 - acc: 0.9828 - val_loss: 0.1245 - val_acc: 0.9619\n",
      "Epoch 371/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0434 - acc: 0.9827 - val_loss: 0.1253 - val_acc: 0.9621\n",
      "Epoch 372/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0438 - acc: 0.9827 - val_loss: 0.1253 - val_acc: 0.9619\n",
      "Epoch 373/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0436 - acc: 0.9825 - val_loss: 0.1237 - val_acc: 0.9625\n",
      "Epoch 374/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0436 - acc: 0.9826 - val_loss: 0.1241 - val_acc: 0.9622\n",
      "Epoch 375/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0429 - acc: 0.9828 - val_loss: 0.1301 - val_acc: 0.9611\n",
      "Epoch 376/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0425 - acc: 0.9830 - val_loss: 0.1242 - val_acc: 0.9619\n",
      "Epoch 377/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0436 - acc: 0.9828 - val_loss: 0.1264 - val_acc: 0.9614\n",
      "Epoch 378/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0432 - acc: 0.9828 - val_loss: 0.1250 - val_acc: 0.9626\n",
      "Epoch 379/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0424 - acc: 0.9831 - val_loss: 0.1236 - val_acc: 0.9630\n",
      "Epoch 380/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0441 - acc: 0.9823 - val_loss: 0.1264 - val_acc: 0.9618\n",
      "Epoch 381/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0433 - acc: 0.9828 - val_loss: 0.1297 - val_acc: 0.9607\n",
      "Epoch 382/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0429 - acc: 0.9829 - val_loss: 0.1263 - val_acc: 0.9610\n",
      "Epoch 383/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0435 - acc: 0.9826 - val_loss: 0.1286 - val_acc: 0.9613\n",
      "Epoch 384/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0429 - acc: 0.9829 - val_loss: 0.1242 - val_acc: 0.9620\n",
      "Epoch 385/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0422 - acc: 0.9832 - val_loss: 0.1226 - val_acc: 0.9629\n",
      "Epoch 386/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0426 - acc: 0.9831 - val_loss: 0.1269 - val_acc: 0.9613\n",
      "Epoch 387/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0427 - acc: 0.9831 - val_loss: 0.1225 - val_acc: 0.9633\n",
      "Epoch 388/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0413 - acc: 0.9836 - val_loss: 0.1225 - val_acc: 0.9633\n",
      "Epoch 389/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0422 - acc: 0.9832 - val_loss: 0.1201 - val_acc: 0.9632\n",
      "Epoch 390/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0423 - acc: 0.9832 - val_loss: 0.1261 - val_acc: 0.9621\n",
      "Epoch 391/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0422 - acc: 0.9832 - val_loss: 0.1239 - val_acc: 0.9625\n",
      "Epoch 392/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0430 - acc: 0.9829 - val_loss: 0.1246 - val_acc: 0.9622\n",
      "Epoch 393/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0417 - acc: 0.9835 - val_loss: 0.1250 - val_acc: 0.9629\n",
      "Epoch 394/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0419 - acc: 0.9836 - val_loss: 0.1307 - val_acc: 0.9612\n",
      "Epoch 395/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0419 - acc: 0.9834 - val_loss: 0.1239 - val_acc: 0.9625\n",
      "Epoch 396/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0418 - acc: 0.9834 - val_loss: 0.1249 - val_acc: 0.9627\n",
      "Epoch 397/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0419 - acc: 0.9834 - val_loss: 0.1218 - val_acc: 0.9635\n",
      "Epoch 398/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0415 - acc: 0.9836 - val_loss: 0.1217 - val_acc: 0.9632\n",
      "Epoch 399/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0422 - acc: 0.9834 - val_loss: 0.1293 - val_acc: 0.9614\n",
      "Epoch 400/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0417 - acc: 0.9835 - val_loss: 0.1228 - val_acc: 0.9628\n",
      "Epoch 401/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0419 - acc: 0.9834 - val_loss: 0.1235 - val_acc: 0.9621\n",
      "Epoch 402/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0413 - acc: 0.9835 - val_loss: 0.1229 - val_acc: 0.9632\n",
      "Epoch 403/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0412 - acc: 0.9839 - val_loss: 0.1264 - val_acc: 0.9620\n",
      "Epoch 404/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0416 - acc: 0.9834 - val_loss: 0.1250 - val_acc: 0.9628\n",
      "Epoch 405/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0417 - acc: 0.9833 - val_loss: 0.1226 - val_acc: 0.9630\n",
      "Epoch 406/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0414 - acc: 0.9837 - val_loss: 0.1232 - val_acc: 0.9628\n",
      "Epoch 407/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0414 - acc: 0.9837 - val_loss: 0.1249 - val_acc: 0.9626\n",
      "Epoch 408/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0408 - acc: 0.9838 - val_loss: 0.1328 - val_acc: 0.9603\n",
      "Epoch 409/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0420 - acc: 0.9833 - val_loss: 0.1313 - val_acc: 0.9604\n",
      "Epoch 410/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0423 - acc: 0.9831 - val_loss: 0.1246 - val_acc: 0.9625\n",
      "Epoch 411/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0417 - acc: 0.9834 - val_loss: 0.1246 - val_acc: 0.9620\n",
      "Epoch 412/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0408 - acc: 0.9838 - val_loss: 0.1249 - val_acc: 0.9622\n",
      "Epoch 413/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0418 - acc: 0.9837 - val_loss: 0.1270 - val_acc: 0.9623\n",
      "Epoch 414/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0411 - acc: 0.9841 - val_loss: 0.1297 - val_acc: 0.9616\n",
      "Epoch 415/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0410 - acc: 0.9838 - val_loss: 0.1251 - val_acc: 0.9628\n",
      "Epoch 416/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0414 - acc: 0.9835 - val_loss: 0.1230 - val_acc: 0.9630\n",
      "Epoch 417/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0399 - acc: 0.9842 - val_loss: 0.1289 - val_acc: 0.9614\n",
      "Epoch 418/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0407 - acc: 0.9839 - val_loss: 0.1311 - val_acc: 0.9609\n",
      "Epoch 419/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0406 - acc: 0.9840 - val_loss: 0.1218 - val_acc: 0.9636\n",
      "Epoch 420/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0419 - acc: 0.9834 - val_loss: 0.1257 - val_acc: 0.9622\n",
      "Epoch 421/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0406 - acc: 0.9839 - val_loss: 0.1236 - val_acc: 0.9638\n",
      "Epoch 422/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0404 - acc: 0.9841 - val_loss: 0.1243 - val_acc: 0.9632\n",
      "Epoch 423/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0404 - acc: 0.9839 - val_loss: 0.1316 - val_acc: 0.9611\n",
      "Epoch 424/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0400 - acc: 0.9840 - val_loss: 0.1248 - val_acc: 0.9625\n",
      "Epoch 425/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0396 - acc: 0.9846 - val_loss: 0.1254 - val_acc: 0.9629\n",
      "Epoch 426/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0405 - acc: 0.9842 - val_loss: 0.1263 - val_acc: 0.9621\n",
      "Epoch 427/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0407 - acc: 0.9838 - val_loss: 0.1250 - val_acc: 0.9624\n",
      "Epoch 428/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0406 - acc: 0.9839 - val_loss: 0.1251 - val_acc: 0.9628\n",
      "Epoch 429/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0401 - acc: 0.9844 - val_loss: 0.1239 - val_acc: 0.9628\n",
      "Epoch 430/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0396 - acc: 0.9845 - val_loss: 0.1318 - val_acc: 0.9612\n",
      "Epoch 431/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0409 - acc: 0.9838 - val_loss: 0.1213 - val_acc: 0.9639\n",
      "Epoch 432/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0396 - acc: 0.9844 - val_loss: 0.1235 - val_acc: 0.9630\n",
      "Epoch 433/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0398 - acc: 0.9842 - val_loss: 0.1241 - val_acc: 0.9628\n",
      "Epoch 434/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0403 - acc: 0.9840 - val_loss: 0.1260 - val_acc: 0.9636\n",
      "Epoch 435/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0395 - acc: 0.9842 - val_loss: 0.1259 - val_acc: 0.9627\n",
      "Epoch 436/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0405 - acc: 0.9839 - val_loss: 0.1227 - val_acc: 0.9635\n",
      "Epoch 437/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0404 - acc: 0.9842 - val_loss: 0.1240 - val_acc: 0.9637\n",
      "Epoch 438/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0403 - acc: 0.9842 - val_loss: 0.1393 - val_acc: 0.9588\n",
      "Epoch 439/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0398 - acc: 0.9842 - val_loss: 0.1260 - val_acc: 0.9629\n",
      "Epoch 440/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0400 - acc: 0.9841 - val_loss: 0.1272 - val_acc: 0.9628\n",
      "Epoch 441/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0404 - acc: 0.9839 - val_loss: 0.1321 - val_acc: 0.9612\n",
      "Epoch 442/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0403 - acc: 0.9840 - val_loss: 0.1295 - val_acc: 0.9621\n",
      "Epoch 443/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0393 - acc: 0.9846 - val_loss: 0.1304 - val_acc: 0.9610\n",
      "Epoch 444/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0385 - acc: 0.9848 - val_loss: 0.1268 - val_acc: 0.9620\n",
      "Epoch 445/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0402 - acc: 0.9841 - val_loss: 0.1288 - val_acc: 0.9625\n",
      "Epoch 446/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0398 - acc: 0.9842 - val_loss: 0.1321 - val_acc: 0.9609\n",
      "Epoch 447/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0393 - acc: 0.9845 - val_loss: 0.1263 - val_acc: 0.9623\n",
      "Epoch 448/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0391 - acc: 0.9848 - val_loss: 0.1252 - val_acc: 0.9631\n",
      "Epoch 449/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0385 - acc: 0.9849 - val_loss: 0.1243 - val_acc: 0.9629\n",
      "Epoch 450/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0390 - acc: 0.9846 - val_loss: 0.1234 - val_acc: 0.9634\n",
      "Epoch 451/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0394 - acc: 0.9844 - val_loss: 0.1279 - val_acc: 0.9634\n",
      "Epoch 452/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0402 - acc: 0.9842 - val_loss: 0.1257 - val_acc: 0.9638\n",
      "Epoch 453/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0404 - acc: 0.9841 - val_loss: 0.1253 - val_acc: 0.9633\n",
      "Epoch 454/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0387 - acc: 0.9847 - val_loss: 0.1289 - val_acc: 0.9625\n",
      "Epoch 455/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0395 - acc: 0.9844 - val_loss: 0.1225 - val_acc: 0.9640\n",
      "Epoch 456/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0394 - acc: 0.9845 - val_loss: 0.1270 - val_acc: 0.9625\n",
      "Epoch 457/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0384 - acc: 0.9848 - val_loss: 0.1293 - val_acc: 0.9620\n",
      "Epoch 458/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0391 - acc: 0.9843 - val_loss: 0.1271 - val_acc: 0.9624\n",
      "Epoch 459/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0383 - acc: 0.9847 - val_loss: 0.1267 - val_acc: 0.9624\n",
      "Epoch 460/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0387 - acc: 0.9848 - val_loss: 0.1292 - val_acc: 0.9624\n",
      "Epoch 461/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0391 - acc: 0.9845 - val_loss: 0.1303 - val_acc: 0.9622\n",
      "Epoch 462/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0384 - acc: 0.9847 - val_loss: 0.1290 - val_acc: 0.9626\n",
      "Epoch 463/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0380 - acc: 0.9851 - val_loss: 0.1338 - val_acc: 0.9615\n",
      "Epoch 464/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0394 - acc: 0.9842 - val_loss: 0.1322 - val_acc: 0.9613\n",
      "Epoch 465/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0393 - acc: 0.9844 - val_loss: 0.1249 - val_acc: 0.9637\n",
      "Epoch 466/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0390 - acc: 0.9848 - val_loss: 0.1279 - val_acc: 0.9627\n",
      "Epoch 467/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0382 - acc: 0.9847 - val_loss: 0.1342 - val_acc: 0.9606\n",
      "Epoch 468/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0383 - acc: 0.9850 - val_loss: 0.1302 - val_acc: 0.9620\n",
      "Epoch 469/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0384 - acc: 0.9848 - val_loss: 0.1292 - val_acc: 0.9623\n",
      "Epoch 470/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0386 - acc: 0.9848 - val_loss: 0.1293 - val_acc: 0.9625\n",
      "Epoch 471/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0386 - acc: 0.9846 - val_loss: 0.1274 - val_acc: 0.9627\n",
      "Epoch 472/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0375 - acc: 0.9851 - val_loss: 0.1300 - val_acc: 0.9621\n",
      "Epoch 473/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0378 - acc: 0.9851 - val_loss: 0.1277 - val_acc: 0.9626\n",
      "Epoch 474/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0395 - acc: 0.9842 - val_loss: 0.1275 - val_acc: 0.9628\n",
      "Epoch 475/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0378 - acc: 0.9852 - val_loss: 0.1323 - val_acc: 0.9620\n",
      "Epoch 476/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0385 - acc: 0.9847 - val_loss: 0.1280 - val_acc: 0.9629\n",
      "Epoch 477/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0385 - acc: 0.9848 - val_loss: 0.1269 - val_acc: 0.9630\n",
      "Epoch 478/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0384 - acc: 0.9847 - val_loss: 0.1292 - val_acc: 0.9622\n",
      "Epoch 479/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0385 - acc: 0.9848 - val_loss: 0.1286 - val_acc: 0.9627\n",
      "Epoch 480/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0388 - acc: 0.9847 - val_loss: 0.1291 - val_acc: 0.9628\n",
      "Epoch 481/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0377 - acc: 0.9852 - val_loss: 0.1255 - val_acc: 0.9639\n",
      "Epoch 482/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0370 - acc: 0.9854 - val_loss: 0.1307 - val_acc: 0.9627\n",
      "Epoch 483/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0385 - acc: 0.9850 - val_loss: 0.1297 - val_acc: 0.9620\n",
      "Epoch 484/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0384 - acc: 0.9850 - val_loss: 0.1323 - val_acc: 0.9616\n",
      "Epoch 485/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0377 - acc: 0.9851 - val_loss: 0.1323 - val_acc: 0.9620\n",
      "Epoch 486/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0375 - acc: 0.9853 - val_loss: 0.1265 - val_acc: 0.9633\n",
      "Epoch 487/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0383 - acc: 0.9848 - val_loss: 0.1353 - val_acc: 0.9610\n",
      "Epoch 488/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0388 - acc: 0.9846 - val_loss: 0.1277 - val_acc: 0.9635\n",
      "Epoch 489/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0368 - acc: 0.9854 - val_loss: 0.1256 - val_acc: 0.9639\n",
      "Epoch 490/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0374 - acc: 0.9853 - val_loss: 0.1284 - val_acc: 0.9629\n",
      "Epoch 491/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0387 - acc: 0.9848 - val_loss: 0.1289 - val_acc: 0.9627\n",
      "Epoch 492/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0374 - acc: 0.9852 - val_loss: 0.1325 - val_acc: 0.9623\n",
      "Epoch 493/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0373 - acc: 0.9851 - val_loss: 0.1282 - val_acc: 0.9624\n",
      "Epoch 494/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0374 - acc: 0.9853 - val_loss: 0.1280 - val_acc: 0.9634\n",
      "Epoch 495/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0376 - acc: 0.9853 - val_loss: 0.1286 - val_acc: 0.9633\n",
      "Epoch 496/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0369 - acc: 0.9855 - val_loss: 0.1330 - val_acc: 0.9618\n",
      "Epoch 497/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0379 - acc: 0.9852 - val_loss: 0.1354 - val_acc: 0.9612\n",
      "Epoch 498/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0375 - acc: 0.9852 - val_loss: 0.1326 - val_acc: 0.9617\n",
      "Epoch 499/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0376 - acc: 0.9849 - val_loss: 0.1260 - val_acc: 0.9634\n",
      "Epoch 500/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0372 - acc: 0.9850 - val_loss: 0.1265 - val_acc: 0.9634\n",
      "Epoch 501/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0372 - acc: 0.9855 - val_loss: 0.1358 - val_acc: 0.9611\n",
      "Epoch 502/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0376 - acc: 0.9851 - val_loss: 0.1330 - val_acc: 0.9616\n",
      "Epoch 503/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0369 - acc: 0.9853 - val_loss: 0.1273 - val_acc: 0.9638\n",
      "Epoch 504/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0369 - acc: 0.9854 - val_loss: 0.1271 - val_acc: 0.9639\n",
      "Epoch 505/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0363 - acc: 0.9857 - val_loss: 0.1276 - val_acc: 0.9632\n",
      "Epoch 506/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0368 - acc: 0.9856 - val_loss: 0.1306 - val_acc: 0.9623\n",
      "Epoch 507/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0368 - acc: 0.9855 - val_loss: 0.1308 - val_acc: 0.9625\n",
      "Epoch 508/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0367 - acc: 0.9854 - val_loss: 0.1294 - val_acc: 0.9627\n",
      "Epoch 509/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0369 - acc: 0.9856 - val_loss: 0.1291 - val_acc: 0.9630\n",
      "Epoch 510/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0368 - acc: 0.9855 - val_loss: 0.1275 - val_acc: 0.9629\n",
      "Epoch 511/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0363 - acc: 0.9857 - val_loss: 0.1319 - val_acc: 0.9619\n",
      "Epoch 512/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0372 - acc: 0.9853 - val_loss: 0.1307 - val_acc: 0.9628\n",
      "Epoch 513/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0362 - acc: 0.9858 - val_loss: 0.1282 - val_acc: 0.9633\n",
      "Epoch 514/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0367 - acc: 0.9855 - val_loss: 0.1339 - val_acc: 0.9618\n",
      "Epoch 515/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0371 - acc: 0.9854 - val_loss: 0.1269 - val_acc: 0.9643\n",
      "Epoch 516/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0372 - acc: 0.9853 - val_loss: 0.1288 - val_acc: 0.9633\n",
      "Epoch 517/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0371 - acc: 0.9855 - val_loss: 0.1287 - val_acc: 0.9632\n",
      "Epoch 518/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0365 - acc: 0.9857 - val_loss: 0.1300 - val_acc: 0.9628\n",
      "Epoch 519/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0361 - acc: 0.9857 - val_loss: 0.1281 - val_acc: 0.9630\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f968a4779b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f968596d668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model several epochs, and test on the validation set. Plot the loss for train and validation sets\n",
    "t_init = time.time()\n",
    "# for _ in np.arange(200):\n",
    "# train_time = 15 # how long to train for in minutes\n",
    "# print('Training for {} minutes...'.format(train_time))\n",
    "# while (time.time() - t_init)/60 < train_time:\n",
    "    #print('Creating batch number', num_epochs_trained + 1, '...')\n",
    "#     batch_data, batch_labels = get_batch(train_data,train_labels)\n",
    "#     if num_epochs_trained%100==0:\n",
    "#         print('Training on batch number', num_epochs_trained + 1, '...')\n",
    "#     train_loss.append(model.train_on_batch(batch_data, batch_labels))\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "t = time.time()\n",
    "history = model.fit(train_data, train_labels, batch_size = 1000, epochs = 2500, \n",
    "                    validation_data=(valid_data,valid_labels), verbose = 1, callbacks=[early_stopping])\n",
    "# train_loss.append(history.history['loss'])\n",
    "# valid_loss.append(model.test_on_batch(valid_data, valid_labels, sample_weight=None))\n",
    "epoch_time = time.time() - t\n",
    "# print('\\b\\b\\b\\rEpoch = {}, train_loss = {:0.4f}, valid_loss = {:0.4f}, epoch_time = {:0.1f}s, current_time = {:0.1f}m'\n",
    "#       .format(num_epochs_trained+1, train_loss[-1][0], valid_loss[-1], epoch_time, (time.time()-t_init)/60), end='')\n",
    "num_epochs_trained = num_epochs_trained + 1\n",
    "total_time = time.time() - t_init\n",
    "\n",
    "# print('\\nTotal time elapsed for this session = {:0.1f}m'.format(total_time/60))\n",
    "# print('train_loss =', train_loss[-1], '    valid_loss =', valid_loss[-1])\n",
    "# print('\\nTotal number of epochs trained = {}'.format(num_epochs_trained))\n",
    "\n",
    "# model.save('models/ground_cover_classifier_natural.h5')\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history[\"val_acc\"])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/ground_cover_classifier_natural.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 98.28216216216217 %\n"
     ]
    }
   ],
   "source": [
    "percent_correct(model,train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 96.004 %\n"
     ]
    }
   ],
   "source": [
    "percent_correct(model,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss= 0.126042\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.test_on_batch(test_data, test_labels, sample_weight=None)\n",
    "print('test_loss=',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 95.89503837422981 %\n"
     ]
    }
   ],
   "source": [
    "percent_correct(model,test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Build the model - validation loss of 0.12 (hits 0.1199 at some point) after 250 epochs, but should probably \n",
    "# stop a good bit sooner by \n",
    "# the look of the plot. Maybe averaging a bunch of these together will give some improvement. Also, look into\n",
    "# parameter optimization.\n",
    "print('Build model...')\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(512, activation='relu', input_dim=54))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model1.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "# model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 370000 samples, validate on 100000 samples\n",
      "Epoch 1/2500\n",
      "370000/370000 [==============================] - 6s 16us/step - loss: 0.6259 - acc: 0.7662 - val_loss: 0.9620 - val_acc: 0.5906\n",
      "Epoch 2/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.4287 - acc: 0.8238 - val_loss: 0.4120 - val_acc: 0.8285\n",
      "Epoch 3/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.3659 - acc: 0.8517 - val_loss: 0.3516 - val_acc: 0.8577\n",
      "Epoch 4/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.3238 - acc: 0.8680 - val_loss: 0.3062 - val_acc: 0.8740\n",
      "Epoch 5/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2878 - acc: 0.8819 - val_loss: 0.3027 - val_acc: 0.8760\n",
      "Epoch 6/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2662 - acc: 0.8911 - val_loss: 0.2758 - val_acc: 0.8844\n",
      "Epoch 7/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2495 - acc: 0.8985 - val_loss: 0.2569 - val_acc: 0.8958\n",
      "Epoch 8/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2349 - acc: 0.9043 - val_loss: 0.2469 - val_acc: 0.8988\n",
      "Epoch 9/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.2238 - acc: 0.9084 - val_loss: 0.2396 - val_acc: 0.9028\n",
      "Epoch 10/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2141 - acc: 0.9126 - val_loss: 0.2206 - val_acc: 0.9099\n",
      "Epoch 11/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2054 - acc: 0.9164 - val_loss: 0.2195 - val_acc: 0.9110\n",
      "Epoch 12/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1989 - acc: 0.9187 - val_loss: 0.2099 - val_acc: 0.9145\n",
      "Epoch 13/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1920 - acc: 0.9214 - val_loss: 0.2086 - val_acc: 0.9155\n",
      "Epoch 14/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1864 - acc: 0.9240 - val_loss: 0.2059 - val_acc: 0.9161\n",
      "Epoch 15/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1811 - acc: 0.9260 - val_loss: 0.1950 - val_acc: 0.9211\n",
      "Epoch 16/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1767 - acc: 0.9278 - val_loss: 0.1965 - val_acc: 0.9209\n",
      "Epoch 17/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1707 - acc: 0.9300 - val_loss: 0.1958 - val_acc: 0.9219\n",
      "Epoch 18/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1659 - acc: 0.9330 - val_loss: 0.1959 - val_acc: 0.9207\n",
      "Epoch 19/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1630 - acc: 0.9337 - val_loss: 0.1876 - val_acc: 0.9245\n",
      "Epoch 20/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1602 - acc: 0.9348 - val_loss: 0.1716 - val_acc: 0.9313\n",
      "Epoch 21/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1578 - acc: 0.9357 - val_loss: 0.1819 - val_acc: 0.9270\n",
      "Epoch 22/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1546 - acc: 0.9367 - val_loss: 0.1730 - val_acc: 0.9310\n",
      "Epoch 23/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1510 - acc: 0.9384 - val_loss: 0.1832 - val_acc: 0.9264\n",
      "Epoch 24/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1486 - acc: 0.9393 - val_loss: 0.1666 - val_acc: 0.9335\n",
      "Epoch 25/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1464 - acc: 0.9403 - val_loss: 0.1846 - val_acc: 0.9260\n",
      "Epoch 26/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1446 - acc: 0.9415 - val_loss: 0.1695 - val_acc: 0.9322\n",
      "Epoch 27/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1413 - acc: 0.9427 - val_loss: 0.1682 - val_acc: 0.9332\n",
      "Epoch 28/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1408 - acc: 0.9429 - val_loss: 0.1653 - val_acc: 0.9340\n",
      "Epoch 29/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1381 - acc: 0.9441 - val_loss: 0.1530 - val_acc: 0.9399\n",
      "Epoch 30/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1355 - acc: 0.9449 - val_loss: 0.1598 - val_acc: 0.9364\n",
      "Epoch 31/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1332 - acc: 0.9459 - val_loss: 0.1562 - val_acc: 0.9374\n",
      "Epoch 32/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1321 - acc: 0.9464 - val_loss: 0.1665 - val_acc: 0.9345\n",
      "Epoch 33/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1318 - acc: 0.9465 - val_loss: 0.1567 - val_acc: 0.9378\n",
      "Epoch 34/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1298 - acc: 0.9477 - val_loss: 0.1492 - val_acc: 0.9402\n",
      "Epoch 35/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1269 - acc: 0.9483 - val_loss: 0.1646 - val_acc: 0.9348\n",
      "Epoch 36/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1274 - acc: 0.9486 - val_loss: 0.1646 - val_acc: 0.9359\n",
      "Epoch 37/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1246 - acc: 0.9494 - val_loss: 0.1536 - val_acc: 0.9392\n",
      "Epoch 38/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1245 - acc: 0.9493 - val_loss: 0.1490 - val_acc: 0.9414\n",
      "Epoch 39/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1221 - acc: 0.9506 - val_loss: 0.1493 - val_acc: 0.9410\n",
      "Epoch 40/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1206 - acc: 0.9506 - val_loss: 0.1471 - val_acc: 0.9423\n",
      "Epoch 41/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1184 - acc: 0.9520 - val_loss: 0.1445 - val_acc: 0.9432\n",
      "Epoch 42/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1182 - acc: 0.9522 - val_loss: 0.1411 - val_acc: 0.9452\n",
      "Epoch 43/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1171 - acc: 0.9522 - val_loss: 0.1468 - val_acc: 0.9422\n",
      "Epoch 44/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1149 - acc: 0.9533 - val_loss: 0.1446 - val_acc: 0.9429\n",
      "Epoch 45/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1150 - acc: 0.9534 - val_loss: 0.1468 - val_acc: 0.9429\n",
      "Epoch 46/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1139 - acc: 0.9538 - val_loss: 0.1375 - val_acc: 0.9468\n",
      "Epoch 47/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1130 - acc: 0.9543 - val_loss: 0.1446 - val_acc: 0.9442\n",
      "Epoch 48/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1116 - acc: 0.9547 - val_loss: 0.1465 - val_acc: 0.9426\n",
      "Epoch 49/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1109 - acc: 0.9550 - val_loss: 0.1434 - val_acc: 0.9448\n",
      "Epoch 50/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1097 - acc: 0.9552 - val_loss: 0.1386 - val_acc: 0.9454\n",
      "Epoch 51/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1089 - acc: 0.9557 - val_loss: 0.1480 - val_acc: 0.9413\n",
      "Epoch 52/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1083 - acc: 0.9558 - val_loss: 0.1412 - val_acc: 0.9456\n",
      "Epoch 53/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1079 - acc: 0.9562 - val_loss: 0.1478 - val_acc: 0.9423\n",
      "Epoch 54/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1060 - acc: 0.9570 - val_loss: 0.1404 - val_acc: 0.9460\n",
      "Epoch 55/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1058 - acc: 0.9569 - val_loss: 0.1460 - val_acc: 0.9434\n",
      "Epoch 56/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1046 - acc: 0.9577 - val_loss: 0.1354 - val_acc: 0.9474\n",
      "Epoch 57/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1043 - acc: 0.9578 - val_loss: 0.1448 - val_acc: 0.9451\n",
      "Epoch 58/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1037 - acc: 0.9580 - val_loss: 0.1364 - val_acc: 0.9475\n",
      "Epoch 59/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1017 - acc: 0.9589 - val_loss: 0.1346 - val_acc: 0.9475\n",
      "Epoch 60/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1013 - acc: 0.9586 - val_loss: 0.1442 - val_acc: 0.9443\n",
      "Epoch 61/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1008 - acc: 0.9588 - val_loss: 0.1622 - val_acc: 0.9377\n",
      "Epoch 62/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1001 - acc: 0.9590 - val_loss: 0.1417 - val_acc: 0.9463\n",
      "Epoch 63/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0998 - acc: 0.9595 - val_loss: 0.1315 - val_acc: 0.9489\n",
      "Epoch 64/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0983 - acc: 0.9603 - val_loss: 0.1286 - val_acc: 0.9504\n",
      "Epoch 65/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0982 - acc: 0.9603 - val_loss: 0.1296 - val_acc: 0.9505\n",
      "Epoch 66/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0976 - acc: 0.9602 - val_loss: 0.1349 - val_acc: 0.9486\n",
      "Epoch 67/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0967 - acc: 0.9604 - val_loss: 0.1323 - val_acc: 0.9500\n",
      "Epoch 68/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0962 - acc: 0.9610 - val_loss: 0.1329 - val_acc: 0.9495\n",
      "Epoch 69/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0949 - acc: 0.9616 - val_loss: 0.1277 - val_acc: 0.9512\n",
      "Epoch 70/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0948 - acc: 0.9616 - val_loss: 0.1367 - val_acc: 0.9475\n",
      "Epoch 71/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0949 - acc: 0.9615 - val_loss: 0.1291 - val_acc: 0.9512\n",
      "Epoch 72/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0935 - acc: 0.9624 - val_loss: 0.1313 - val_acc: 0.9504\n",
      "Epoch 73/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0922 - acc: 0.9625 - val_loss: 0.1325 - val_acc: 0.9494\n",
      "Epoch 74/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0921 - acc: 0.9624 - val_loss: 0.1332 - val_acc: 0.9499\n",
      "Epoch 75/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0917 - acc: 0.9627 - val_loss: 0.1304 - val_acc: 0.9508\n",
      "Epoch 76/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0918 - acc: 0.9626 - val_loss: 0.1316 - val_acc: 0.9508\n",
      "Epoch 77/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0912 - acc: 0.9628 - val_loss: 0.1305 - val_acc: 0.9516\n",
      "Epoch 78/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0903 - acc: 0.9635 - val_loss: 0.1236 - val_acc: 0.9533\n",
      "Epoch 79/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0888 - acc: 0.9642 - val_loss: 0.1374 - val_acc: 0.9483\n",
      "Epoch 80/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0894 - acc: 0.9639 - val_loss: 0.1327 - val_acc: 0.9494\n",
      "Epoch 81/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0877 - acc: 0.9644 - val_loss: 0.1326 - val_acc: 0.9507\n",
      "Epoch 82/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0891 - acc: 0.9640 - val_loss: 0.1238 - val_acc: 0.9536\n",
      "Epoch 83/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0877 - acc: 0.9644 - val_loss: 0.1310 - val_acc: 0.9502\n",
      "Epoch 84/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0885 - acc: 0.9639 - val_loss: 0.1290 - val_acc: 0.9512\n",
      "Epoch 85/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0873 - acc: 0.9644 - val_loss: 0.1406 - val_acc: 0.9483\n",
      "Epoch 86/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0867 - acc: 0.9650 - val_loss: 0.1243 - val_acc: 0.9534\n",
      "Epoch 87/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0854 - acc: 0.9653 - val_loss: 0.1281 - val_acc: 0.9526\n",
      "Epoch 88/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0853 - acc: 0.9655 - val_loss: 0.1341 - val_acc: 0.9509\n",
      "Epoch 89/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0854 - acc: 0.9654 - val_loss: 0.1276 - val_acc: 0.9533\n",
      "Epoch 90/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0842 - acc: 0.9656 - val_loss: 0.1265 - val_acc: 0.9535\n",
      "Epoch 91/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0845 - acc: 0.9658 - val_loss: 0.1234 - val_acc: 0.9548\n",
      "Epoch 92/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0836 - acc: 0.9664 - val_loss: 0.1281 - val_acc: 0.9517\n",
      "Epoch 93/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0830 - acc: 0.9663 - val_loss: 0.1288 - val_acc: 0.9516\n",
      "Epoch 94/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0830 - acc: 0.9663 - val_loss: 0.1381 - val_acc: 0.9485\n",
      "Epoch 95/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0837 - acc: 0.9664 - val_loss: 0.1257 - val_acc: 0.9542\n",
      "Epoch 96/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0821 - acc: 0.9668 - val_loss: 0.1299 - val_acc: 0.9522\n",
      "Epoch 97/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0821 - acc: 0.9669 - val_loss: 0.1307 - val_acc: 0.9522\n",
      "Epoch 98/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0815 - acc: 0.9670 - val_loss: 0.1298 - val_acc: 0.9527\n",
      "Epoch 99/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0807 - acc: 0.9674 - val_loss: 0.1169 - val_acc: 0.9570\n",
      "Epoch 100/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0803 - acc: 0.9676 - val_loss: 0.1261 - val_acc: 0.9538\n",
      "Epoch 101/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0803 - acc: 0.9675 - val_loss: 0.1347 - val_acc: 0.9510\n",
      "Epoch 102/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0811 - acc: 0.9672 - val_loss: 0.1311 - val_acc: 0.9520\n",
      "Epoch 103/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0798 - acc: 0.9676 - val_loss: 0.1277 - val_acc: 0.9537\n",
      "Epoch 104/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0786 - acc: 0.9680 - val_loss: 0.1290 - val_acc: 0.9527\n",
      "Epoch 105/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0805 - acc: 0.9673 - val_loss: 0.1222 - val_acc: 0.9547\n",
      "Epoch 106/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0786 - acc: 0.9682 - val_loss: 0.1325 - val_acc: 0.9515\n",
      "Epoch 107/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0779 - acc: 0.9685 - val_loss: 0.1252 - val_acc: 0.9543\n",
      "Epoch 108/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0781 - acc: 0.9684 - val_loss: 0.1294 - val_acc: 0.9529\n",
      "Epoch 109/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0779 - acc: 0.9686 - val_loss: 0.1273 - val_acc: 0.9537\n",
      "Epoch 110/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0770 - acc: 0.9689 - val_loss: 0.1217 - val_acc: 0.9557\n",
      "Epoch 111/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0781 - acc: 0.9685 - val_loss: 0.1236 - val_acc: 0.9542\n",
      "Epoch 112/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0769 - acc: 0.9691 - val_loss: 0.1202 - val_acc: 0.9561\n",
      "Epoch 113/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0763 - acc: 0.9687 - val_loss: 0.1205 - val_acc: 0.9562\n",
      "Epoch 114/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0754 - acc: 0.9699 - val_loss: 0.1256 - val_acc: 0.9549\n",
      "Epoch 115/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0764 - acc: 0.9693 - val_loss: 0.1387 - val_acc: 0.9501\n",
      "Epoch 116/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0761 - acc: 0.9694 - val_loss: 0.1211 - val_acc: 0.9559\n",
      "Epoch 117/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0759 - acc: 0.9694 - val_loss: 0.1167 - val_acc: 0.9575\n",
      "Epoch 118/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0755 - acc: 0.9695 - val_loss: 0.1273 - val_acc: 0.9539\n",
      "Epoch 119/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0749 - acc: 0.9701 - val_loss: 0.1170 - val_acc: 0.9571\n",
      "Epoch 120/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0733 - acc: 0.9703 - val_loss: 0.1201 - val_acc: 0.9573\n",
      "Epoch 121/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0740 - acc: 0.9700 - val_loss: 0.1296 - val_acc: 0.9538\n",
      "Epoch 122/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0740 - acc: 0.9700 - val_loss: 0.1215 - val_acc: 0.9555\n",
      "Epoch 123/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0741 - acc: 0.9699 - val_loss: 0.1263 - val_acc: 0.9548\n",
      "Epoch 124/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0754 - acc: 0.9696 - val_loss: 0.1255 - val_acc: 0.9548\n",
      "Epoch 125/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0728 - acc: 0.9706 - val_loss: 0.1227 - val_acc: 0.9563\n",
      "Epoch 126/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0741 - acc: 0.9700 - val_loss: 0.1219 - val_acc: 0.9557\n",
      "Epoch 127/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0725 - acc: 0.9707 - val_loss: 0.1213 - val_acc: 0.9560\n",
      "Epoch 128/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0721 - acc: 0.9709 - val_loss: 0.1229 - val_acc: 0.9552\n",
      "Epoch 129/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0724 - acc: 0.9708 - val_loss: 0.1218 - val_acc: 0.9566\n",
      "Epoch 130/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0718 - acc: 0.9709 - val_loss: 0.1203 - val_acc: 0.9570\n",
      "Epoch 131/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0710 - acc: 0.9712 - val_loss: 0.1263 - val_acc: 0.9550\n",
      "Epoch 132/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0722 - acc: 0.9705 - val_loss: 0.1318 - val_acc: 0.9532\n",
      "Epoch 133/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0705 - acc: 0.9715 - val_loss: 0.1243 - val_acc: 0.9558\n",
      "Epoch 134/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0705 - acc: 0.9714 - val_loss: 0.1242 - val_acc: 0.9560\n",
      "Epoch 135/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0699 - acc: 0.9715 - val_loss: 0.1242 - val_acc: 0.9556\n",
      "Epoch 136/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0705 - acc: 0.9714 - val_loss: 0.1277 - val_acc: 0.9542\n",
      "Epoch 137/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0694 - acc: 0.9717 - val_loss: 0.1227 - val_acc: 0.9562\n",
      "Epoch 138/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0693 - acc: 0.9722 - val_loss: 0.1242 - val_acc: 0.9559\n",
      "Epoch 139/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0689 - acc: 0.9725 - val_loss: 0.1187 - val_acc: 0.9579\n",
      "Epoch 140/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0697 - acc: 0.9719 - val_loss: 0.1216 - val_acc: 0.9571\n",
      "Epoch 141/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0685 - acc: 0.9722 - val_loss: 0.1198 - val_acc: 0.9572\n",
      "Epoch 142/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0690 - acc: 0.9721 - val_loss: 0.1355 - val_acc: 0.9522\n",
      "Epoch 143/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0687 - acc: 0.9723 - val_loss: 0.1204 - val_acc: 0.9573\n",
      "Epoch 144/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0684 - acc: 0.9723 - val_loss: 0.1192 - val_acc: 0.9576\n",
      "Epoch 145/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0680 - acc: 0.9727 - val_loss: 0.1296 - val_acc: 0.9549\n",
      "Epoch 146/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0669 - acc: 0.9730 - val_loss: 0.1228 - val_acc: 0.9559\n",
      "Epoch 147/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0684 - acc: 0.9722 - val_loss: 0.1224 - val_acc: 0.9567\n",
      "Epoch 148/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0679 - acc: 0.9727 - val_loss: 0.1192 - val_acc: 0.9582\n",
      "Epoch 149/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0663 - acc: 0.9730 - val_loss: 0.1208 - val_acc: 0.9576\n",
      "Epoch 150/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0670 - acc: 0.9729 - val_loss: 0.1226 - val_acc: 0.9566\n",
      "Epoch 151/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0666 - acc: 0.9730 - val_loss: 0.1201 - val_acc: 0.9578\n",
      "Epoch 152/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0674 - acc: 0.9728 - val_loss: 0.1173 - val_acc: 0.9584\n",
      "Epoch 153/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0655 - acc: 0.9735 - val_loss: 0.1280 - val_acc: 0.9557\n",
      "Epoch 154/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0662 - acc: 0.9731 - val_loss: 0.1225 - val_acc: 0.9571\n",
      "Epoch 155/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0670 - acc: 0.9729 - val_loss: 0.1158 - val_acc: 0.9592\n",
      "Epoch 156/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0651 - acc: 0.9737 - val_loss: 0.1215 - val_acc: 0.9571\n",
      "Epoch 157/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0656 - acc: 0.9737 - val_loss: 0.1217 - val_acc: 0.9575\n",
      "Epoch 158/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0654 - acc: 0.9737 - val_loss: 0.1217 - val_acc: 0.9572\n",
      "Epoch 159/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0651 - acc: 0.9736 - val_loss: 0.1186 - val_acc: 0.9586\n",
      "Epoch 160/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0644 - acc: 0.9743 - val_loss: 0.1196 - val_acc: 0.9583\n",
      "Epoch 161/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0650 - acc: 0.9734 - val_loss: 0.1158 - val_acc: 0.9592\n",
      "Epoch 162/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0642 - acc: 0.9741 - val_loss: 0.1181 - val_acc: 0.9579\n",
      "Epoch 163/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0653 - acc: 0.9737 - val_loss: 0.1251 - val_acc: 0.9566\n",
      "Epoch 164/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0643 - acc: 0.9741 - val_loss: 0.1183 - val_acc: 0.9590\n",
      "Epoch 165/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0636 - acc: 0.9745 - val_loss: 0.1244 - val_acc: 0.9567\n",
      "Epoch 166/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0649 - acc: 0.9741 - val_loss: 0.1151 - val_acc: 0.9601\n",
      "Epoch 167/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0627 - acc: 0.9746 - val_loss: 0.1186 - val_acc: 0.9590\n",
      "Epoch 168/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0641 - acc: 0.9741 - val_loss: 0.1218 - val_acc: 0.9583\n",
      "Epoch 169/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0636 - acc: 0.9745 - val_loss: 0.1212 - val_acc: 0.9578\n",
      "Epoch 170/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0630 - acc: 0.9747 - val_loss: 0.1240 - val_acc: 0.9569\n",
      "Epoch 171/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0633 - acc: 0.9744 - val_loss: 0.1183 - val_acc: 0.9585\n",
      "Epoch 172/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0624 - acc: 0.9748 - val_loss: 0.1236 - val_acc: 0.9579\n",
      "Epoch 173/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0640 - acc: 0.9740 - val_loss: 0.1180 - val_acc: 0.9588\n",
      "Epoch 174/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0630 - acc: 0.9747 - val_loss: 0.1188 - val_acc: 0.9586\n",
      "Epoch 175/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0623 - acc: 0.9747 - val_loss: 0.1271 - val_acc: 0.9568\n",
      "Epoch 176/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0621 - acc: 0.9748 - val_loss: 0.1233 - val_acc: 0.9573\n",
      "Epoch 177/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0624 - acc: 0.9747 - val_loss: 0.1209 - val_acc: 0.9582\n",
      "Epoch 178/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0615 - acc: 0.9752 - val_loss: 0.1239 - val_acc: 0.9576\n",
      "Epoch 179/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0616 - acc: 0.9751 - val_loss: 0.1261 - val_acc: 0.9574\n",
      "Epoch 180/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0619 - acc: 0.9753 - val_loss: 0.1212 - val_acc: 0.9583\n",
      "Epoch 181/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0614 - acc: 0.9754 - val_loss: 0.1217 - val_acc: 0.9581\n",
      "Epoch 182/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0613 - acc: 0.9755 - val_loss: 0.1209 - val_acc: 0.9590\n",
      "Epoch 183/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0611 - acc: 0.9757 - val_loss: 0.1210 - val_acc: 0.9586\n",
      "Epoch 184/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0603 - acc: 0.9759 - val_loss: 0.1228 - val_acc: 0.9581\n",
      "Epoch 185/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0611 - acc: 0.9755 - val_loss: 0.1179 - val_acc: 0.9594\n",
      "Epoch 186/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0608 - acc: 0.9755 - val_loss: 0.1215 - val_acc: 0.9585\n",
      "Epoch 187/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0600 - acc: 0.9758 - val_loss: 0.1203 - val_acc: 0.9592\n",
      "Epoch 188/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0595 - acc: 0.9763 - val_loss: 0.1216 - val_acc: 0.9585\n",
      "Epoch 189/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0612 - acc: 0.9756 - val_loss: 0.1207 - val_acc: 0.9593\n",
      "Epoch 190/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0601 - acc: 0.9758 - val_loss: 0.1285 - val_acc: 0.9569\n",
      "Epoch 191/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0602 - acc: 0.9756 - val_loss: 0.1218 - val_acc: 0.9587\n",
      "Epoch 192/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0596 - acc: 0.9757 - val_loss: 0.1277 - val_acc: 0.9570\n",
      "Epoch 193/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0588 - acc: 0.9763 - val_loss: 0.1250 - val_acc: 0.9583\n",
      "Epoch 194/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0593 - acc: 0.9762 - val_loss: 0.1229 - val_acc: 0.9586\n",
      "Epoch 195/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0596 - acc: 0.9763 - val_loss: 0.1158 - val_acc: 0.9600\n",
      "Epoch 196/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0591 - acc: 0.9759 - val_loss: 0.1220 - val_acc: 0.9591\n",
      "Epoch 197/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0582 - acc: 0.9767 - val_loss: 0.1208 - val_acc: 0.9597\n",
      "Epoch 198/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0579 - acc: 0.9767 - val_loss: 0.1301 - val_acc: 0.9554\n",
      "Epoch 199/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0595 - acc: 0.9762 - val_loss: 0.1221 - val_acc: 0.9590\n",
      "Epoch 200/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0580 - acc: 0.9766 - val_loss: 0.1202 - val_acc: 0.9593\n",
      "Epoch 201/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0584 - acc: 0.9765 - val_loss: 0.1282 - val_acc: 0.9566\n",
      "Epoch 202/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0590 - acc: 0.9762 - val_loss: 0.1205 - val_acc: 0.9602\n",
      "Epoch 203/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0588 - acc: 0.9765 - val_loss: 0.1204 - val_acc: 0.9597\n",
      "Epoch 204/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0575 - acc: 0.9768 - val_loss: 0.1275 - val_acc: 0.9569\n",
      "Epoch 205/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0583 - acc: 0.9766 - val_loss: 0.1229 - val_acc: 0.9591\n",
      "Epoch 206/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0573 - acc: 0.9772 - val_loss: 0.1175 - val_acc: 0.9606\n",
      "Epoch 207/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0571 - acc: 0.9769 - val_loss: 0.1224 - val_acc: 0.9588\n",
      "Epoch 208/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0577 - acc: 0.9766 - val_loss: 0.1158 - val_acc: 0.9607\n",
      "Epoch 209/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0573 - acc: 0.9772 - val_loss: 0.1194 - val_acc: 0.9598\n",
      "Epoch 210/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0574 - acc: 0.9769 - val_loss: 0.1207 - val_acc: 0.9591\n",
      "Epoch 211/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0569 - acc: 0.9771 - val_loss: 0.1214 - val_acc: 0.9590\n",
      "Epoch 212/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0566 - acc: 0.9773 - val_loss: 0.1177 - val_acc: 0.9609\n",
      "Epoch 213/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0569 - acc: 0.9773 - val_loss: 0.1250 - val_acc: 0.9582\n",
      "Epoch 214/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0563 - acc: 0.9771 - val_loss: 0.1186 - val_acc: 0.9602\n",
      "Epoch 215/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0563 - acc: 0.9771 - val_loss: 0.1220 - val_acc: 0.9594\n",
      "Epoch 216/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0573 - acc: 0.9771 - val_loss: 0.1229 - val_acc: 0.9585\n",
      "Epoch 217/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0552 - acc: 0.9778 - val_loss: 0.1205 - val_acc: 0.9598\n",
      "Epoch 218/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0563 - acc: 0.9773 - val_loss: 0.1231 - val_acc: 0.9593\n",
      "Epoch 219/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0561 - acc: 0.9777 - val_loss: 0.1215 - val_acc: 0.9590\n",
      "Epoch 220/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0564 - acc: 0.9773 - val_loss: 0.1194 - val_acc: 0.9599\n",
      "Epoch 221/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0552 - acc: 0.9777 - val_loss: 0.1246 - val_acc: 0.9588\n",
      "Epoch 222/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0552 - acc: 0.9778 - val_loss: 0.1209 - val_acc: 0.9599\n",
      "Epoch 223/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0564 - acc: 0.9775 - val_loss: 0.1283 - val_acc: 0.9581\n",
      "Epoch 224/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0562 - acc: 0.9774 - val_loss: 0.1276 - val_acc: 0.9577\n",
      "Epoch 225/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0546 - acc: 0.9781 - val_loss: 0.1202 - val_acc: 0.9606\n",
      "Epoch 226/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0548 - acc: 0.9780 - val_loss: 0.1254 - val_acc: 0.9586\n",
      "Epoch 227/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0552 - acc: 0.9778 - val_loss: 0.1217 - val_acc: 0.9600\n",
      "Epoch 228/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0547 - acc: 0.9782 - val_loss: 0.1315 - val_acc: 0.9576\n",
      "Epoch 229/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0549 - acc: 0.9782 - val_loss: 0.1231 - val_acc: 0.9593\n",
      "Epoch 230/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0549 - acc: 0.9778 - val_loss: 0.1195 - val_acc: 0.9595\n",
      "Epoch 231/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0539 - acc: 0.9784 - val_loss: 0.1188 - val_acc: 0.9609\n",
      "Epoch 232/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0543 - acc: 0.9782 - val_loss: 0.1248 - val_acc: 0.9591\n",
      "Epoch 233/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0542 - acc: 0.9784 - val_loss: 0.1163 - val_acc: 0.9624\n",
      "Epoch 234/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0546 - acc: 0.9782 - val_loss: 0.1227 - val_acc: 0.9596\n",
      "Epoch 235/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0537 - acc: 0.9783 - val_loss: 0.1213 - val_acc: 0.9603\n",
      "Epoch 236/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0536 - acc: 0.9785 - val_loss: 0.1229 - val_acc: 0.9603\n",
      "Epoch 237/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0538 - acc: 0.9784 - val_loss: 0.1225 - val_acc: 0.9595\n",
      "Epoch 238/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0538 - acc: 0.9785 - val_loss: 0.1270 - val_acc: 0.9586\n",
      "Epoch 239/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0537 - acc: 0.9785 - val_loss: 0.1187 - val_acc: 0.9615\n",
      "Epoch 240/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0531 - acc: 0.9787 - val_loss: 0.1185 - val_acc: 0.9615\n",
      "Epoch 241/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0524 - acc: 0.9788 - val_loss: 0.1204 - val_acc: 0.9604\n",
      "Epoch 242/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0533 - acc: 0.9783 - val_loss: 0.1210 - val_acc: 0.9598\n",
      "Epoch 243/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0532 - acc: 0.9787 - val_loss: 0.1279 - val_acc: 0.9587\n",
      "Epoch 244/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0531 - acc: 0.9787 - val_loss: 0.1219 - val_acc: 0.9607\n",
      "Epoch 245/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0541 - acc: 0.9783 - val_loss: 0.1225 - val_acc: 0.9599\n",
      "Epoch 246/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0537 - acc: 0.9784 - val_loss: 0.1229 - val_acc: 0.9596\n",
      "Epoch 247/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0528 - acc: 0.9788 - val_loss: 0.1223 - val_acc: 0.9599\n",
      "Epoch 248/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0525 - acc: 0.9791 - val_loss: 0.1213 - val_acc: 0.9604\n",
      "Epoch 249/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0527 - acc: 0.9787 - val_loss: 0.1250 - val_acc: 0.9595\n",
      "Epoch 250/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0523 - acc: 0.9788 - val_loss: 0.1225 - val_acc: 0.9602\n",
      "Epoch 251/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0523 - acc: 0.9790 - val_loss: 0.1226 - val_acc: 0.9600\n",
      "Epoch 252/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0513 - acc: 0.9795 - val_loss: 0.1160 - val_acc: 0.9624\n",
      "Epoch 253/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0527 - acc: 0.9791 - val_loss: 0.1218 - val_acc: 0.9604\n",
      "Epoch 254/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0520 - acc: 0.9791 - val_loss: 0.1208 - val_acc: 0.9600\n",
      "Epoch 255/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0516 - acc: 0.9791 - val_loss: 0.1235 - val_acc: 0.9603\n",
      "Epoch 256/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0528 - acc: 0.9788 - val_loss: 0.1209 - val_acc: 0.9607\n",
      "Epoch 257/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0518 - acc: 0.9793 - val_loss: 0.1222 - val_acc: 0.9609\n",
      "Epoch 258/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0520 - acc: 0.9792 - val_loss: 0.1213 - val_acc: 0.9611\n",
      "Epoch 259/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0509 - acc: 0.9798 - val_loss: 0.1219 - val_acc: 0.9605\n",
      "Epoch 260/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0512 - acc: 0.9797 - val_loss: 0.1263 - val_acc: 0.9586\n",
      "Epoch 261/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0513 - acc: 0.9796 - val_loss: 0.1213 - val_acc: 0.9606\n",
      "Epoch 262/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0507 - acc: 0.9795 - val_loss: 0.1270 - val_acc: 0.9580\n",
      "Epoch 263/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0515 - acc: 0.9795 - val_loss: 0.1239 - val_acc: 0.9595\n",
      "Epoch 264/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0522 - acc: 0.9793 - val_loss: 0.1238 - val_acc: 0.9594\n",
      "Epoch 265/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0501 - acc: 0.9800 - val_loss: 0.1168 - val_acc: 0.9622\n",
      "Epoch 266/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0516 - acc: 0.9793 - val_loss: 0.1198 - val_acc: 0.9619\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XeclOW9///XZ2Z2tneWtoCgoCBF\nQATUaDCWry32lqiJnkTTjOYXk3NMNScnOWnG488ETfQbE5MYjSVGcqKxJNgFAQtSVJAiS1tYYHuZ\ncn3/uGaXBbeBOzu7O+/n48GDmXvumfncM7P3e67ruu9rzDmHiIgIQCDVBYiISP+hUBARkTYKBRER\naaNQEBGRNgoFERFpo1AQEZE2CgWRHjKz35nZD3q47gYzO+XDPo5IX1MoiIhIG4WCiIi0USjIoJLo\ntvm6mS03s3oz+42ZDTOzJ8ys1syeMbPiduufY2YrzWyPmT1rZpPa3TbDzF5L3O/PQNZ+z3W2mb2R\nuO/LZjbtIGu+xszWmtkuM1tgZiMTy83M/sfMKs2sxszeMrMpidvONLNVido2m9nXDuoFE9mPQkEG\nowuBU4HDgY8DTwDfBMrwn/nrAczscOB+4CuJ2x4H/mZmYTMLA38F/gCUAA8lHpfEfWcA9wCfA0qB\nXwMLzCzzQAo1s48BPwIuAUYAG4EHEjefBpyY2I7CxDpVidt+A3zOOZcPTAH+dSDPK9IZhYIMRr9w\nzm13zm0GXgAWO+ded841AY8CMxLrXQr83Tn3tHMuAtwCZAPHAXOBDOA251zEOfcwsKTdc1wL/No5\nt9g5F3PO3Qs0J+53IC4H7nHOveacawa+ARxrZmOBCJAPTATMObfaObc1cb8IcKSZFTjndjvnXjvA\n5xXpkEJBBqPt7S43dnA9L3F5JP6bOQDOuTiwCShP3LbZ7Ttj5MZ2lw8Bbkx0He0xsz3A6MT9DsT+\nNdThWwPlzrl/Ab8E5gOVZnaXmRUkVr0QOBPYaGbPmdmxB/i8Ih1SKEg624LfuQO+Dx+/Y98MbAXK\nE8tajWl3eRPwQ+dcUbt/Oc65+z9kDbn47qjNAM65251zRwNH4ruRvp5YvsQ5dy4wFN/N9eABPq9I\nhxQKks4eBM4ys5PNLAO4Ed8F9DLwChAFrjezDDO7AJjd7r53A583szmJAeFcMzvLzPIPsIb7gavN\nbHpiPOK/8d1dG8zsmMTjZwD1QBMQT4x5XG5mhYlurxog/iFeB5E2CgVJW865d4ArgF8AO/GD0h93\nzrU451qAC4CrgF348Ye/tLvvUuAafPfObmBtYt0DreEZ4DvAI/jWyWHAZYmbC/DhsxvfxVQF/Cxx\n25XABjOrAT6PH5sQ+dBMP7IjIiKt1FIQEZE2CgUREWmjUBARkTZJCwUzuydxev6KTm43M7s9cXr/\ncjObmaxaRESkZ0JJfOzf4Y/M+H0nt58BTEj8mwPcmfi/S0OGDHFjx47tnQpFRNLEsmXLdjrnyrpb\nL2mh4Jx7PnGqfmfOBX6fOGN0kZkVmdmIdqfxd2js2LEsXbq0FysVERn8zGxj92uldkyhHH9WaKuK\nxLIPMLNrzWypmS3dsWNHnxQnIpKOBsRAs3PuLufcLOfcrLKybls/IiJykFIZCpvx88y0GpVYJiIi\nKZLMgebuLACuM7MH8APM1d2NJ3QmEolQUVFBU1NTrxaYrrKyshg1ahQZGRmpLkVE+ljSQsHM7gfm\nAUPMrAK4GT8/Pc65X+F/0ORM/JwxDcDVB/tcFRUV5OfnM3bsWPad1FIOlHOOqqoqKioqGDduXKrL\nEZE+lsyjjz7Rze0O+FJvPFdTU5MCoZeYGaWlpWhAXyQ9DYiB5p5QIPQevZYi6WvQhEK3muugZis4\nTTsvItKZ9AmFSD3UbYMkTBW+Z88e7rjjjgO+35lnnsmePXt6vR4RkYOVPqGQRJ2FQjQa7fJ+jz/+\nOEVFRckqS0TkgKXykNQ+1tpP3vsthZtuuon33nuP6dOnk5GRQVZWFsXFxbz99tu8++67nHfeeWza\ntImmpiZuuOEGrr32WmDvlB11dXWcccYZfOQjH+Hll1+mvLycxx57jOzs7F6vVUSkK4MuFP7zbytZ\ntaXmgzfEIhBrhvCr7A2InjlyZAE3f3xyp7f/+Mc/ZsWKFbzxxhs8++yznHXWWaxYsaLtkM577rmH\nkpISGhsbOeaYY7jwwgspLS3d5zHWrFnD/fffz913380ll1zCI488whVXXHFAdYqIfFiDLhQ61YcH\n1MyePXufY/xvv/12Hn30UQA2bdrEmjVrPhAK48aNY/r06QAcffTRbNiwoc/qFRFpNehCodNv9PU7\noLoChk2BYHLP1M3NzW27/Oyzz/LMM8/wyiuvkJOTw7x58zo88zozM7PtcjAYpLGxMak1ioh0JI0G\nmpM3ppCfn09tbW2Ht1VXV1NcXExOTg5vv/02ixYt6vXnFxHpLYOupdCt3s8ESktLOf7445kyZQrZ\n2dkMGzas7bbTTz+dX/3qV0yaNIkjjjiCuXPn9n4BIiK9xFwSjttPplmzZrn9f2Rn9erVTJo0qes7\n1ldB9fsw9EgIZXa9rvTsNRWRAcPMljnnZnW3Xvp0H2nmBhGRbqVPKCRxTEFEZLBIo1BIUCaIiHQq\n/UJBREQ6lT6hYOo+EhHpTvqEgkaaRUS6lUahkNAPDsHNy8sDYMuWLVx00UUdrjNv3jz2P/R2f7fd\ndhsNDQ1t1zUVt4h8WGkUCv2vpTBy5Egefvjhg77//qGgqbhF5MNKn1Boy4TkTJ09f/78tuvf+973\n+MEPfsDJJ5/MzJkzmTp1Ko899tgH7rdhwwamTJkCQGNjI5dddhmTJk3i/PPP32fuoy984QvMmjWL\nyZMnc/PNNwN+kr0tW7Zw0kkncdJJJwF+Ku6dO3cCcOuttzJlyhSmTJnCbbfd1vZ8kyZN4pprrmHy\n5MmcdtppmmNJRPYx+Ka5eOIm2PbWB5fHoxBthIwcsOCBPebwqXDGjzu9+dJLL+UrX/kKX/rSlwB4\n8MEHefLJJ7n++uspKChg586dzJ07l3POOafT3z++8847ycnJYfXq1SxfvpyZM2e23fbDH/6QkpIS\nYrEYJ598MsuXL+f666/n1ltvZeHChQwZMmSfx1q2bBm//e1vWbx4Mc455syZw0c/+lGKi4s1RbeI\ndCl9WgpJNGPGDCorK9myZQtvvvkmxcXFDB8+nG9+85tMmzaNU045hc2bN7N9+/ZOH+P5559v2zlP\nmzaNadOmtd324IMPMnPmTGbMmMHKlStZtWpVl/W8+OKLnH/++eTm5pKXl8cFF1zACy+8AGiKbhHp\n2uBrKXT2jb6pBna9B6UTIDOv15/24osv5uGHH2bbtm1ceuml3HfffezYsYNly5aRkZHB2LFjO5wy\nuzvr16/nlltuYcmSJRQXF3PVVVcd1OO00hTdItKV9GkpJPk8hUsvvZQHHniAhx9+mIsvvpjq6mqG\nDh1KRkYGCxcuZOPGjV3e/8QTT+RPf/oTACtWrGD58uUA1NTUkJubS2FhIdu3b+eJJ55ou09nU3af\ncMIJ/PWvf6WhoYH6+noeffRRTjjhhF7cWhEZrAZfSyFFJk+eTG1tLeXl5YwYMYLLL7+cj3/840yd\nOpVZs2YxceLELu//hS98gauvvppJkyYxadIkjj76aACOOuooZsyYwcSJExk9ejTHH398232uvfZa\nTj/9dEaOHMnChQvbls+cOZOrrrqK2bNnA/DZz36WGTNmqKtIRLqVPlNnN9dB1RooOQyyCpJY4eCg\nqbNFBhdNnS0iIgcsfUKhk0NBRURkr0ETCj3vBhtY3WWpMNC6FEWk9wyKUMjKyqKqqqqbnVmipaD9\nXZecc1RVVZGVlZXqUkQkBQbF0UejRo2ioqKCHTt2dL5SrAVqK2Gng4zsvituAMrKymLUqFGpLkNE\nUmBQhEJGRgbjxo3reqVtK+DhS+CS38Okc/umMBGRAWZQdB/1SCAx35GLp7YOEZF+LH1CwRKbGo+l\ntg4RkX4sqaFgZqeb2TtmttbMburg9jFmttDMXjez5WZ2ZvKKaW0paKRZRKQzSQsFMwsC84EzgCOB\nT5jZkfut9m3gQefcDOAy4I5k1dN2noJTS0FEpDPJbCnMBtY659Y551qAB4D9R3gd0DrnRCGwJWnV\naExBRKRbyQyFcmBTu+sViWXtfQ+4wswqgMeBL3f0QGZ2rZktNbOlXR522hWNKYiIdCvVA82fAH7n\nnBsFnAn8wcw+UJNz7i7n3Czn3KyysrKDeyZTS0FEpDvJDIXNwOh210cllrX3GeBBAOfcK0AWMIRk\naM0ajSmIiHQqmaGwBJhgZuPMLIwfSF6w3zrvAycDmNkkfCgcZP9QN9pCQS0FEZHOJC0UnHNR4Drg\nSWA1/iijlWb2fTM7J7HajcA1ZvYmcD9wlUvWbGwBHZIqItKdpE5z4Zx7HD+A3H7Zd9tdXgUcv//9\nkkIDzSIi3Ur1QHPfUfeRiEi30jAU1FIQEelM+oSCTl4TEelW+oSCxhRERLqVRqGgloKISHfSKBQ0\n0Cwi0p30CQWNKYiIdCt9QqF16myNKYiIdCp9QgH8uIJaCiIinUqzUAjoPAURkS6kVygE1FIQEelK\neoWCBTSmICLShfQLBc2SKiLSqTQLBXUfiYh0Jc1CwTTQLCLShfQKBQ00i4h0Kb1CQQPNIiJdSrNQ\nUEtBRKQraRYKOnlNRKQr6RUKgaAOSRUR6UJ6hYKZxhRERLqQZqGgMQURka6kWShoTEFEpCvpFQo6\nT0FEpEvpFQo6T0FEpEtpFgpqKYiIdCXNQiGgUBAR6UKahYIpFEREupBeoRAIakxBRKQL6RUK6j4S\nEelSmoWCBppFRLqSNqHwr7e3s66qgbi6j0REOpU2ofBeZT076qMKBRGRLqRNKIRDAeIugFMoiIh0\nKm1CISMYIIbh4hpTEBHpTFJDwcxON7N3zGytmd3UyTqXmNkqM1tpZn9KVi3hUIA4aimIiHQllKwH\nNrMgMB84FagAlpjZAufcqnbrTAC+ARzvnNttZkOTVY9CQUSke8lsKcwG1jrn1jnnWoAHgHP3W+ca\nYL5zbjeAc64yWcWEgwHimEJBRKQLyQyFcmBTu+sViWXtHQ4cbmYvmdkiMzu9owcys2vNbKmZLd2x\nY8dBFZMZChAjgNN5CiIinUr1QHMImADMAz4B3G1mRfuv5Jy7yzk3yzk3q6ys7KCeKBwK4NRSEBHp\nUjJDYTMwut31UYll7VUAC5xzEefceuBdfEj0unCipYCOPhIR6VQyQ2EJMMHMxplZGLgMWLDfOn/F\ntxIwsyH47qR1ySimdUxBP8cpItK5pIWCcy4KXAc8CawGHnTOrTSz75vZOYnVngSqzGwVsBD4unOu\nKhn1ZAQDOAI6T0FEpAtJOyQVwDn3OPD4fsu+2+6yA76a+JdUbd1HaimIiHQq1QPNfSYz1Np9pJaC\niEhn0iYUWk9eUyiIiHQufUIhGCDu1FIQEelK+oRC25iCQkFEpDNpFQpxDNPJayIinUqbUAgFjLgF\nAJfqUkRE+q20CQUzwyyI6ZBUEZFOpU0oAGABTGMKIiKd6lEomNkNZlZg3m/M7DUzOy3ZxfU2CwQV\nCiIiXehpS+HfnHM1wGlAMXAl8OOkVZUsgQCgUBAR6UxPQ8ES/58J/ME5t7LdsgHDAkECaimIiHSq\np6GwzMyewofCk2aWzwD8ym0WxAZe2SIifaanE+J9BpgOrHPONZhZCXB18spKDgtooFlEpCs9bSkc\nC7zjnNtjZlcA3waqk1dWcgQCAQI6T0FEpFM9DYU7gQYzOwq4EXgP+H3SqkqWQIgAcXAKBhGRjvQ0\nFKKJ3z44F/ilc24+kJ+8spIjGEhsrkJBRKRDPR1TqDWzb+APRT3BzAJARvLKSg4LBP0FFyfdztsT\nEemJnu4ZLwWa8ecrbANGAT9LWlVJEmgLBU11ISLSkR6FQiII7gMKzexsoMk5N+DGFCzYvqUgIiL7\n6+k0F5cArwIXA5cAi83somQWlgxtLQVNny0i0qGejil8CzjGOVcJYGZlwDPAw8kqLBkCaimIiHSp\np2MKgdZASKg6gPv2GxpTEBHpWk9bCv8wsyeB+xPXLwUeT05JybM3FHRIqohIR3oUCs65r5vZhcDx\niUV3OeceTV5ZyRFMdB+5eHTgzeYnItIHetpSwDn3CPBIEmtJutYxhUg0RjjFtYiI9EddhoKZ1dLx\njxob4JxzBUmpKklaWwrRaEShICLSgS5DwTk34Kay6Eog6De3JRIjJ8W1iIj0RwPuCKIPI9jWfRRJ\ncSUiIv1TeoVCYO+YgoiIfFB6hUIoEQoRtRRERDqSXqGgloKISJfSKhSyM/0xR3WNzSmuRESkf0qr\nUMjL9qFQ3aBQEBHpSJqFQiYA1WopiIh0KKmhYGanm9k7ZrbWzG7qYr0LzcyZ2axk1pOXnQVAXV1D\nMp9GRGTASloomFkQmA+cARwJfMLMjuxgvXzgBmBxsmppFcwrAyBSV9nNmiIi6SmZLYXZwFrn3Drn\nXAvwAHBuB+v9F/AToCmJtXi5Q/z/dTuT/lQiIgNRMkOhHNjU7npFYlkbM5sJjHbO/b2rBzKza81s\nqZkt3bFjx8FXlDsUgGCjQkFEpCMpG2g2swBwK3Bjd+s65+5yzs1yzs0qKys7+CcN59JimYSbqg7+\nMUREBrFkhsJmYHS766MSy1rlA1OAZ81sAzAXWJDUwWYz6kPF5ER2Je0pREQGsmSGwhJggpmNM7Mw\ncBmwoPVG51y1c26Ic26sc24ssAg4xzm3NIk10ZRZSkFsN9GYfqdZRGR/SQsF51wUuA54ElgNPOic\nW2lm3zezc5L1vN2JZZdSajXsbtD8RyIi++vxL68dDOfc4+z3W87Oue92su68ZNbSKp4zlCG2nKr6\nZsryM/viKUVEBoy0OqMZIJhfRgm1VNUm/whYEZGBJu1CIVw4jAyLsWfXhzi0VURkkEq7UCgYMhKA\n6h1bUlyJiEj/k3ahkFk4HIC6XQoFEZH9pV0okJuY/6h6a4oLERHpf9IvFAr9TBuBWoWCiMj+0i8U\nsgppCuaS27iNeNyluhoRkX4l/UIBaMwewXB2sKNOP7YjItJeWoZCvKCckVZFxW792I6ISHtpGQqh\notGMtJ1U7G5MdSkiIv1KWoZCztCxlFgdWyo1W6qISHtpGQoZxWMAqN6+IbWFiIj0M2kZChSOAqC5\nakNq6xAR6WfSOhSsuiLFhYiI9C/pGQoFI2kKFfLF+J+ofee5VFcjItJvpGcoBDN4/WN/JEoQ9/wt\nqa5GRKTfSM9QAIZOmMkLsamEd6wApzObRUQgjUNhdHEOK9w4slp2QY1mTBURgTQOhXAoQFXBkf7K\n1jdSW4yISD+RtqEAUDB2BjEMt0WhICICaR4KM8eXszZeTv2GpakuRUSkX0jrUJgzroTX4hMIb3kV\nYpFUlyMiknJpHQqjirN5K2sW4WgdVCxJdTkiIimX1qFgZgTHzyNKgNi7z6S6HBGRlEvrUAA4cdoE\nXotPoGHVE6kuRUQk5dI+FE6YMIRnmEv+7lWw/oVUlyMiklJpHwpZGUG2jb+M7ZTgnvlPnd0sImkt\n7UMB4PQZ47glchG2eQks/nWqyxERSRmFAvCxiUP5R8bJrMg7Dp7+Duxan+qSRERSQqGA70I6e1o5\nN1R/EmIt8M7jqS5JRCQlFAoJl88Zw3uREnbljIO1OjxVRNKTQiFhSnkhJ0wYwj8aj8RtfBkijaku\nSUSkzykU2vnyxybwj+YpWLQJ/nINVL2X6pJERPqUQqGd2eNKyJt4Eo+4k4iv/Rc88lmIx1NdlohI\nn0lqKJjZ6Wb2jpmtNbObOrj9q2a2ysyWm9k/zeyQZNbTEzeddRTfiH6OB8quhy2vwQs/h/qqVJcl\nItInkhYKZhYE5gNnAEcCnzCzI/db7XVglnNuGvAw8NNk1dNTY0pz+MwJ4/jWusnUDZsNC38A/zMZ\nnv1xqksTEUm6ZLYUZgNrnXPrnHMtwAPAue1XcM4tdM41JK4uAkYlsZ4e+9JJ4xlWkMMZe/6dPVc8\nBRNOgWd/BO8vTnVpIiJJlcxQKAc2tbtekVjWmc8AHc5KZ2bXmtlSM1u6Y8eOXiyxY3mZIe761NHs\naIjymadjNJ19B+QMgae+Df/8Prz8S3/mc83WpNciItKX+sVAs5ldAcwCftbR7c65u5xzs5xzs8rK\nyvqkpmmjirj1kuks27ibb/zvOtxx10PFq/DCrfDUt+CJf4f7LtaP84jIoJLMUNgMjG53fVRi2T7M\n7BTgW8A5zrnmJNZzwM6cOoIbTz2cR1/fzB0tZ8DnX4RvV8J/bIQLfwPb34JFd6S6TBGRXpPMUFgC\nTDCzcWYWBi4DFrRfwcxmAL/GB0JlEms5aNd9bDznzyjnZ0+t4ffr8yEUhuwimHoRHDoPFt8FTdXw\n/iJoqoHH/x1qt8MfLvCtChGRASSUrAd2zkXN7DrgSSAI3OOcW2lm3weWOucW4LuL8oCHzAzgfefc\nOcmq6WCYGT+5cBp1zVG++9hKttc0ceOpRxAIGEy7DP76ebjndKhcBRNOgzVPQXMtvPdP2L4Sjr8B\nAsFUb4aISI+YG2C/HzBr1iy3dOnSPn/elmic7z62ggeWbOLaEw/lm2dOgsY98LPxEO9iXOFTj/kW\nhYhICpnZMufcrO7W6xcDzQNBOBTgRxdM5VPHHsJdz6/j9n+uwWUVwoRTIasQzr8LisbAzE/5O5Qc\nCuF8+Od/wer//eCP98TjOltaRPqdpHUfDUZmxs0fn0xdc5Rbn36XVVtq+Ma8n3DIaREoPQymXQK7\nN8Brv4eJZ0PhKH9+w58vhzHH+VZDKAyxKNw9D4ZPg/Pu8HMsPf8zCIbh1P+E7OK+2aB4DKLNEM7p\nm+cTkX5PoXCAggHjlouO4rCyPOYvXMszq7dz8axRfPaEOg4ry4OScX7nP2K6H5A+5rOw+Ffw5Dfh\nzT9BdQW4OGx7y/+bfY0PkbcegngUcsvg5O/0zcY891P/3F95C4L6KIiIxhQ+lB21zfziX2t4YMkm\norE4n5wzhq+eegQlueF9V4zHYf4xsGudDwSAYVOgdisMORx2vgvjPupDYd2zfiedXZT8DfjFLKha\nA9f8C8qPTv7ziUjKaEyhD5TlZ/L9c6fw8k0f41PHjuX+Vzcx72cL+e1L62mJthsvCARgzud9IBx3\nvf937nw49fvw/ivQUOUPcT3xa/7IpT9f4cchdq458KLaj1N0Ffi71vlAAFj//IE/j4gMSmop9KJ3\nt9fy/b+t4sW1OynJDXPe9HKumDuGQ8vy/M5602IYPceHBPid9oOfgo0vw1dXQSgTlj8If/3i3iOa\nDj8djv8K5A7xXVDls/xJc5MvgLEfgSW/gZoKv05WIdw1D6Zf7rum4lE4+bv+l+SOvwG2vA4jjoJg\nBiz6FfzjP/z0HSOmwZWPpux1E5Hk62lLQaHQy5xzvLh2J/e/+j5Pr9oOwPkzypk4vIALjx5FYXbG\nvneIRfxJb7mle5dVb4b6Snj3KXj1LmjYCZkFflA41gwW8Nfzh8OOdyCU5QNg5HSoWLLv4wdC/rZp\nl8LyP8Psz8HpP4a7T4JIAxz2MVh2L/zHBsjISu6Ls+Zp321WMCK5zyMiH6BQ6Acqa5v4yRPv8NSq\nbdQ2RcnLDHHlsYfwmY+MY0heZs8eJNIIz98Cqxf4qTVyh0Bdpd+puzhc/oj/pv/Q1bDxRZj1b36i\nvhFHQfUmeG+h39nvWufDxDmYdTUsvQfOu9MfIXXvx+GMn8Gca/1z1u/06+aU+Ost9fDq3TDjyn3D\nqyPP/hiyS/wAuj8h0dvxrh9XOeqTcP6dfplz+67T6vmf+fUvvLvj54hFfKBlFfbsNdzfK3f47f/i\nor4fYG+qhl3rfYCL9CGFQj+zaksN859dy+NvbSUzFODYQ0sZU5LD+GH5nD11BMX7D05359W7fStg\n1tX+erQZVvwFjjwHwrl+mXO+lfDuP+Dhf4ML7oaF/w0734FhU+Fzz/md/+/O9uMLn3/Jt0p+d7bf\n6Y6Z67uXMvNh6W9gwv+Boy6DdQv9TjurECafD3Xb/OOVHga3J3Z2o2b7VsiJX4O1/4QVj8BbD0JW\nEXx9rZ9x9t0n4erHoWDk3u3auQbumOvrvvZZ3yLavQGKx/rHB3joKn/fU74Hx1yztztu0Z3+XJGJ\nZ3X+usWicNtUqN0CV/3dd8HtLx7f+5jdcQ5e/6N/nJJx3a//9xt9y+yrqyGv7MCea7BoqoGsglRX\nAVvf9J+zNDnIQqHQT63bUcc9L63n1fW72FrdRG1TlJxwkAtnjiIrI8BFR4/miOH5vf/EzbV+5x6P\n+S6mojF7d8abXoXfngEW9GMZuUNh3Imw422oXO2XFY/1O2fwYTB8mr+9vt1U5oVjfOvk2C/Buuf8\n2MfoubBpkb+9dDxUrYXxp/hxDgtA2SQ45jMw6Rz/g0bv/MMHkov7cKvbvvfxz77N1/3HC6DoENiz\nEYYc4VtTR38K/vUDCGbC+JNhyxsw7WI46dv+3JBWbz8OD3zCXz72Ojj1v2DxnXDkub7V9PjX/TxW\nn14Am5ZA3lDf6uqoRQPw9M3w0m2+jmuf9ed8rH8e3nkC5t20b2smFoWfH+GD98xb/Lksd82DOZ+D\nE77a+Xv34v9A4Wh/MEJPxKIH3gLa9paflmXqJT6k4nHYvAyGToLMvJ49xsZX/Gtx+o/8WNfoOTDp\n4/u+duuehT9eCGfdCkd/2k9B7xzM/byfM2zJ/4W5X9jbSu1MPNbz6WPWPQcv3+5PKD35ZnAxv/z2\nGRBtgeuW7O3S7Kz12lQNqxb49yAje+/yDS/69/rkm/f9nB2siqW+zqq1ULPF/1300pcGhcIAsXJL\nNfMXruXJldsJGERijsxQgLmHlvLJOWM4YcIQcsJ90MWxc41vfWQVwozLfQiA/0a++Ne+q2n1Av9t\nfdw8/0Ftqff3KxoDz9zsz3k47GS48i97T9Db9pbf0ZSOh+mfgPlzIVLvz9+YcBo8dp0fP7Eg4ODw\nM3wX2Nqn/fkdx9/g13vqO9C42+8IXNx3/ax4xHcD1VX6gMgq8icANlT5UFu30LdWMvP9H9fIGfCn\nS3zdQyb4P7qPfQce+rTfeZ2dAUobAAATSklEQVRwo99Jgz+BsHG3v1x+NBxxBhSPg5rNPghHz4Ud\nq30QHXayn+sqq9CHUn1ibsfS8T74Pvoffixlwwvw+Nd8jSNnwvCpsORuwHx32/hT/JQo7y30gTr1\nYmjY5bsKAc7/NRx5nt+xRhK/TTX+lH2/db/8S3/+yVm3wMu/8Nt3+Gn+BMntK/zOZu2//JFvi+/0\nLb/Rc2D+HL9t4070z7HoTt96HDYVPvrv/iCIgpGwZ5M/YOK4L/vXLxCCaKOf8mXB9f6gh1AWRJt8\nPSWH+YMdxp3ow/K5n0LlSgjn+Zbe41/z6132J9+tt/FFKJsIV/7V/xxu4SgfyvGYr71xt/+8/eY0\n/57M/BSs/pv/xj/qGN8qHTbZv+8Lvuw/K9tX+Drrd/oW3aZX/WtWv8O/F+M+Chf/zn9WH/o0nPFT\niLX4z1Hr38bGl/yXoOO+DKf9wHdhbl8Bvz8PmvbAEWf697hxlz/XqOgQeO1eX/OR5/rXbu4Xfesk\n0ui/FMUi/v2u2QwF5f71WXyn/9ur3e5f16JDoOwIOO9X/j0I53b+BaUbCoUBJh53VDdGeGjZJrZW\nN/G3N7eys66Z3HCQeROHMjQ/kykjCzl18jAKsjK6f8C+FmmCp78D0z/pd77gWxmv/9HvmFoHsVct\n8DvKSWf76875b+Yv/f/+D3zimX55tBl2b4Syw/315Q/BXz7rL1/+sJ9epNWe9/24yLHXwaGJAfQR\n0+DF23xYZRX6b3rgpx65/EE/geHfb/RB0lzjdx5FY6ClwYfQWw/5HauL+53rrnV7ny8Y9jsN8EeB\nXfh/fdfdxpcA53dkpeNh4Y/8ens27j0/JZznW1LP/QQwfwBAfaU/Ai3a5EMllphBPhCC/JG+vuFT\n/es0fKrfWbbKHepbMyOn+7PmW3eEJP6uC8f49+TFW/fW3H6nHcryrb6KJXD89b5rq2mPb8FNvRCe\n/7nfOe0vp3TvTrOVBfzh1ovugNN+6M+1eel2311ZNMbvIMHf9sLP/Q60eKzf5p3v+NvmftF/uQiG\n/e1ZRf41evMBaG73HrbUtj5pYidpvgUQyNh75F4gBKFs/3p87nl483544RYfOjVbfaiUH+1/GyV3\niP8Mt9Tu9/j4z09Grt85r3/Ofz42vuLryUx8iVp05951m6r9659VBKNmwYaX/Gs4fKoPntbaLLD3\nPWk1+QIfGHlDfYtp3bP+gJOhk3wIn/ETmHLBB9+PHlAoDHCRWJwl63fxl9c3s2hdFbvqW2hoiZEZ\nClCcE2Z4YRZTywuZOqqQqeWFTBiaRyg4iPumo81w2zT/R3bZfR+8vbNmf12l34G99bDfyRx2sg+a\naAv8/avw+h98t9TCH0JGDpz7SzjkI37H2L4Lo6Xeh09mgd+BbH7Nf8ObdE7X3QbNdfC3632XQOEo\n/y1y/Cm+9VW5Gk652R9FFovA0t/6ExkPPx2GjPff+l+7F076lu9quWue78I76+e+xvodPkxjLb4b\nw8X8t9XTf+xbMEec4UMRfKtjzhf8N81Igw/EuV+EZb/1J1HO+gwcd52vd/sKf+hzMLT3SLhos+/K\nyy4GDBZc58eThhzhv8HmlPiAGTPX71xbvwQ07IJfneDHnc6dD3nD/Lfj5hrf7TJyht+Rvv13yB/h\nvxRULIP7L/Oti7XP+Pdi8gX+i0BznQ/UU//Td29ZED72Lf/te/NrvoVQtdYfaXfoPL8jbq71LcNY\nBFY95h8nGPYBEgz5QF7yG/8YR13qx6xGzfZT0Fhg71hR4x549PM+5IdP8/Udcpy/vbnWf34CQb/9\nu9f797V1yppnfwLP/rdvCc++xn9pCGb4LxvFY6F2m9/+wnL/mc3I9i1c8K3h//3/YMyxvmuu9UvX\nAVIoDDLxuGP55moWvLGFuuYIG6saWLmlhrrmKACZoQATRxQwpiSHEYVZDC/IYvLIAo4ZW+Kn+R4M\nGnb5P7zeOnTWOT/tSNFo/wefkdM7/cK9KdLkd7pmfge9ewOMPf6D621f6Xcsh87bt6992e/8eMT4\nk/um3o7s3uh3dKOP6fl9Wgfgt6/yO9wxc/be1tkXgN5Sudq3bFoP2OgN8bjvPhw95+A+v3s2+S8V\nH2K7FQppIB53rK+qZ8Xmat6qqGbV1hq27Glka3UTzYkzqnPCQcoSXU9DCzIZkpfJnHElHH1IMZbM\nPywR6Vd6GgqaBW0ACwSMw8ryOKwsj3Onl7ctd86xq76FF9fu5M1N1WyraWTFlmp2vtNMfYs/8iIc\nDFCaF6Ys3wfFsIIsZh1SzNCCTEpzMxldkk1+fxy7EJGkUkshzdQ0RXh65XberaxlZ20LO+ua2VnX\nTMXuRqob9/2xoOKcDA4ty2NqeSGZoQAYTByez5xxpYwsyu7kGUSkP1JLQTpUkJXBhUeP+sDyeNyx\nprKOmqYIlTXNvL+rgU27G3hnWy0PLd1EzDlicUck5r9E5ISDZIYCZIaC5ISDlBdnM6Ykh5ljiinI\nzqAwO4PRJdlU7G5k0ogC9jS0MDQ/i3BoEA+GiwwCCgUBfFdUdyfNxeOO1dtqWLRuF1v3NNISi9Mc\niVPXHKVidwN/e3ML9y1+v9P7Z4YCjBuSy8Th+YwfmoeZkRkKtD3vkLxMxpTkkJsZoiUapyUWJy9T\nH1GRvqS/OOmxQMCYPLKQySM7nnMoHnes2lpDNO7YtKuB7TVNjC7J4d1ttZTkhVm/o54NVfW8uLaK\nv76xpdPnCYcCRGJ+oHzi8AJyE4Pl5UXZjCzKpiA7g+rGCDWNEY4aXcjhw/J5/f09jC3NZUp5gQbQ\nRT4EjSlIn3PO0RKLYxi1TRHe3V5HMGBU1jaxsaqBmqYIWaEgDnhz0x5aonG21zaxZU8jTZGuf9e6\nICvUNo9UZijAsIIsNu1qYHRJDhOH5zN2SC7OQWVNEwXZGRTlhCnKzqA4N4MJw/IpyMogGosTTZxM\n+F5lHTPGFJOVEVDYyICmMQXpt3y3kT+WvjQvk2N7OGNs61FV9c0x8rJCZGcEeWPTHt7eVsPU8kLW\nVtaxcksNNU0RDKhvibG12o9pbKhq4N5XNu7740f7CQWM7HCQ2qboPsuLczJoicYpzg1z1OgiskJB\nYvE4I4uyGVaQxcaqBg4pzWH80DxyM0PkhIM0tsSYMCyvbYqSpkiMUMAG9wmGMiiopSBpIx53bKn2\nUzaMLMymtjlKdUOEPY0tVNW18OqGXdQ3RxmSl0koaGRnBBlRmM3f39pKYXaI7TXNvFdZR3M0jhls\nq24iGneEQ4FOwyYcCpAbDrKnMUJmKMCQvEyaInEKskLkZ2dQlJ3BoWW5/uivhgiHluUydVQhexoi\nhIMBdtY1M2lEAcW5Yd6vqicQMI49tJTmaJysjCC54WDbz786IGDGrvoWhuSFMTOcc2rhCKCT10SS\nLhqLU1XfwpC8TN7f1UBljZ/1tiESIxwM8N4OfzRXQ3OMktwwNU0Rdte3tLVGqhsj7G5oYc32Osry\nMxlZmM3qbTX7tFSCASMW7/pvNBgw4s4RMCMcDNAYiZEbDjK6JIcNVfUcOiSPopwMdtQ2M7wwi+Kc\nMC3ROMMKMlmxpYaAwfiheYwqziEcDNASiycG/IOYGQaEAgEygkZuZojhhVlU1jQTChrD8rMoyA5R\n0xRlW3UTh5blEjAjOFjOoh9EFAoiA0Q87jDz3WqRWJztNU2U5ma2HX31ZsUeItE4h5TmUt0Y4Y1N\nu8nP8l1atc1Rtlc3EQgYsXichpYYo4tzeH9XA+/vamBkURbLK6qJxByji7PZXtvMnoYWQgFj855G\nDh+WT2YowNrKOnY3RLovtgP5mSEaIzGi7cJrWEEmo4tziCe6/BwwvCCLEYVZ5Gdl8Pqm3YwqyqEs\nP5P6ligNzTECARhflsfuhgjlxdmU5oapa44SjTnysnw3XGF2BgVZGUTicfIzQ+RmhqisbaYpEuP4\n8UPYVt1EMGA0R2MML8iiKMeH8ftVDRRk+cOk07XlpFAQkQPSFInREosTChgbqxpoicaJO0fcQSzu\niMbiVDdG2FrdxPDCLGJxx/aaJip2N5ITDjJ+aB4bqxpwwJY9jby/q4FQwCjJ9V1Z26r9FCy76luY\nUl7I5t2NNLREyQmHyMsM0RSNsbGqgfys0AfGdQ5WbjhIQyRG625uZGEWBdkZOAcOf+5NNO7ICPrD\npeNxR0NLjIZIjOKcDEYUZpMRNDKCAUJBIyMQICMYYEh+mMaWGLvqW9qOllu/s56sULDtPJ3Wf3lZ\nIcKhAKOKslm9rZaMgDG0IIuaRt91OaYkh4AZhw3NIyMQoCkSIzvsx9w27WqgtjnKUaOK2FBVT2lu\nmKKcg5ufSwPNInJAsjKCZGX4ndGkEan5ZbSWaJxwKEB1Y4Tqhgi5mUFCwQANLT4kWpeHggFqmyI0\nRWIUZoeJxuMs2bCbsaU5mEE4GOT9XQ3srGumKDuDCcPy2FHXwuJ1VbQkxoQM380VChoNLTE2VtWT\nEQyQEw5SkBViW3UTKzb7VlY0FicSd0Ricdp/jw4FjGjcETA4pDSXlmicmsYItc29E2qtcsJBGlpi\n/Nd5U7hy7iG9+tj7UyiISL/ResZ767fsVq2XRxR2Pr3KCRPKun383tihRmNxKmubyQwFKM3LJB53\nxJ3b58iyaCzeNm5U1xylKRJjQ1UDRwzLJxgwttc0kR0OUpobpmJPI9GY470ddYA/lLquKYoDDinN\nAeCV96qYXF7IKZOGfuj6u6PuIxGRNNDT7iMdNC0iIm0UCiIi0kahICIibRQKIiLSRqEgIiJtFAoi\nItJGoSAiIm0UCiIi0mbAnbxmZjuAjQd59yHAzl4sp79Kh+1Mh22E9NhObWPfOMQ51+1p3wMuFD4M\nM1vakzP6Brp02M502EZIj+3UNvYv6j4SEZE2CgUREWmTbqFwV6oL6CPpsJ3psI2QHtupbexH0mpM\nQUREupZuLQUREemCQkFERNqkTSiY2elm9o6ZrTWzm1JdT28xsw1m9paZvWFmSxPLSszsaTNbk/i/\nONV1Higzu8fMKs1sRbtlHW6Xebcn3tvlZjYzdZX3XCfb+D0z25x4P98wszPb3faNxDa+Y2b/JzVV\nHxgzG21mC81slZmtNLMbEssH23vZ2XYOvPfTOTfo/wFB4D3gUCAMvAkcmeq6emnbNgBD9lv2U+Cm\nxOWbgJ+kus6D2K4TgZnAiu62CzgTeAIwYC6wONX1f4ht/B7wtQ7WPTLxuc0ExiU+z8FUb0MPtnEE\nMDNxOR94N7Etg+297Gw7B9z7mS4thdnAWufcOudcC/AAcG6Ka0qmc4F7E5fvBc5LYS0HxTn3PLBr\nv8Wdbde5wO+dtwgoMrMRfVPpwetkGztzLvCAc67ZObceWIv/XPdrzrmtzrnXEpdrgdVAOYPvvexs\nOzvTb9/PdAmFcmBTu+sVdP2GDSQOeMrMlpnZtYllw5xzWxOXtwHDUlNar+tsuwbb+3tdouvknnZd\nfwN+G81sLDADWMwgfi/3204YYO9nuoTCYPYR59xM4AzgS2Z2YvsbnW+rDrrjjgfrdgF3AocB04Gt\nwM9TW07vMLM84BHgK865mva3Dab3soPtHHDvZ7qEwmZgdLvroxLLBjzn3ObE/5XAo/gm6PbWJnfi\n/8rUVdirOtuuQfP+Oue2O+dizrk4cDd7uxQG7DaaWQZ+R3mfc+4vicWD7r3saDsH4vuZLqGwBJhg\nZuPMLAxcBixIcU0fmpnlmll+62XgNGAFfts+nVjt08Bjqamw13W2XQuATyWOXJkLVLfrmhhQ9us/\nPx//foLfxsvMLNPMxgETgFf7ur4DZWYG/AZY7Zy7td1Ng+q97Gw7B+T7meqR7r76hz+q4V38KP+3\nUl1PL23TofgjGN4EVrZuF1AK/BNYAzwDlKS61oPYtvvxze0Ivr/1M51tF/5IlfmJ9/YtYFaq6/8Q\n2/iHxDYsx+84RrRb/1uJbXwHOCPV9fdwGz+C7xpaDryR+HfmIHwvO9vOAfd+apoLERFpky7dRyIi\n0gMKBRERaaNQEBGRNgoFERFpo1AQEZE2CgWRPmRm88zsf1Ndh0hnFAoiItJGoSDSATO7wsxeTcyB\n/2szC5pZnZn9T2K+/H+aWVli3elmtigx6dmj7X4bYLyZPWNmb5rZa2Z2WOLh88zsYTN728zuS5wN\nK9IvKBRE9mNmk4BLgeOdc9OBGHA5kAssdc5NBp4Dbk7c5ffAfzjnpuHPXm1dfh8w3zl3FHAc/uxl\n8DNofgU/p/6hwPFJ3yiRHgqlugCRfuhk4GhgSeJLfDZ+wrY48OfEOn8E/mJmhUCRc+65xPJ7gYcS\nc1KVO+ceBXDONQEkHu9V51xF4vobwFjgxeRvlkj3FAoiH2TAvc65b+yz0Ow7+613sHPENLe7HEN/\nh9KPqPtI5IP+CVxkZkOh7feED8H/vVyUWOeTwIvOuWpgt5mdkFh+JfCc87++VWFm5yUeI9PMcvp0\nK0QOgr6hiOzHObfKzL6N/0W7AH4W0y8B9cDsxG2V+HEH8FM//yqx018HXJ1YfiXwazP7fuIxLu7D\nzRA5KJolVaSHzKzOOZeX6jpEkkndRyIi0kYtBRERaaOWgoiItFEoiIhIG4WCiIi0USiIiEgbhYKI\niLT5f0qS/EL9YqB6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9685c36860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFiIikpeShYiI5KVkISIief1/j6fKT10cSRgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9685a65630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model several epochs, and test on the validation set. Plot the loss for train and validation sets\n",
    "t_init = time.time()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "t = time.time()\n",
    "history = model1.fit(train_data, train_labels, batch_size = 1000, epochs = 2500, \n",
    "                    validation_data=(valid_data,valid_labels), verbose = 1, callbacks=[early_stopping])\n",
    "\n",
    "epoch_time = time.time() - t\n",
    "\n",
    "total_time = time.time() - t_init\n",
    "\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history[\"val_acc\"])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Build the model - validation loss of 0.12 (hits 0.1199 at some point) after 250 epochs, but should probably \n",
    "# stop a good bit sooner by \n",
    "# the look of the plot. Maybe averaging a bunch of these together will give some improvement. Also, look into\n",
    "# parameter optimization.\n",
    "print('Build model...')\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(512, activation='relu', input_dim=54))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "# model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 370000 samples, validate on 100000 samples\n",
      "Epoch 1/2500\n",
      "370000/370000 [==============================] - 6s 16us/step - loss: 0.6268 - acc: 0.7683 - val_loss: 0.8363 - val_acc: 0.6665\n",
      "Epoch 2/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.4245 - acc: 0.8249 - val_loss: 0.4095 - val_acc: 0.8271\n",
      "Epoch 3/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.3607 - acc: 0.8533 - val_loss: 0.3461 - val_acc: 0.8617\n",
      "Epoch 4/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.3200 - acc: 0.8712 - val_loss: 0.3109 - val_acc: 0.8721\n",
      "Epoch 5/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2862 - acc: 0.8825 - val_loss: 0.2843 - val_acc: 0.8826\n",
      "Epoch 6/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2630 - acc: 0.8925 - val_loss: 0.2625 - val_acc: 0.8923\n",
      "Epoch 7/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2477 - acc: 0.8989 - val_loss: 0.2515 - val_acc: 0.8963\n",
      "Epoch 8/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2343 - acc: 0.9049 - val_loss: 0.2559 - val_acc: 0.8946\n",
      "Epoch 9/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2217 - acc: 0.9097 - val_loss: 0.2421 - val_acc: 0.9025\n",
      "Epoch 10/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2136 - acc: 0.9131 - val_loss: 0.2323 - val_acc: 0.9058\n",
      "Epoch 11/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2062 - acc: 0.9158 - val_loss: 0.2141 - val_acc: 0.9139\n",
      "Epoch 12/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1992 - acc: 0.9188 - val_loss: 0.2163 - val_acc: 0.9126\n",
      "Epoch 13/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1925 - acc: 0.9215 - val_loss: 0.2180 - val_acc: 0.9102\n",
      "Epoch 14/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1875 - acc: 0.9234 - val_loss: 0.2062 - val_acc: 0.9161\n",
      "Epoch 15/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1815 - acc: 0.9258 - val_loss: 0.2000 - val_acc: 0.9203\n",
      "Epoch 16/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1767 - acc: 0.9282 - val_loss: 0.1981 - val_acc: 0.9190\n",
      "Epoch 17/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1736 - acc: 0.9294 - val_loss: 0.1872 - val_acc: 0.9253\n",
      "Epoch 18/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1694 - acc: 0.9312 - val_loss: 0.1902 - val_acc: 0.9226\n",
      "Epoch 19/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1652 - acc: 0.9328 - val_loss: 0.1873 - val_acc: 0.9243\n",
      "Epoch 20/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1620 - acc: 0.9342 - val_loss: 0.1783 - val_acc: 0.9274\n",
      "Epoch 21/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1581 - acc: 0.9358 - val_loss: 0.1864 - val_acc: 0.9247\n",
      "Epoch 22/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1563 - acc: 0.9365 - val_loss: 0.1751 - val_acc: 0.9298\n",
      "Epoch 23/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1530 - acc: 0.9378 - val_loss: 0.1766 - val_acc: 0.9297\n",
      "Epoch 24/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1508 - acc: 0.9384 - val_loss: 0.1642 - val_acc: 0.9342\n",
      "Epoch 25/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1480 - acc: 0.9397 - val_loss: 0.1721 - val_acc: 0.9313\n",
      "Epoch 26/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1461 - acc: 0.9408 - val_loss: 0.1672 - val_acc: 0.9335\n",
      "Epoch 27/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1429 - acc: 0.9424 - val_loss: 0.1692 - val_acc: 0.9332\n",
      "Epoch 28/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1419 - acc: 0.9420 - val_loss: 0.1651 - val_acc: 0.9352\n",
      "Epoch 29/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1393 - acc: 0.9436 - val_loss: 0.1703 - val_acc: 0.9316\n",
      "Epoch 30/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1374 - acc: 0.9442 - val_loss: 0.1607 - val_acc: 0.9365\n",
      "Epoch 31/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1352 - acc: 0.9452 - val_loss: 0.1616 - val_acc: 0.9361\n",
      "Epoch 32/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1331 - acc: 0.9459 - val_loss: 0.1501 - val_acc: 0.9412\n",
      "Epoch 33/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1320 - acc: 0.9463 - val_loss: 0.1567 - val_acc: 0.9377\n",
      "Epoch 34/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1315 - acc: 0.9468 - val_loss: 0.1596 - val_acc: 0.9368\n",
      "Epoch 35/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1281 - acc: 0.9479 - val_loss: 0.1500 - val_acc: 0.9405\n",
      "Epoch 36/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1271 - acc: 0.9481 - val_loss: 0.1568 - val_acc: 0.9380\n",
      "Epoch 37/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1259 - acc: 0.9490 - val_loss: 0.1610 - val_acc: 0.9362\n",
      "Epoch 38/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1241 - acc: 0.9497 - val_loss: 0.1503 - val_acc: 0.9407\n",
      "Epoch 39/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1227 - acc: 0.9502 - val_loss: 0.1478 - val_acc: 0.9417\n",
      "Epoch 40/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1219 - acc: 0.9504 - val_loss: 0.1434 - val_acc: 0.9434\n",
      "Epoch 41/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1210 - acc: 0.9509 - val_loss: 0.1458 - val_acc: 0.9431\n",
      "Epoch 42/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1193 - acc: 0.9519 - val_loss: 0.1509 - val_acc: 0.9414\n",
      "Epoch 43/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1181 - acc: 0.9521 - val_loss: 0.1518 - val_acc: 0.9404\n",
      "Epoch 44/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1173 - acc: 0.9521 - val_loss: 0.1522 - val_acc: 0.9411\n",
      "Epoch 45/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1164 - acc: 0.9530 - val_loss: 0.1424 - val_acc: 0.9435\n",
      "Epoch 46/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1154 - acc: 0.9532 - val_loss: 0.1422 - val_acc: 0.9449\n",
      "Epoch 47/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1139 - acc: 0.9537 - val_loss: 0.1468 - val_acc: 0.9430\n",
      "Epoch 48/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1140 - acc: 0.9535 - val_loss: 0.1442 - val_acc: 0.9441\n",
      "Epoch 49/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1130 - acc: 0.9546 - val_loss: 0.1453 - val_acc: 0.9438\n",
      "Epoch 50/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1113 - acc: 0.9546 - val_loss: 0.1468 - val_acc: 0.9436\n",
      "Epoch 51/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1096 - acc: 0.9557 - val_loss: 0.1398 - val_acc: 0.9463\n",
      "Epoch 52/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1098 - acc: 0.9552 - val_loss: 0.1379 - val_acc: 0.9465\n",
      "Epoch 53/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1088 - acc: 0.9556 - val_loss: 0.1399 - val_acc: 0.9455\n",
      "Epoch 54/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1082 - acc: 0.9562 - val_loss: 0.1352 - val_acc: 0.9476\n",
      "Epoch 55/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1072 - acc: 0.9568 - val_loss: 0.1375 - val_acc: 0.9476\n",
      "Epoch 56/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1058 - acc: 0.9570 - val_loss: 0.1437 - val_acc: 0.9440\n",
      "Epoch 57/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1049 - acc: 0.9573 - val_loss: 0.1504 - val_acc: 0.9425\n",
      "Epoch 58/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1038 - acc: 0.9578 - val_loss: 0.1341 - val_acc: 0.9485\n",
      "Epoch 59/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1043 - acc: 0.9581 - val_loss: 0.1380 - val_acc: 0.9469\n",
      "Epoch 60/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1026 - acc: 0.9581 - val_loss: 0.1404 - val_acc: 0.9459\n",
      "Epoch 61/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1027 - acc: 0.9583 - val_loss: 0.1380 - val_acc: 0.9472\n",
      "Epoch 62/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1018 - acc: 0.9587 - val_loss: 0.1279 - val_acc: 0.9507\n",
      "Epoch 63/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1014 - acc: 0.9589 - val_loss: 0.1371 - val_acc: 0.9474\n",
      "Epoch 64/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0999 - acc: 0.9596 - val_loss: 0.1360 - val_acc: 0.9485\n",
      "Epoch 65/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0982 - acc: 0.9601 - val_loss: 0.1332 - val_acc: 0.9492\n",
      "Epoch 66/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0991 - acc: 0.9597 - val_loss: 0.1398 - val_acc: 0.9473\n",
      "Epoch 67/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0993 - acc: 0.9600 - val_loss: 0.1307 - val_acc: 0.9501\n",
      "Epoch 68/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0967 - acc: 0.9609 - val_loss: 0.1309 - val_acc: 0.9507\n",
      "Epoch 69/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0974 - acc: 0.9607 - val_loss: 0.1289 - val_acc: 0.9506\n",
      "Epoch 70/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0958 - acc: 0.9611 - val_loss: 0.1278 - val_acc: 0.9508\n",
      "Epoch 71/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0956 - acc: 0.9612 - val_loss: 0.1310 - val_acc: 0.9502\n",
      "Epoch 72/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0952 - acc: 0.9617 - val_loss: 0.1375 - val_acc: 0.9481\n",
      "Epoch 73/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0945 - acc: 0.9619 - val_loss: 0.1306 - val_acc: 0.9501\n",
      "Epoch 74/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0936 - acc: 0.9620 - val_loss: 0.1265 - val_acc: 0.9524\n",
      "Epoch 75/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0937 - acc: 0.9625 - val_loss: 0.1318 - val_acc: 0.9506\n",
      "Epoch 76/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0927 - acc: 0.9623 - val_loss: 0.1297 - val_acc: 0.9502\n",
      "Epoch 77/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0938 - acc: 0.9618 - val_loss: 0.1277 - val_acc: 0.9513\n",
      "Epoch 78/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0905 - acc: 0.9634 - val_loss: 0.1372 - val_acc: 0.9484\n",
      "Epoch 79/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0909 - acc: 0.9630 - val_loss: 0.1467 - val_acc: 0.9450\n",
      "Epoch 80/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0913 - acc: 0.9627 - val_loss: 0.1366 - val_acc: 0.9487\n",
      "Epoch 81/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0913 - acc: 0.9630 - val_loss: 0.1381 - val_acc: 0.9482\n",
      "Epoch 82/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0901 - acc: 0.9638 - val_loss: 0.1266 - val_acc: 0.9526\n",
      "Epoch 83/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0887 - acc: 0.9641 - val_loss: 0.1267 - val_acc: 0.9526\n",
      "Epoch 84/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0894 - acc: 0.9638 - val_loss: 0.1291 - val_acc: 0.9523\n",
      "Epoch 85/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0884 - acc: 0.9643 - val_loss: 0.1305 - val_acc: 0.9510\n",
      "Epoch 86/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0876 - acc: 0.9646 - val_loss: 0.1234 - val_acc: 0.9538\n",
      "Epoch 87/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0870 - acc: 0.9647 - val_loss: 0.1267 - val_acc: 0.9523\n",
      "Epoch 88/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0878 - acc: 0.9645 - val_loss: 0.1294 - val_acc: 0.9514\n",
      "Epoch 89/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0865 - acc: 0.9649 - val_loss: 0.1301 - val_acc: 0.9518\n",
      "Epoch 90/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0867 - acc: 0.9647 - val_loss: 0.1277 - val_acc: 0.9521\n",
      "Epoch 91/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0848 - acc: 0.9654 - val_loss: 0.1330 - val_acc: 0.9500\n",
      "Epoch 92/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0855 - acc: 0.9653 - val_loss: 0.1250 - val_acc: 0.9533\n",
      "Epoch 93/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0852 - acc: 0.9654 - val_loss: 0.1248 - val_acc: 0.9529\n",
      "Epoch 94/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0843 - acc: 0.9660 - val_loss: 0.1243 - val_acc: 0.9536\n",
      "Epoch 95/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0842 - acc: 0.9661 - val_loss: 0.1281 - val_acc: 0.9531\n",
      "Epoch 96/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0833 - acc: 0.9662 - val_loss: 0.1258 - val_acc: 0.9532\n",
      "Epoch 97/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0829 - acc: 0.9667 - val_loss: 0.1230 - val_acc: 0.9538\n",
      "Epoch 98/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0831 - acc: 0.9662 - val_loss: 0.1238 - val_acc: 0.9537\n",
      "Epoch 99/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0827 - acc: 0.9668 - val_loss: 0.1223 - val_acc: 0.9543\n",
      "Epoch 100/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0823 - acc: 0.9670 - val_loss: 0.1319 - val_acc: 0.9507\n",
      "Epoch 101/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0829 - acc: 0.9666 - val_loss: 0.1192 - val_acc: 0.9565\n",
      "Epoch 102/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0812 - acc: 0.9671 - val_loss: 0.1165 - val_acc: 0.9567\n",
      "Epoch 103/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0815 - acc: 0.9668 - val_loss: 0.1212 - val_acc: 0.9548\n",
      "Epoch 104/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0801 - acc: 0.9676 - val_loss: 0.1225 - val_acc: 0.9549\n",
      "Epoch 105/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0810 - acc: 0.9670 - val_loss: 0.1411 - val_acc: 0.9477\n",
      "Epoch 106/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0803 - acc: 0.9673 - val_loss: 0.1228 - val_acc: 0.9553\n",
      "Epoch 107/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0797 - acc: 0.9676 - val_loss: 0.1288 - val_acc: 0.9528\n",
      "Epoch 108/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0802 - acc: 0.9676 - val_loss: 0.1241 - val_acc: 0.9541\n",
      "Epoch 109/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0792 - acc: 0.9681 - val_loss: 0.1254 - val_acc: 0.9533\n",
      "Epoch 110/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0790 - acc: 0.9679 - val_loss: 0.1235 - val_acc: 0.9551\n",
      "Epoch 111/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0767 - acc: 0.9687 - val_loss: 0.1304 - val_acc: 0.9520\n",
      "Epoch 112/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0787 - acc: 0.9683 - val_loss: 0.1247 - val_acc: 0.9540\n",
      "Epoch 113/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0771 - acc: 0.9690 - val_loss: 0.1206 - val_acc: 0.9559\n",
      "Epoch 114/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0783 - acc: 0.9683 - val_loss: 0.1207 - val_acc: 0.9553\n",
      "Epoch 115/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0780 - acc: 0.9685 - val_loss: 0.1209 - val_acc: 0.9563\n",
      "Epoch 116/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0770 - acc: 0.9692 - val_loss: 0.1247 - val_acc: 0.9546\n",
      "Epoch 117/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0760 - acc: 0.9691 - val_loss: 0.1230 - val_acc: 0.9545\n",
      "Epoch 118/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0760 - acc: 0.9694 - val_loss: 0.1339 - val_acc: 0.9511\n",
      "Epoch 119/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0757 - acc: 0.9692 - val_loss: 0.1264 - val_acc: 0.9538\n",
      "Epoch 120/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0768 - acc: 0.9692 - val_loss: 0.1254 - val_acc: 0.9541\n",
      "Epoch 121/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0762 - acc: 0.9692 - val_loss: 0.1368 - val_acc: 0.9504\n",
      "Epoch 122/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0746 - acc: 0.9702 - val_loss: 0.1347 - val_acc: 0.9511\n",
      "Epoch 123/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0755 - acc: 0.9695 - val_loss: 0.1228 - val_acc: 0.9556\n",
      "Epoch 124/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0747 - acc: 0.9699 - val_loss: 0.1178 - val_acc: 0.9572\n",
      "Epoch 125/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0738 - acc: 0.9703 - val_loss: 0.1204 - val_acc: 0.9567\n",
      "Epoch 126/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0741 - acc: 0.9703 - val_loss: 0.1219 - val_acc: 0.9563\n",
      "Epoch 127/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0738 - acc: 0.9702 - val_loss: 0.1259 - val_acc: 0.9545\n",
      "Epoch 128/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0739 - acc: 0.9700 - val_loss: 0.1202 - val_acc: 0.9567\n",
      "Epoch 129/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0740 - acc: 0.9701 - val_loss: 0.1262 - val_acc: 0.9544\n",
      "Epoch 130/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0727 - acc: 0.9704 - val_loss: 0.1240 - val_acc: 0.9551\n",
      "Epoch 131/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0728 - acc: 0.9708 - val_loss: 0.1177 - val_acc: 0.9582\n",
      "Epoch 132/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0715 - acc: 0.9712 - val_loss: 0.1205 - val_acc: 0.9572\n",
      "Epoch 133/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0715 - acc: 0.9713 - val_loss: 0.1200 - val_acc: 0.9567\n",
      "Epoch 134/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0721 - acc: 0.9709 - val_loss: 0.1203 - val_acc: 0.9569\n",
      "Epoch 135/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0716 - acc: 0.9712 - val_loss: 0.1212 - val_acc: 0.9567\n",
      "Epoch 136/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0717 - acc: 0.9712 - val_loss: 0.1242 - val_acc: 0.9552\n",
      "Epoch 137/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0716 - acc: 0.9712 - val_loss: 0.1156 - val_acc: 0.9581\n",
      "Epoch 138/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0711 - acc: 0.9715 - val_loss: 0.1240 - val_acc: 0.9551\n",
      "Epoch 139/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0713 - acc: 0.9713 - val_loss: 0.1252 - val_acc: 0.9547\n",
      "Epoch 140/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0704 - acc: 0.9714 - val_loss: 0.1223 - val_acc: 0.9567\n",
      "Epoch 141/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0702 - acc: 0.9716 - val_loss: 0.1231 - val_acc: 0.9567\n",
      "Epoch 142/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0706 - acc: 0.9717 - val_loss: 0.1183 - val_acc: 0.9577\n",
      "Epoch 143/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0698 - acc: 0.9718 - val_loss: 0.1218 - val_acc: 0.9568\n",
      "Epoch 144/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0699 - acc: 0.9719 - val_loss: 0.1226 - val_acc: 0.9567\n",
      "Epoch 145/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0693 - acc: 0.9721 - val_loss: 0.1195 - val_acc: 0.9569\n",
      "Epoch 146/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0697 - acc: 0.9717 - val_loss: 0.1250 - val_acc: 0.9562\n",
      "Epoch 147/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0683 - acc: 0.9723 - val_loss: 0.1213 - val_acc: 0.9565\n",
      "Epoch 148/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0684 - acc: 0.9725 - val_loss: 0.1201 - val_acc: 0.9575\n",
      "Epoch 149/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0685 - acc: 0.9724 - val_loss: 0.1265 - val_acc: 0.9550\n",
      "Epoch 150/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0685 - acc: 0.9722 - val_loss: 0.1291 - val_acc: 0.9543\n",
      "Epoch 151/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0692 - acc: 0.9721 - val_loss: 0.1276 - val_acc: 0.9545\n",
      "Epoch 152/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0676 - acc: 0.9728 - val_loss: 0.1193 - val_acc: 0.9569\n",
      "Epoch 153/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0676 - acc: 0.9728 - val_loss: 0.1177 - val_acc: 0.9585\n",
      "Epoch 154/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0678 - acc: 0.9727 - val_loss: 0.1230 - val_acc: 0.9565\n",
      "Epoch 155/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0674 - acc: 0.9727 - val_loss: 0.1230 - val_acc: 0.9573\n",
      "Epoch 156/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0669 - acc: 0.9728 - val_loss: 0.1214 - val_acc: 0.9571\n",
      "Epoch 157/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0667 - acc: 0.9732 - val_loss: 0.1195 - val_acc: 0.9583\n",
      "Epoch 158/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0675 - acc: 0.9727 - val_loss: 0.1191 - val_acc: 0.9573\n",
      "Epoch 159/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0666 - acc: 0.9733 - val_loss: 0.1281 - val_acc: 0.9552\n",
      "Epoch 160/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0667 - acc: 0.9735 - val_loss: 0.1220 - val_acc: 0.9572\n",
      "Epoch 161/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0667 - acc: 0.9732 - val_loss: 0.1243 - val_acc: 0.9561\n",
      "Epoch 162/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0651 - acc: 0.9737 - val_loss: 0.1196 - val_acc: 0.9581\n",
      "Epoch 163/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0666 - acc: 0.9730 - val_loss: 0.1178 - val_acc: 0.9583\n",
      "Epoch 164/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0652 - acc: 0.9737 - val_loss: 0.1219 - val_acc: 0.9571\n",
      "Epoch 165/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0661 - acc: 0.9733 - val_loss: 0.1231 - val_acc: 0.9567\n",
      "Epoch 166/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0654 - acc: 0.9735 - val_loss: 0.1193 - val_acc: 0.9588\n",
      "Epoch 167/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0643 - acc: 0.9739 - val_loss: 0.1194 - val_acc: 0.9588\n",
      "Epoch 168/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0644 - acc: 0.9741 - val_loss: 0.1196 - val_acc: 0.9580\n",
      "Epoch 169/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0649 - acc: 0.9739 - val_loss: 0.1235 - val_acc: 0.9567\n",
      "Epoch 170/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0652 - acc: 0.9736 - val_loss: 0.1225 - val_acc: 0.9577\n",
      "Epoch 171/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0641 - acc: 0.9743 - val_loss: 0.1221 - val_acc: 0.9572\n",
      "Epoch 172/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0644 - acc: 0.9739 - val_loss: 0.1160 - val_acc: 0.9595\n",
      "Epoch 173/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0637 - acc: 0.9743 - val_loss: 0.1228 - val_acc: 0.9580\n",
      "Epoch 174/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0637 - acc: 0.9742 - val_loss: 0.1212 - val_acc: 0.9589\n",
      "Epoch 175/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0636 - acc: 0.9743 - val_loss: 0.1251 - val_acc: 0.9569\n",
      "Epoch 176/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0634 - acc: 0.9744 - val_loss: 0.1219 - val_acc: 0.9579\n",
      "Epoch 177/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0620 - acc: 0.9751 - val_loss: 0.1243 - val_acc: 0.9576\n",
      "Epoch 178/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0634 - acc: 0.9745 - val_loss: 0.1165 - val_acc: 0.9597\n",
      "Epoch 179/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0630 - acc: 0.9748 - val_loss: 0.1236 - val_acc: 0.9571\n",
      "Epoch 180/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0630 - acc: 0.9748 - val_loss: 0.1237 - val_acc: 0.9574\n",
      "Epoch 181/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0629 - acc: 0.9746 - val_loss: 0.1171 - val_acc: 0.9592\n",
      "Epoch 182/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0627 - acc: 0.9748 - val_loss: 0.1225 - val_acc: 0.9578\n",
      "Epoch 183/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0620 - acc: 0.9747 - val_loss: 0.1164 - val_acc: 0.9592\n",
      "Epoch 184/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0626 - acc: 0.9749 - val_loss: 0.1220 - val_acc: 0.9579\n",
      "Epoch 185/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0615 - acc: 0.9754 - val_loss: 0.1153 - val_acc: 0.9605\n",
      "Epoch 186/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0612 - acc: 0.9757 - val_loss: 0.1207 - val_acc: 0.9589\n",
      "Epoch 187/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0616 - acc: 0.9753 - val_loss: 0.1235 - val_acc: 0.9576\n",
      "Epoch 188/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0616 - acc: 0.9753 - val_loss: 0.1249 - val_acc: 0.9563\n",
      "Epoch 189/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0616 - acc: 0.9752 - val_loss: 0.1210 - val_acc: 0.9593\n",
      "Epoch 190/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0615 - acc: 0.9754 - val_loss: 0.1174 - val_acc: 0.9597\n",
      "Epoch 191/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0604 - acc: 0.9754 - val_loss: 0.1321 - val_acc: 0.9548\n",
      "Epoch 192/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0617 - acc: 0.9753 - val_loss: 0.1199 - val_acc: 0.9588\n",
      "Epoch 193/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0594 - acc: 0.9759 - val_loss: 0.1177 - val_acc: 0.9602\n",
      "Epoch 194/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0603 - acc: 0.9756 - val_loss: 0.1197 - val_acc: 0.9588\n",
      "Epoch 195/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0600 - acc: 0.9758 - val_loss: 0.1164 - val_acc: 0.9603\n",
      "Epoch 196/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0607 - acc: 0.9755 - val_loss: 0.1187 - val_acc: 0.9601\n",
      "Epoch 197/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0604 - acc: 0.9757 - val_loss: 0.1191 - val_acc: 0.9586\n",
      "Epoch 198/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0608 - acc: 0.9755 - val_loss: 0.1279 - val_acc: 0.9562\n",
      "Epoch 199/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0594 - acc: 0.9761 - val_loss: 0.1222 - val_acc: 0.9586\n",
      "Epoch 200/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0597 - acc: 0.9760 - val_loss: 0.1220 - val_acc: 0.9584\n",
      "Epoch 201/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0590 - acc: 0.9761 - val_loss: 0.1188 - val_acc: 0.9592\n",
      "Epoch 202/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0603 - acc: 0.9757 - val_loss: 0.1199 - val_acc: 0.9595\n",
      "Epoch 203/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0596 - acc: 0.9761 - val_loss: 0.1250 - val_acc: 0.9581\n",
      "Epoch 204/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0591 - acc: 0.9762 - val_loss: 0.1219 - val_acc: 0.9584\n",
      "Epoch 205/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0584 - acc: 0.9768 - val_loss: 0.1282 - val_acc: 0.9556\n",
      "Epoch 206/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0594 - acc: 0.9762 - val_loss: 0.1217 - val_acc: 0.9584\n",
      "Epoch 207/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0585 - acc: 0.9764 - val_loss: 0.1158 - val_acc: 0.9610\n",
      "Epoch 208/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0594 - acc: 0.9761 - val_loss: 0.1169 - val_acc: 0.9601\n",
      "Epoch 209/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0579 - acc: 0.9767 - val_loss: 0.1289 - val_acc: 0.9575\n",
      "Epoch 210/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0588 - acc: 0.9764 - val_loss: 0.1249 - val_acc: 0.9573\n",
      "Epoch 211/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0583 - acc: 0.9767 - val_loss: 0.1205 - val_acc: 0.9597\n",
      "Epoch 212/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0579 - acc: 0.9770 - val_loss: 0.1230 - val_acc: 0.9582\n",
      "Epoch 213/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0572 - acc: 0.9772 - val_loss: 0.1161 - val_acc: 0.9610\n",
      "Epoch 214/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0582 - acc: 0.9766 - val_loss: 0.1165 - val_acc: 0.9605\n",
      "Epoch 215/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0580 - acc: 0.9765 - val_loss: 0.1190 - val_acc: 0.9598\n",
      "Epoch 216/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0572 - acc: 0.9770 - val_loss: 0.1228 - val_acc: 0.9585\n",
      "Epoch 217/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0584 - acc: 0.9767 - val_loss: 0.1244 - val_acc: 0.9576\n",
      "Epoch 218/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0573 - acc: 0.9771 - val_loss: 0.1215 - val_acc: 0.9594\n",
      "Epoch 219/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0572 - acc: 0.9773 - val_loss: 0.1163 - val_acc: 0.9609\n",
      "Epoch 220/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0573 - acc: 0.9769 - val_loss: 0.1183 - val_acc: 0.9604\n",
      "Epoch 221/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0569 - acc: 0.9771 - val_loss: 0.1232 - val_acc: 0.9590\n",
      "Epoch 222/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0577 - acc: 0.9769 - val_loss: 0.1242 - val_acc: 0.9575\n",
      "Epoch 223/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0572 - acc: 0.9772 - val_loss: 0.1298 - val_acc: 0.9567\n",
      "Epoch 224/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0576 - acc: 0.9767 - val_loss: 0.1191 - val_acc: 0.9599\n",
      "Epoch 225/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0557 - acc: 0.9777 - val_loss: 0.1209 - val_acc: 0.9596\n",
      "Epoch 226/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0554 - acc: 0.9777 - val_loss: 0.1253 - val_acc: 0.9581\n",
      "Epoch 227/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0557 - acc: 0.9776 - val_loss: 0.1200 - val_acc: 0.9596\n",
      "Epoch 228/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0555 - acc: 0.9776 - val_loss: 0.1210 - val_acc: 0.9597\n",
      "Epoch 229/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0563 - acc: 0.9774 - val_loss: 0.1206 - val_acc: 0.9599\n",
      "Epoch 230/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0553 - acc: 0.9779 - val_loss: 0.1226 - val_acc: 0.9602\n",
      "Epoch 231/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0562 - acc: 0.9775 - val_loss: 0.1225 - val_acc: 0.9591\n",
      "Epoch 232/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0560 - acc: 0.9775 - val_loss: 0.1223 - val_acc: 0.9594\n",
      "Epoch 233/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0557 - acc: 0.9775 - val_loss: 0.1230 - val_acc: 0.9591\n",
      "Epoch 234/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0540 - acc: 0.9782 - val_loss: 0.1196 - val_acc: 0.9601\n",
      "Epoch 235/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0559 - acc: 0.9777 - val_loss: 0.1195 - val_acc: 0.9601\n",
      "Epoch 236/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0553 - acc: 0.9779 - val_loss: 0.1207 - val_acc: 0.9592\n",
      "Epoch 237/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0547 - acc: 0.9781 - val_loss: 0.1204 - val_acc: 0.9604\n",
      "Epoch 238/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0552 - acc: 0.9778 - val_loss: 0.1194 - val_acc: 0.9603\n",
      "Epoch 239/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0546 - acc: 0.9781 - val_loss: 0.1203 - val_acc: 0.9601\n",
      "Epoch 240/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0555 - acc: 0.9781 - val_loss: 0.1233 - val_acc: 0.9597\n",
      "Epoch 241/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0551 - acc: 0.9779 - val_loss: 0.1173 - val_acc: 0.9610\n",
      "Epoch 242/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0541 - acc: 0.9785 - val_loss: 0.1234 - val_acc: 0.9586\n",
      "Epoch 243/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0540 - acc: 0.9783 - val_loss: 0.1174 - val_acc: 0.9610\n",
      "Epoch 244/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0547 - acc: 0.9781 - val_loss: 0.1250 - val_acc: 0.9598\n",
      "Epoch 245/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0552 - acc: 0.9778 - val_loss: 0.1192 - val_acc: 0.9607\n",
      "Epoch 246/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0526 - acc: 0.9789 - val_loss: 0.1212 - val_acc: 0.9602\n",
      "Epoch 247/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0546 - acc: 0.9780 - val_loss: 0.1191 - val_acc: 0.9606\n",
      "Epoch 248/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0533 - acc: 0.9787 - val_loss: 0.1192 - val_acc: 0.9607\n",
      "Epoch 249/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0542 - acc: 0.9781 - val_loss: 0.1226 - val_acc: 0.9601\n",
      "Epoch 250/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0534 - acc: 0.9784 - val_loss: 0.1180 - val_acc: 0.9618\n",
      "Epoch 251/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0531 - acc: 0.9789 - val_loss: 0.1265 - val_acc: 0.9587\n",
      "Epoch 252/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0533 - acc: 0.9788 - val_loss: 0.1233 - val_acc: 0.9598\n",
      "Epoch 253/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0534 - acc: 0.9786 - val_loss: 0.1182 - val_acc: 0.9613\n",
      "Epoch 254/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0525 - acc: 0.9790 - val_loss: 0.1216 - val_acc: 0.9599\n",
      "Epoch 255/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0540 - acc: 0.9783 - val_loss: 0.1184 - val_acc: 0.9618\n",
      "Epoch 256/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0529 - acc: 0.9786 - val_loss: 0.1254 - val_acc: 0.9592\n",
      "Epoch 257/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0534 - acc: 0.9786 - val_loss: 0.1180 - val_acc: 0.9608\n",
      "Epoch 258/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0527 - acc: 0.9787 - val_loss: 0.1156 - val_acc: 0.9624\n",
      "Epoch 259/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0528 - acc: 0.9787 - val_loss: 0.1213 - val_acc: 0.9596\n",
      "Epoch 260/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0515 - acc: 0.9793 - val_loss: 0.1173 - val_acc: 0.9620\n",
      "Epoch 261/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0522 - acc: 0.9794 - val_loss: 0.1241 - val_acc: 0.9604\n",
      "Epoch 262/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0528 - acc: 0.9790 - val_loss: 0.1235 - val_acc: 0.9599\n",
      "Epoch 263/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0525 - acc: 0.9788 - val_loss: 0.1195 - val_acc: 0.9612\n",
      "Epoch 264/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0521 - acc: 0.9794 - val_loss: 0.1202 - val_acc: 0.9613\n",
      "Epoch 265/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0526 - acc: 0.9788 - val_loss: 0.1147 - val_acc: 0.9627\n",
      "Epoch 266/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0518 - acc: 0.9791 - val_loss: 0.1183 - val_acc: 0.9604\n",
      "Epoch 267/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0522 - acc: 0.9789 - val_loss: 0.1211 - val_acc: 0.9605\n",
      "Epoch 268/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0521 - acc: 0.9791 - val_loss: 0.1215 - val_acc: 0.9599\n",
      "Epoch 269/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0518 - acc: 0.9792 - val_loss: 0.1254 - val_acc: 0.9587\n",
      "Epoch 270/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0518 - acc: 0.9794 - val_loss: 0.1208 - val_acc: 0.9606\n",
      "Epoch 271/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0520 - acc: 0.9791 - val_loss: 0.1201 - val_acc: 0.9620\n",
      "Epoch 272/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0509 - acc: 0.9797 - val_loss: 0.1262 - val_acc: 0.9594\n",
      "Epoch 273/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0518 - acc: 0.9795 - val_loss: 0.1355 - val_acc: 0.9565\n",
      "Epoch 274/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0522 - acc: 0.9793 - val_loss: 0.1217 - val_acc: 0.9611\n",
      "Epoch 275/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0515 - acc: 0.9795 - val_loss: 0.1203 - val_acc: 0.9619\n",
      "Epoch 276/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0509 - acc: 0.9796 - val_loss: 0.1292 - val_acc: 0.9579\n",
      "Epoch 277/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0504 - acc: 0.9799 - val_loss: 0.1169 - val_acc: 0.9616\n",
      "Epoch 278/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0506 - acc: 0.9796 - val_loss: 0.1198 - val_acc: 0.9607\n",
      "Epoch 279/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0513 - acc: 0.9797 - val_loss: 0.1178 - val_acc: 0.9614\n",
      "Epoch 280/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0509 - acc: 0.9797 - val_loss: 0.1235 - val_acc: 0.9599\n",
      "Epoch 281/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0505 - acc: 0.9797 - val_loss: 0.1217 - val_acc: 0.9607\n",
      "Epoch 282/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0505 - acc: 0.9798 - val_loss: 0.1245 - val_acc: 0.9604\n",
      "Epoch 283/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0497 - acc: 0.9801 - val_loss: 0.1193 - val_acc: 0.9615\n",
      "Epoch 284/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0494 - acc: 0.9803 - val_loss: 0.1266 - val_acc: 0.9591\n",
      "Epoch 285/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0513 - acc: 0.9796 - val_loss: 0.1200 - val_acc: 0.9612\n",
      "Epoch 286/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0492 - acc: 0.9803 - val_loss: 0.1217 - val_acc: 0.9605\n",
      "Epoch 287/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0503 - acc: 0.9798 - val_loss: 0.1216 - val_acc: 0.9611\n",
      "Epoch 288/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0505 - acc: 0.9798 - val_loss: 0.1219 - val_acc: 0.9614\n",
      "Epoch 289/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0496 - acc: 0.9801 - val_loss: 0.1338 - val_acc: 0.9577\n",
      "Epoch 290/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0506 - acc: 0.9799 - val_loss: 0.1259 - val_acc: 0.9601\n",
      "Epoch 291/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0497 - acc: 0.9803 - val_loss: 0.1199 - val_acc: 0.9622\n",
      "Epoch 292/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0499 - acc: 0.9801 - val_loss: 0.1227 - val_acc: 0.9615\n",
      "Epoch 293/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0500 - acc: 0.9801 - val_loss: 0.1234 - val_acc: 0.9605\n",
      "Epoch 294/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0487 - acc: 0.9807 - val_loss: 0.1203 - val_acc: 0.9617\n",
      "Epoch 295/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0490 - acc: 0.9803 - val_loss: 0.1243 - val_acc: 0.9607\n",
      "Epoch 296/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0494 - acc: 0.9804 - val_loss: 0.1258 - val_acc: 0.9600\n",
      "Epoch 297/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0495 - acc: 0.9803 - val_loss: 0.1220 - val_acc: 0.9608\n",
      "Epoch 298/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0486 - acc: 0.9804 - val_loss: 0.1194 - val_acc: 0.9616\n",
      "Epoch 299/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0497 - acc: 0.9801 - val_loss: 0.1264 - val_acc: 0.9599\n",
      "Epoch 300/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0484 - acc: 0.9807 - val_loss: 0.1230 - val_acc: 0.9614\n",
      "Epoch 301/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0483 - acc: 0.9805 - val_loss: 0.1274 - val_acc: 0.9596\n",
      "Epoch 302/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0487 - acc: 0.9806 - val_loss: 0.1235 - val_acc: 0.9609\n",
      "Epoch 303/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0492 - acc: 0.9805 - val_loss: 0.1272 - val_acc: 0.9604\n",
      "Epoch 304/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0499 - acc: 0.9800 - val_loss: 0.1212 - val_acc: 0.9612\n",
      "Epoch 305/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0487 - acc: 0.9807 - val_loss: 0.1260 - val_acc: 0.9598\n",
      "Epoch 306/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0486 - acc: 0.9808 - val_loss: 0.1230 - val_acc: 0.9612\n",
      "Epoch 307/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0475 - acc: 0.9811 - val_loss: 0.1215 - val_acc: 0.9619\n",
      "Epoch 308/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0487 - acc: 0.9806 - val_loss: 0.1220 - val_acc: 0.9612\n",
      "Epoch 309/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0476 - acc: 0.9809 - val_loss: 0.1305 - val_acc: 0.9585\n",
      "Epoch 310/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0485 - acc: 0.9804 - val_loss: 0.1257 - val_acc: 0.9601\n",
      "Epoch 311/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0482 - acc: 0.9806 - val_loss: 0.1209 - val_acc: 0.9615\n",
      "Epoch 312/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0486 - acc: 0.9807 - val_loss: 0.1263 - val_acc: 0.9601\n",
      "Epoch 313/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0484 - acc: 0.9805 - val_loss: 0.1213 - val_acc: 0.9612\n",
      "Epoch 314/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0479 - acc: 0.9811 - val_loss: 0.1242 - val_acc: 0.9602\n",
      "Epoch 315/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0479 - acc: 0.9808 - val_loss: 0.1240 - val_acc: 0.9607\n",
      "Epoch 316/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0476 - acc: 0.9811 - val_loss: 0.1267 - val_acc: 0.9601\n",
      "Epoch 317/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0477 - acc: 0.9809 - val_loss: 0.1212 - val_acc: 0.9614\n",
      "Epoch 318/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0477 - acc: 0.9810 - val_loss: 0.1255 - val_acc: 0.9604\n",
      "Epoch 319/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0482 - acc: 0.9810 - val_loss: 0.1177 - val_acc: 0.9620\n",
      "Epoch 320/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0469 - acc: 0.9814 - val_loss: 0.1207 - val_acc: 0.9619\n",
      "Epoch 321/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0485 - acc: 0.9807 - val_loss: 0.1229 - val_acc: 0.9610\n",
      "Epoch 322/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0473 - acc: 0.9810 - val_loss: 0.1301 - val_acc: 0.9591\n",
      "Epoch 323/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0471 - acc: 0.9812 - val_loss: 0.1183 - val_acc: 0.9626\n",
      "Epoch 324/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0464 - acc: 0.9814 - val_loss: 0.1258 - val_acc: 0.9604\n",
      "Epoch 325/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0479 - acc: 0.9808 - val_loss: 0.1233 - val_acc: 0.9603\n",
      "Epoch 326/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0473 - acc: 0.9811 - val_loss: 0.1227 - val_acc: 0.9618\n",
      "Epoch 327/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0474 - acc: 0.9812 - val_loss: 0.1222 - val_acc: 0.9611\n",
      "Epoch 328/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0462 - acc: 0.9816 - val_loss: 0.1183 - val_acc: 0.9629\n",
      "Epoch 329/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0471 - acc: 0.9811 - val_loss: 0.1193 - val_acc: 0.9629\n",
      "Epoch 330/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0465 - acc: 0.9815 - val_loss: 0.1203 - val_acc: 0.9624\n",
      "Epoch 331/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0466 - acc: 0.9813 - val_loss: 0.1223 - val_acc: 0.9618\n",
      "Epoch 332/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0461 - acc: 0.9816 - val_loss: 0.1252 - val_acc: 0.9607\n",
      "Epoch 333/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0472 - acc: 0.9810 - val_loss: 0.1206 - val_acc: 0.9620\n",
      "Epoch 334/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0464 - acc: 0.9816 - val_loss: 0.1229 - val_acc: 0.9616\n",
      "Epoch 335/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0460 - acc: 0.9816 - val_loss: 0.1228 - val_acc: 0.9613\n",
      "Epoch 336/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0460 - acc: 0.9817 - val_loss: 0.1191 - val_acc: 0.9629\n",
      "Epoch 337/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0466 - acc: 0.9814 - val_loss: 0.1220 - val_acc: 0.9616\n",
      "Epoch 338/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0468 - acc: 0.9812 - val_loss: 0.1219 - val_acc: 0.9619\n",
      "Epoch 339/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0462 - acc: 0.9815 - val_loss: 0.1233 - val_acc: 0.9615\n",
      "Epoch 340/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0459 - acc: 0.9816 - val_loss: 0.1296 - val_acc: 0.9599\n",
      "Epoch 341/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0479 - acc: 0.9810 - val_loss: 0.1212 - val_acc: 0.9614\n",
      "Epoch 342/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0450 - acc: 0.9819 - val_loss: 0.1205 - val_acc: 0.9632\n",
      "Epoch 343/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0462 - acc: 0.9815 - val_loss: 0.1232 - val_acc: 0.9611\n",
      "Epoch 344/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0456 - acc: 0.9818 - val_loss: 0.1256 - val_acc: 0.9618\n",
      "Epoch 345/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0459 - acc: 0.9819 - val_loss: 0.1201 - val_acc: 0.9624\n",
      "Epoch 346/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0455 - acc: 0.9819 - val_loss: 0.1234 - val_acc: 0.9617\n",
      "Epoch 347/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0448 - acc: 0.9821 - val_loss: 0.1288 - val_acc: 0.9603\n",
      "Epoch 348/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0471 - acc: 0.9814 - val_loss: 0.1229 - val_acc: 0.9620\n",
      "Epoch 349/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0457 - acc: 0.9817 - val_loss: 0.1239 - val_acc: 0.9619\n",
      "Epoch 350/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0457 - acc: 0.9817 - val_loss: 0.1205 - val_acc: 0.9624\n",
      "Epoch 351/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0447 - acc: 0.9821 - val_loss: 0.1230 - val_acc: 0.9616\n",
      "Epoch 352/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0459 - acc: 0.9817 - val_loss: 0.1214 - val_acc: 0.9618\n",
      "Epoch 353/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0456 - acc: 0.9820 - val_loss: 0.1290 - val_acc: 0.9593\n",
      "Epoch 354/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0444 - acc: 0.9822 - val_loss: 0.1227 - val_acc: 0.9624\n",
      "Epoch 355/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0449 - acc: 0.9821 - val_loss: 0.1261 - val_acc: 0.9607\n",
      "Epoch 356/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0462 - acc: 0.9814 - val_loss: 0.1210 - val_acc: 0.9626\n",
      "Epoch 357/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0452 - acc: 0.9821 - val_loss: 0.1230 - val_acc: 0.9616\n",
      "Epoch 358/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0444 - acc: 0.9823 - val_loss: 0.1241 - val_acc: 0.9615\n",
      "Epoch 359/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0443 - acc: 0.9824 - val_loss: 0.1261 - val_acc: 0.9610\n",
      "Epoch 360/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0447 - acc: 0.9823 - val_loss: 0.1196 - val_acc: 0.9624\n",
      "Epoch 361/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0445 - acc: 0.9821 - val_loss: 0.1231 - val_acc: 0.9623\n",
      "Epoch 362/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0442 - acc: 0.9824 - val_loss: 0.1269 - val_acc: 0.9610\n",
      "Epoch 363/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0449 - acc: 0.9819 - val_loss: 0.1230 - val_acc: 0.9618\n",
      "Epoch 364/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0443 - acc: 0.9824 - val_loss: 0.1269 - val_acc: 0.9611\n",
      "Epoch 365/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0443 - acc: 0.9824 - val_loss: 0.1275 - val_acc: 0.9612\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95e4cacfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWZcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95e410de48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model several epochs, and test on the validation set. Plot the loss for train and validation sets\n",
    "t_init = time.time()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "t = time.time()\n",
    "history = model2.fit(train_data, train_labels, batch_size = 1000, epochs = 2500, \n",
    "                    validation_data=(valid_data,valid_labels), verbose = 1, callbacks=[early_stopping])\n",
    "\n",
    "epoch_time = time.time() - t\n",
    "\n",
    "total_time = time.time() - t_init\n",
    "\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history[\"val_acc\"])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Build the model - validation loss of 0.12 (hits 0.1199 at some point) after 250 epochs, but should probably \n",
    "# stop a good bit sooner by \n",
    "# the look of the plot. Maybe averaging a bunch of these together will give some improvement. Also, look into\n",
    "# parameter optimization.\n",
    "print('Build model...')\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(512, activation='relu', input_dim=54))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "# model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 370000 samples, validate on 100000 samples\n",
      "Epoch 1/2500\n",
      "370000/370000 [==============================] - 6s 17us/step - loss: 0.6234 - acc: 0.7676 - val_loss: 0.9168 - val_acc: 0.6551\n",
      "Epoch 2/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.4318 - acc: 0.8248 - val_loss: 0.4222 - val_acc: 0.8262\n",
      "Epoch 3/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.3696 - acc: 0.8525 - val_loss: 0.3802 - val_acc: 0.8476\n",
      "Epoch 4/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.3280 - acc: 0.8694 - val_loss: 0.3270 - val_acc: 0.8695\n",
      "Epoch 5/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2968 - acc: 0.8817 - val_loss: 0.2979 - val_acc: 0.8812\n",
      "Epoch 6/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2688 - acc: 0.8907 - val_loss: 0.2799 - val_acc: 0.8864\n",
      "Epoch 7/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2508 - acc: 0.8977 - val_loss: 0.2706 - val_acc: 0.8904\n",
      "Epoch 8/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2361 - acc: 0.9042 - val_loss: 0.2539 - val_acc: 0.8970\n",
      "Epoch 9/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2257 - acc: 0.9076 - val_loss: 0.2362 - val_acc: 0.9037\n",
      "Epoch 10/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.2148 - acc: 0.9126 - val_loss: 0.2244 - val_acc: 0.9087\n",
      "Epoch 11/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.2059 - acc: 0.9159 - val_loss: 0.2288 - val_acc: 0.9080\n",
      "Epoch 12/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1981 - acc: 0.9197 - val_loss: 0.2146 - val_acc: 0.9137\n",
      "Epoch 13/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1939 - acc: 0.9212 - val_loss: 0.2094 - val_acc: 0.9164\n",
      "Epoch 14/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1867 - acc: 0.9243 - val_loss: 0.1972 - val_acc: 0.9212\n",
      "Epoch 15/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1815 - acc: 0.9262 - val_loss: 0.1970 - val_acc: 0.9202\n",
      "Epoch 16/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1771 - acc: 0.9279 - val_loss: 0.1975 - val_acc: 0.9212\n",
      "Epoch 17/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1721 - acc: 0.9303 - val_loss: 0.1794 - val_acc: 0.9280\n",
      "Epoch 18/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1683 - acc: 0.9314 - val_loss: 0.1837 - val_acc: 0.9257\n",
      "Epoch 19/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1655 - acc: 0.9325 - val_loss: 0.1866 - val_acc: 0.9248\n",
      "Epoch 20/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1627 - acc: 0.9341 - val_loss: 0.1853 - val_acc: 0.9267\n",
      "Epoch 21/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1590 - acc: 0.9358 - val_loss: 0.1864 - val_acc: 0.9255\n",
      "Epoch 22/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1560 - acc: 0.9367 - val_loss: 0.1923 - val_acc: 0.9240\n",
      "Epoch 23/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1532 - acc: 0.9377 - val_loss: 0.1697 - val_acc: 0.9328\n",
      "Epoch 24/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1496 - acc: 0.9394 - val_loss: 0.1890 - val_acc: 0.9248\n",
      "Epoch 25/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1484 - acc: 0.9399 - val_loss: 0.1676 - val_acc: 0.9346\n",
      "Epoch 26/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1452 - acc: 0.9410 - val_loss: 0.1660 - val_acc: 0.9337\n",
      "Epoch 27/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1439 - acc: 0.9412 - val_loss: 0.1631 - val_acc: 0.9349\n",
      "Epoch 28/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1412 - acc: 0.9427 - val_loss: 0.1576 - val_acc: 0.9371\n",
      "Epoch 29/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1393 - acc: 0.9436 - val_loss: 0.1632 - val_acc: 0.9350\n",
      "Epoch 30/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1380 - acc: 0.9439 - val_loss: 0.1611 - val_acc: 0.9358\n",
      "Epoch 31/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1349 - acc: 0.9452 - val_loss: 0.1568 - val_acc: 0.9368\n",
      "Epoch 32/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1328 - acc: 0.9460 - val_loss: 0.1488 - val_acc: 0.9409\n",
      "Epoch 33/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1315 - acc: 0.9466 - val_loss: 0.1601 - val_acc: 0.9365\n",
      "Epoch 34/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1295 - acc: 0.9472 - val_loss: 0.1652 - val_acc: 0.9360\n",
      "Epoch 35/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1288 - acc: 0.9476 - val_loss: 0.1710 - val_acc: 0.9327\n",
      "Epoch 36/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1278 - acc: 0.9484 - val_loss: 0.1537 - val_acc: 0.9401\n",
      "Epoch 37/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1262 - acc: 0.9487 - val_loss: 0.1540 - val_acc: 0.9392\n",
      "Epoch 38/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1240 - acc: 0.9499 - val_loss: 0.1453 - val_acc: 0.9433\n",
      "Epoch 39/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1229 - acc: 0.9502 - val_loss: 0.1523 - val_acc: 0.9401\n",
      "Epoch 40/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1223 - acc: 0.9507 - val_loss: 0.1487 - val_acc: 0.9417\n",
      "Epoch 41/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1212 - acc: 0.9507 - val_loss: 0.1519 - val_acc: 0.9403\n",
      "Epoch 42/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1185 - acc: 0.9517 - val_loss: 0.1467 - val_acc: 0.9433\n",
      "Epoch 43/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1190 - acc: 0.9516 - val_loss: 0.1458 - val_acc: 0.9429\n",
      "Epoch 44/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1166 - acc: 0.9526 - val_loss: 0.1456 - val_acc: 0.9440\n",
      "Epoch 45/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1164 - acc: 0.9529 - val_loss: 0.1466 - val_acc: 0.9433\n",
      "Epoch 46/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1147 - acc: 0.9535 - val_loss: 0.1442 - val_acc: 0.9441\n",
      "Epoch 47/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1133 - acc: 0.9542 - val_loss: 0.1455 - val_acc: 0.9429\n",
      "Epoch 48/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1134 - acc: 0.9540 - val_loss: 0.1452 - val_acc: 0.9432\n",
      "Epoch 49/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1116 - acc: 0.9547 - val_loss: 0.1511 - val_acc: 0.9414\n",
      "Epoch 50/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1116 - acc: 0.9548 - val_loss: 0.1398 - val_acc: 0.9453\n",
      "Epoch 51/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1106 - acc: 0.9550 - val_loss: 0.1391 - val_acc: 0.9458\n",
      "Epoch 52/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1094 - acc: 0.9556 - val_loss: 0.1579 - val_acc: 0.9386\n",
      "Epoch 53/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1090 - acc: 0.9557 - val_loss: 0.1481 - val_acc: 0.9422\n",
      "Epoch 54/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1077 - acc: 0.9561 - val_loss: 0.1440 - val_acc: 0.9442\n",
      "Epoch 55/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1074 - acc: 0.9565 - val_loss: 0.1433 - val_acc: 0.9455\n",
      "Epoch 56/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1060 - acc: 0.9574 - val_loss: 0.1369 - val_acc: 0.9471\n",
      "Epoch 57/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1045 - acc: 0.9575 - val_loss: 0.1373 - val_acc: 0.9470\n",
      "Epoch 58/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1042 - acc: 0.9577 - val_loss: 0.1339 - val_acc: 0.9488\n",
      "Epoch 59/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1034 - acc: 0.9582 - val_loss: 0.1442 - val_acc: 0.9440\n",
      "Epoch 60/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1025 - acc: 0.9584 - val_loss: 0.1372 - val_acc: 0.9474\n",
      "Epoch 61/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1025 - acc: 0.9582 - val_loss: 0.1363 - val_acc: 0.9470\n",
      "Epoch 62/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.1019 - acc: 0.9587 - val_loss: 0.1309 - val_acc: 0.9497\n",
      "Epoch 63/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.1001 - acc: 0.9595 - val_loss: 0.1341 - val_acc: 0.9487\n",
      "Epoch 64/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0998 - acc: 0.9595 - val_loss: 0.1269 - val_acc: 0.9508\n",
      "Epoch 65/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0999 - acc: 0.9591 - val_loss: 0.1313 - val_acc: 0.9501\n",
      "Epoch 66/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0987 - acc: 0.9600 - val_loss: 0.1402 - val_acc: 0.9466\n",
      "Epoch 67/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0981 - acc: 0.9602 - val_loss: 0.1414 - val_acc: 0.9464\n",
      "Epoch 68/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0972 - acc: 0.9606 - val_loss: 0.1404 - val_acc: 0.9467\n",
      "Epoch 69/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0978 - acc: 0.9602 - val_loss: 0.1311 - val_acc: 0.9508\n",
      "Epoch 70/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0951 - acc: 0.9618 - val_loss: 0.1342 - val_acc: 0.9491\n",
      "Epoch 71/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0952 - acc: 0.9613 - val_loss: 0.1435 - val_acc: 0.9452\n",
      "Epoch 72/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0951 - acc: 0.9618 - val_loss: 0.1349 - val_acc: 0.9484\n",
      "Epoch 73/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0944 - acc: 0.9615 - val_loss: 0.1306 - val_acc: 0.9499\n",
      "Epoch 74/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0937 - acc: 0.9619 - val_loss: 0.1287 - val_acc: 0.9506\n",
      "Epoch 75/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0933 - acc: 0.9621 - val_loss: 0.1305 - val_acc: 0.9497\n",
      "Epoch 76/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0928 - acc: 0.9625 - val_loss: 0.1288 - val_acc: 0.9507\n",
      "Epoch 77/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0929 - acc: 0.9624 - val_loss: 0.1363 - val_acc: 0.9485\n",
      "Epoch 78/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0926 - acc: 0.9624 - val_loss: 0.1287 - val_acc: 0.9518\n",
      "Epoch 79/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0913 - acc: 0.9628 - val_loss: 0.1397 - val_acc: 0.9471\n",
      "Epoch 80/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0895 - acc: 0.9637 - val_loss: 0.1308 - val_acc: 0.9508\n",
      "Epoch 81/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0898 - acc: 0.9637 - val_loss: 0.1268 - val_acc: 0.9527\n",
      "Epoch 82/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0897 - acc: 0.9638 - val_loss: 0.1364 - val_acc: 0.9493\n",
      "Epoch 83/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0891 - acc: 0.9639 - val_loss: 0.1241 - val_acc: 0.9538\n",
      "Epoch 84/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0893 - acc: 0.9636 - val_loss: 0.1382 - val_acc: 0.9481\n",
      "Epoch 85/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0887 - acc: 0.9639 - val_loss: 0.1334 - val_acc: 0.9491\n",
      "Epoch 86/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0876 - acc: 0.9643 - val_loss: 0.1246 - val_acc: 0.9531\n",
      "Epoch 87/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0878 - acc: 0.9642 - val_loss: 0.1290 - val_acc: 0.9509\n",
      "Epoch 88/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0872 - acc: 0.9650 - val_loss: 0.1238 - val_acc: 0.9535\n",
      "Epoch 89/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0868 - acc: 0.9647 - val_loss: 0.1273 - val_acc: 0.9517\n",
      "Epoch 90/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0864 - acc: 0.9647 - val_loss: 0.1261 - val_acc: 0.9537\n",
      "Epoch 91/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0849 - acc: 0.9653 - val_loss: 0.1330 - val_acc: 0.9507\n",
      "Epoch 92/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0856 - acc: 0.9654 - val_loss: 0.1244 - val_acc: 0.9534\n",
      "Epoch 93/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0845 - acc: 0.9656 - val_loss: 0.1237 - val_acc: 0.9536\n",
      "Epoch 94/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0845 - acc: 0.9655 - val_loss: 0.1315 - val_acc: 0.9508\n",
      "Epoch 95/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0852 - acc: 0.9652 - val_loss: 0.1276 - val_acc: 0.9527\n",
      "Epoch 96/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0836 - acc: 0.9661 - val_loss: 0.1211 - val_acc: 0.9551\n",
      "Epoch 97/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0842 - acc: 0.9659 - val_loss: 0.1437 - val_acc: 0.9468\n",
      "Epoch 98/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0824 - acc: 0.9665 - val_loss: 0.1277 - val_acc: 0.9531\n",
      "Epoch 99/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0833 - acc: 0.9662 - val_loss: 0.1290 - val_acc: 0.9523\n",
      "Epoch 100/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0816 - acc: 0.9669 - val_loss: 0.1301 - val_acc: 0.9520\n",
      "Epoch 101/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0815 - acc: 0.9669 - val_loss: 0.1306 - val_acc: 0.9518\n",
      "Epoch 102/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0821 - acc: 0.9665 - val_loss: 0.1274 - val_acc: 0.9538\n",
      "Epoch 103/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0813 - acc: 0.9671 - val_loss: 0.1225 - val_acc: 0.9546\n",
      "Epoch 104/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0817 - acc: 0.9668 - val_loss: 0.1254 - val_acc: 0.9542\n",
      "Epoch 105/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0801 - acc: 0.9674 - val_loss: 0.1252 - val_acc: 0.9543\n",
      "Epoch 106/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0800 - acc: 0.9674 - val_loss: 0.1224 - val_acc: 0.9556\n",
      "Epoch 107/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0803 - acc: 0.9673 - val_loss: 0.1258 - val_acc: 0.9539\n",
      "Epoch 108/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0796 - acc: 0.9677 - val_loss: 0.1242 - val_acc: 0.9543\n",
      "Epoch 109/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0782 - acc: 0.9682 - val_loss: 0.1261 - val_acc: 0.9540\n",
      "Epoch 110/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0791 - acc: 0.9679 - val_loss: 0.1207 - val_acc: 0.9560\n",
      "Epoch 111/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0779 - acc: 0.9685 - val_loss: 0.1249 - val_acc: 0.9550\n",
      "Epoch 112/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0787 - acc: 0.9682 - val_loss: 0.1284 - val_acc: 0.9530\n",
      "Epoch 113/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0769 - acc: 0.9684 - val_loss: 0.1181 - val_acc: 0.9565\n",
      "Epoch 114/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0780 - acc: 0.9683 - val_loss: 0.1277 - val_acc: 0.9541\n",
      "Epoch 115/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0777 - acc: 0.9685 - val_loss: 0.1340 - val_acc: 0.9505\n",
      "Epoch 116/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0769 - acc: 0.9686 - val_loss: 0.1284 - val_acc: 0.9528\n",
      "Epoch 117/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0756 - acc: 0.9695 - val_loss: 0.1238 - val_acc: 0.9553\n",
      "Epoch 118/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0760 - acc: 0.9691 - val_loss: 0.1334 - val_acc: 0.9516\n",
      "Epoch 119/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0760 - acc: 0.9692 - val_loss: 0.1257 - val_acc: 0.9545\n",
      "Epoch 120/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0748 - acc: 0.9697 - val_loss: 0.1244 - val_acc: 0.9549\n",
      "Epoch 121/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0745 - acc: 0.9701 - val_loss: 0.1241 - val_acc: 0.9545\n",
      "Epoch 122/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0752 - acc: 0.9693 - val_loss: 0.1245 - val_acc: 0.9553\n",
      "Epoch 123/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0738 - acc: 0.9703 - val_loss: 0.1216 - val_acc: 0.9558\n",
      "Epoch 124/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0753 - acc: 0.9692 - val_loss: 0.1238 - val_acc: 0.9552\n",
      "Epoch 125/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0735 - acc: 0.9701 - val_loss: 0.1202 - val_acc: 0.9568\n",
      "Epoch 126/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0745 - acc: 0.9695 - val_loss: 0.1221 - val_acc: 0.9563\n",
      "Epoch 127/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0749 - acc: 0.9697 - val_loss: 0.1212 - val_acc: 0.9559\n",
      "Epoch 128/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0732 - acc: 0.9706 - val_loss: 0.1294 - val_acc: 0.9537\n",
      "Epoch 129/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0731 - acc: 0.9704 - val_loss: 0.1371 - val_acc: 0.9515\n",
      "Epoch 130/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0731 - acc: 0.9702 - val_loss: 0.1214 - val_acc: 0.9576\n",
      "Epoch 131/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0723 - acc: 0.9709 - val_loss: 0.1301 - val_acc: 0.9533\n",
      "Epoch 132/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0735 - acc: 0.9705 - val_loss: 0.1201 - val_acc: 0.9573\n",
      "Epoch 133/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0727 - acc: 0.9705 - val_loss: 0.1264 - val_acc: 0.9542\n",
      "Epoch 134/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0723 - acc: 0.9705 - val_loss: 0.1222 - val_acc: 0.9562\n",
      "Epoch 135/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0721 - acc: 0.9709 - val_loss: 0.1200 - val_acc: 0.9573\n",
      "Epoch 136/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0718 - acc: 0.9709 - val_loss: 0.1306 - val_acc: 0.9528\n",
      "Epoch 137/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0704 - acc: 0.9713 - val_loss: 0.1193 - val_acc: 0.9581\n",
      "Epoch 138/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0718 - acc: 0.9709 - val_loss: 0.1243 - val_acc: 0.9555\n",
      "Epoch 139/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0705 - acc: 0.9714 - val_loss: 0.1242 - val_acc: 0.9555\n",
      "Epoch 140/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0701 - acc: 0.9719 - val_loss: 0.1221 - val_acc: 0.9567\n",
      "Epoch 141/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0703 - acc: 0.9716 - val_loss: 0.1247 - val_acc: 0.9565\n",
      "Epoch 142/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0703 - acc: 0.9715 - val_loss: 0.1217 - val_acc: 0.9565\n",
      "Epoch 143/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0702 - acc: 0.9715 - val_loss: 0.1296 - val_acc: 0.9542\n",
      "Epoch 144/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0690 - acc: 0.9719 - val_loss: 0.1313 - val_acc: 0.9530\n",
      "Epoch 145/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0690 - acc: 0.9720 - val_loss: 0.1157 - val_acc: 0.9587\n",
      "Epoch 146/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0690 - acc: 0.9720 - val_loss: 0.1205 - val_acc: 0.9570\n",
      "Epoch 147/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0686 - acc: 0.9720 - val_loss: 0.1214 - val_acc: 0.9566\n",
      "Epoch 148/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0686 - acc: 0.9723 - val_loss: 0.1235 - val_acc: 0.9565\n",
      "Epoch 149/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0679 - acc: 0.9727 - val_loss: 0.1236 - val_acc: 0.9556\n",
      "Epoch 150/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0680 - acc: 0.9726 - val_loss: 0.1263 - val_acc: 0.9554\n",
      "Epoch 151/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0675 - acc: 0.9728 - val_loss: 0.1179 - val_acc: 0.9584\n",
      "Epoch 152/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0686 - acc: 0.9725 - val_loss: 0.1201 - val_acc: 0.9575\n",
      "Epoch 153/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0684 - acc: 0.9722 - val_loss: 0.1185 - val_acc: 0.9580\n",
      "Epoch 154/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0667 - acc: 0.9729 - val_loss: 0.1234 - val_acc: 0.9564\n",
      "Epoch 155/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0672 - acc: 0.9727 - val_loss: 0.1186 - val_acc: 0.9583\n",
      "Epoch 156/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0667 - acc: 0.9733 - val_loss: 0.1189 - val_acc: 0.9583\n",
      "Epoch 157/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0667 - acc: 0.9730 - val_loss: 0.1207 - val_acc: 0.9575\n",
      "Epoch 158/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0663 - acc: 0.9732 - val_loss: 0.1260 - val_acc: 0.9553\n",
      "Epoch 159/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0659 - acc: 0.9733 - val_loss: 0.1304 - val_acc: 0.9552\n",
      "Epoch 160/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0658 - acc: 0.9733 - val_loss: 0.1199 - val_acc: 0.9581\n",
      "Epoch 161/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0660 - acc: 0.9733 - val_loss: 0.1187 - val_acc: 0.9582\n",
      "Epoch 162/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0659 - acc: 0.9735 - val_loss: 0.1238 - val_acc: 0.9569\n",
      "Epoch 163/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0657 - acc: 0.9733 - val_loss: 0.1191 - val_acc: 0.9582\n",
      "Epoch 164/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0659 - acc: 0.9734 - val_loss: 0.1212 - val_acc: 0.9569\n",
      "Epoch 165/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0654 - acc: 0.9737 - val_loss: 0.1240 - val_acc: 0.9571\n",
      "Epoch 166/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0645 - acc: 0.9739 - val_loss: 0.1251 - val_acc: 0.9571\n",
      "Epoch 167/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0642 - acc: 0.9738 - val_loss: 0.1203 - val_acc: 0.9581\n",
      "Epoch 168/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0647 - acc: 0.9738 - val_loss: 0.1175 - val_acc: 0.9585\n",
      "Epoch 169/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0642 - acc: 0.9741 - val_loss: 0.1226 - val_acc: 0.9575\n",
      "Epoch 170/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0642 - acc: 0.9741 - val_loss: 0.1261 - val_acc: 0.9563\n",
      "Epoch 171/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0639 - acc: 0.9742 - val_loss: 0.1217 - val_acc: 0.9583\n",
      "Epoch 172/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0647 - acc: 0.9735 - val_loss: 0.1238 - val_acc: 0.9579\n",
      "Epoch 173/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0628 - acc: 0.9747 - val_loss: 0.1208 - val_acc: 0.9576\n",
      "Epoch 174/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0636 - acc: 0.9742 - val_loss: 0.1209 - val_acc: 0.9581\n",
      "Epoch 175/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0645 - acc: 0.9739 - val_loss: 0.1236 - val_acc: 0.9578\n",
      "Epoch 176/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0623 - acc: 0.9750 - val_loss: 0.1147 - val_acc: 0.9606\n",
      "Epoch 177/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0625 - acc: 0.9748 - val_loss: 0.1163 - val_acc: 0.9599\n",
      "Epoch 178/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0627 - acc: 0.9745 - val_loss: 0.1269 - val_acc: 0.9563\n",
      "Epoch 179/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0633 - acc: 0.9743 - val_loss: 0.1221 - val_acc: 0.9568\n",
      "Epoch 180/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0622 - acc: 0.9747 - val_loss: 0.1198 - val_acc: 0.9589\n",
      "Epoch 181/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0631 - acc: 0.9747 - val_loss: 0.1159 - val_acc: 0.9600\n",
      "Epoch 182/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0614 - acc: 0.9749 - val_loss: 0.1204 - val_acc: 0.9588\n",
      "Epoch 183/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0626 - acc: 0.9747 - val_loss: 0.1144 - val_acc: 0.9606\n",
      "Epoch 184/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0621 - acc: 0.9751 - val_loss: 0.1206 - val_acc: 0.9586\n",
      "Epoch 185/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0614 - acc: 0.9753 - val_loss: 0.1244 - val_acc: 0.9569\n",
      "Epoch 186/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0614 - acc: 0.9750 - val_loss: 0.1227 - val_acc: 0.9581\n",
      "Epoch 187/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0616 - acc: 0.9752 - val_loss: 0.1214 - val_acc: 0.9583\n",
      "Epoch 188/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0607 - acc: 0.9756 - val_loss: 0.1201 - val_acc: 0.9592\n",
      "Epoch 189/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0608 - acc: 0.9756 - val_loss: 0.1154 - val_acc: 0.9604\n",
      "Epoch 190/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0609 - acc: 0.9754 - val_loss: 0.1207 - val_acc: 0.9581\n",
      "Epoch 191/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0617 - acc: 0.9752 - val_loss: 0.1216 - val_acc: 0.9579\n",
      "Epoch 192/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0611 - acc: 0.9753 - val_loss: 0.1194 - val_acc: 0.9590\n",
      "Epoch 193/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0607 - acc: 0.9755 - val_loss: 0.1246 - val_acc: 0.9571\n",
      "Epoch 194/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0612 - acc: 0.9753 - val_loss: 0.1221 - val_acc: 0.9582\n",
      "Epoch 195/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0604 - acc: 0.9756 - val_loss: 0.1193 - val_acc: 0.9585\n",
      "Epoch 196/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0603 - acc: 0.9758 - val_loss: 0.1228 - val_acc: 0.9581\n",
      "Epoch 197/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0605 - acc: 0.9757 - val_loss: 0.1262 - val_acc: 0.9572\n",
      "Epoch 198/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0604 - acc: 0.9756 - val_loss: 0.1233 - val_acc: 0.9581\n",
      "Epoch 199/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0588 - acc: 0.9765 - val_loss: 0.1202 - val_acc: 0.9588\n",
      "Epoch 200/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0602 - acc: 0.9757 - val_loss: 0.1201 - val_acc: 0.9588\n",
      "Epoch 201/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0591 - acc: 0.9763 - val_loss: 0.1191 - val_acc: 0.9593\n",
      "Epoch 202/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0587 - acc: 0.9764 - val_loss: 0.1168 - val_acc: 0.9605\n",
      "Epoch 203/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0598 - acc: 0.9758 - val_loss: 0.1252 - val_acc: 0.9578\n",
      "Epoch 204/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0587 - acc: 0.9766 - val_loss: 0.1209 - val_acc: 0.9595\n",
      "Epoch 205/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0588 - acc: 0.9763 - val_loss: 0.1160 - val_acc: 0.9606\n",
      "Epoch 206/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0588 - acc: 0.9764 - val_loss: 0.1176 - val_acc: 0.9598\n",
      "Epoch 207/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0587 - acc: 0.9764 - val_loss: 0.1248 - val_acc: 0.9583\n",
      "Epoch 208/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0590 - acc: 0.9763 - val_loss: 0.1188 - val_acc: 0.9602\n",
      "Epoch 209/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0587 - acc: 0.9762 - val_loss: 0.1282 - val_acc: 0.9566\n",
      "Epoch 210/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0582 - acc: 0.9769 - val_loss: 0.1240 - val_acc: 0.9586\n",
      "Epoch 211/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0581 - acc: 0.9767 - val_loss: 0.1216 - val_acc: 0.9584\n",
      "Epoch 212/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0575 - acc: 0.9767 - val_loss: 0.1245 - val_acc: 0.9577\n",
      "Epoch 213/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0575 - acc: 0.9766 - val_loss: 0.1197 - val_acc: 0.9601\n",
      "Epoch 214/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0577 - acc: 0.9767 - val_loss: 0.1231 - val_acc: 0.9584\n",
      "Epoch 215/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0581 - acc: 0.9767 - val_loss: 0.1207 - val_acc: 0.9591\n",
      "Epoch 216/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0573 - acc: 0.9771 - val_loss: 0.1229 - val_acc: 0.9586\n",
      "Epoch 217/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0570 - acc: 0.9771 - val_loss: 0.1229 - val_acc: 0.9592\n",
      "Epoch 218/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0568 - acc: 0.9770 - val_loss: 0.1180 - val_acc: 0.9599\n",
      "Epoch 219/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0563 - acc: 0.9772 - val_loss: 0.1195 - val_acc: 0.9592\n",
      "Epoch 220/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0568 - acc: 0.9772 - val_loss: 0.1162 - val_acc: 0.9604\n",
      "Epoch 221/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0567 - acc: 0.9770 - val_loss: 0.1201 - val_acc: 0.9598\n",
      "Epoch 222/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0572 - acc: 0.9769 - val_loss: 0.1180 - val_acc: 0.9605\n",
      "Epoch 223/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0565 - acc: 0.9775 - val_loss: 0.1174 - val_acc: 0.9609\n",
      "Epoch 224/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0556 - acc: 0.9774 - val_loss: 0.1181 - val_acc: 0.9600\n",
      "Epoch 225/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0557 - acc: 0.9776 - val_loss: 0.1249 - val_acc: 0.9583\n",
      "Epoch 226/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0562 - acc: 0.9773 - val_loss: 0.1229 - val_acc: 0.9594\n",
      "Epoch 227/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0569 - acc: 0.9773 - val_loss: 0.1198 - val_acc: 0.9596\n",
      "Epoch 228/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0550 - acc: 0.9778 - val_loss: 0.1234 - val_acc: 0.9582\n",
      "Epoch 229/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0556 - acc: 0.9776 - val_loss: 0.1162 - val_acc: 0.9615\n",
      "Epoch 230/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0554 - acc: 0.9776 - val_loss: 0.1234 - val_acc: 0.9592\n",
      "Epoch 231/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0559 - acc: 0.9777 - val_loss: 0.1199 - val_acc: 0.9610\n",
      "Epoch 232/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0551 - acc: 0.9781 - val_loss: 0.1159 - val_acc: 0.9613\n",
      "Epoch 233/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0554 - acc: 0.9776 - val_loss: 0.1210 - val_acc: 0.9599\n",
      "Epoch 234/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0548 - acc: 0.9780 - val_loss: 0.1248 - val_acc: 0.9583\n",
      "Epoch 235/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0557 - acc: 0.9777 - val_loss: 0.1192 - val_acc: 0.9602\n",
      "Epoch 236/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0540 - acc: 0.9784 - val_loss: 0.1196 - val_acc: 0.9603\n",
      "Epoch 237/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0549 - acc: 0.9781 - val_loss: 0.1268 - val_acc: 0.9576\n",
      "Epoch 238/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0559 - acc: 0.9776 - val_loss: 0.1203 - val_acc: 0.9604\n",
      "Epoch 239/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0541 - acc: 0.9782 - val_loss: 0.1225 - val_acc: 0.9593\n",
      "Epoch 240/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0534 - acc: 0.9787 - val_loss: 0.1201 - val_acc: 0.9599\n",
      "Epoch 241/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0538 - acc: 0.9781 - val_loss: 0.1187 - val_acc: 0.9609\n",
      "Epoch 242/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0544 - acc: 0.9783 - val_loss: 0.1228 - val_acc: 0.9594\n",
      "Epoch 243/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0549 - acc: 0.9777 - val_loss: 0.1211 - val_acc: 0.9593\n",
      "Epoch 244/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0536 - acc: 0.9783 - val_loss: 0.1187 - val_acc: 0.9608\n",
      "Epoch 245/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0541 - acc: 0.9780 - val_loss: 0.1247 - val_acc: 0.9586\n",
      "Epoch 246/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0533 - acc: 0.9786 - val_loss: 0.1213 - val_acc: 0.9597\n",
      "Epoch 247/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0539 - acc: 0.9783 - val_loss: 0.1228 - val_acc: 0.9597\n",
      "Epoch 248/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0528 - acc: 0.9787 - val_loss: 0.1223 - val_acc: 0.9598\n",
      "Epoch 249/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0527 - acc: 0.9787 - val_loss: 0.1246 - val_acc: 0.9592\n",
      "Epoch 250/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0537 - acc: 0.9782 - val_loss: 0.1270 - val_acc: 0.9590\n",
      "Epoch 251/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0525 - acc: 0.9790 - val_loss: 0.1194 - val_acc: 0.9605\n",
      "Epoch 252/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0528 - acc: 0.9787 - val_loss: 0.1267 - val_acc: 0.9588\n",
      "Epoch 253/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0538 - acc: 0.9785 - val_loss: 0.1220 - val_acc: 0.9607\n",
      "Epoch 254/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0525 - acc: 0.9790 - val_loss: 0.1224 - val_acc: 0.9599\n",
      "Epoch 255/2500\n",
      "370000/370000 [==============================] - 5s 15us/step - loss: 0.0532 - acc: 0.9788 - val_loss: 0.1240 - val_acc: 0.9597\n",
      "Epoch 256/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0516 - acc: 0.9795 - val_loss: 0.1219 - val_acc: 0.9594\n",
      "Epoch 257/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0529 - acc: 0.9787 - val_loss: 0.1254 - val_acc: 0.9596\n",
      "Epoch 258/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0525 - acc: 0.9789 - val_loss: 0.1205 - val_acc: 0.9604\n",
      "Epoch 259/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0524 - acc: 0.9791 - val_loss: 0.1220 - val_acc: 0.9604\n",
      "Epoch 260/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0525 - acc: 0.9790 - val_loss: 0.1220 - val_acc: 0.9596\n",
      "Epoch 261/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0522 - acc: 0.9791 - val_loss: 0.1277 - val_acc: 0.9591\n",
      "Epoch 262/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0523 - acc: 0.9789 - val_loss: 0.1227 - val_acc: 0.9601\n",
      "Epoch 263/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0524 - acc: 0.9791 - val_loss: 0.1259 - val_acc: 0.9598\n",
      "Epoch 264/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0520 - acc: 0.9790 - val_loss: 0.1259 - val_acc: 0.9587\n",
      "Epoch 265/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0510 - acc: 0.9796 - val_loss: 0.1267 - val_acc: 0.9584\n",
      "Epoch 266/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0517 - acc: 0.9791 - val_loss: 0.1264 - val_acc: 0.9597\n",
      "Epoch 267/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0509 - acc: 0.9797 - val_loss: 0.1208 - val_acc: 0.9601\n",
      "Epoch 268/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0526 - acc: 0.9792 - val_loss: 0.1178 - val_acc: 0.9619\n",
      "Epoch 269/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0513 - acc: 0.9793 - val_loss: 0.1258 - val_acc: 0.9596\n",
      "Epoch 270/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0524 - acc: 0.9794 - val_loss: 0.1209 - val_acc: 0.9599\n",
      "Epoch 271/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0508 - acc: 0.9798 - val_loss: 0.1293 - val_acc: 0.9583\n",
      "Epoch 272/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0520 - acc: 0.9792 - val_loss: 0.1189 - val_acc: 0.9618\n",
      "Epoch 273/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0519 - acc: 0.9793 - val_loss: 0.1231 - val_acc: 0.9595\n",
      "Epoch 274/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0524 - acc: 0.9790 - val_loss: 0.1175 - val_acc: 0.9618\n",
      "Epoch 275/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0515 - acc: 0.9797 - val_loss: 0.1188 - val_acc: 0.9626\n",
      "Epoch 276/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0509 - acc: 0.9797 - val_loss: 0.1243 - val_acc: 0.9596\n",
      "Epoch 277/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0506 - acc: 0.9795 - val_loss: 0.1211 - val_acc: 0.9611\n",
      "Epoch 278/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0508 - acc: 0.9795 - val_loss: 0.1260 - val_acc: 0.9603\n",
      "Epoch 279/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0507 - acc: 0.9794 - val_loss: 0.1188 - val_acc: 0.9617\n",
      "Epoch 280/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0498 - acc: 0.9803 - val_loss: 0.1222 - val_acc: 0.9610\n",
      "Epoch 281/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0501 - acc: 0.9798 - val_loss: 0.1210 - val_acc: 0.9602\n",
      "Epoch 282/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0500 - acc: 0.9798 - val_loss: 0.1195 - val_acc: 0.9610\n",
      "Epoch 283/2500\n",
      "370000/370000 [==============================] - 5s 14us/step - loss: 0.0497 - acc: 0.9801 - val_loss: 0.1261 - val_acc: 0.9592\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0kmhICIinRQKIiLS6f8BIuiHmEl9eu0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95e41c37f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95db1a57f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model several epochs, and test on the validation set. Plot the loss for train and validation sets\n",
    "t_init = time.time()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "t = time.time()\n",
    "history = model3.fit(train_data, train_labels, batch_size = 1000, epochs = 2500, \n",
    "                    validation_data=(valid_data,valid_labels), verbose = 1, callbacks=[early_stopping])\n",
    "\n",
    "epoch_time = time.time() - t\n",
    "\n",
    "total_time = time.time() - t_init\n",
    "\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history[\"val_acc\"])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,2],[3,4]])\n",
    "b=np.array([[1,2],[3,3]])\n",
    "np.sum(np.all(a==b,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000/370000 [==============================] - 0s 1us/step\n",
      "370000/370000 [==============================] - 1s 2us/step\n",
      "370000/370000 [==============================] - 1s 2us/step\n",
      "370000/370000 [==============================] - 1s 2us/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(train_data, batch_size = 10000, verbose=1)\n",
    "preds1 = model1.predict(train_data, batch_size = 10000, verbose=1)\n",
    "preds2 = model2.predict(train_data, batch_size = 10000, verbose=1)\n",
    "preds3 = model3.predict(train_data, batch_size = 10000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99148378378378377"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds = (preds + preds1 + preds2 + preds2)/4.0\n",
    "np.sum(np.all(to_categorical(np.argmax(avg_preds,axis=1),7)==train_labels,axis=1))/avg_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(valid_data, batch_size = 10000, verbose=1)\n",
    "preds1 = model1.predict(valid_data, batch_size = 10000, verbose=1)\n",
    "preds2 = model2.predict(valid_data, batch_size = 10000, verbose=1)\n",
    "preds3 = model3.predict(valid_data, batch_size = 10000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96736999999999995"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds = (preds + preds1 + preds2 + preds2)/4.0\n",
    "np.sum(np.all(to_categorical(np.argmax(avg_preds,axis=1),7)==valid_labels,axis=1))/avg_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 created. Current run time = 10.8 minutes.\n",
      "Model 1 created. Current run time = 24.5 minutes.\n",
      "Model 2 created. Current run time = 39.4 minutes.\n",
      "Model 3 created. Current run time = 53.4 minutes.\n",
      "Model 4 created. Current run time = 61.5 minutes.\n",
      "Model 5 created. Current run time = 75.0 minutes.\n",
      "Model 6 created. Current run time = 87.5 minutes.\n",
      "Model 7 created. Current run time = 105.0 minutes.\n",
      "Model 8 created. Current run time = 119.9 minutes.\n",
      "Model 9 created. Current run time = 136.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "models_list = []\n",
    "t_init = time.time()\n",
    "for i in np.arange(10):\n",
    "    modl = Sequential()\n",
    "    modl.add(Dense(512, activation='relu', input_dim=54))\n",
    "    modl.add(BatchNormalization())\n",
    "    modl.add(Dense(256, activation='relu'))\n",
    "    modl.add(BatchNormalization())\n",
    "    modl.add(Dense(128, activation='relu'))\n",
    "    modl.add(BatchNormalization())\n",
    "    modl.add(Dense(64, activation='relu'))\n",
    "    modl.add(BatchNormalization())\n",
    "    modl.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    # model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    modl.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                 kernel_initializer = keras.initializers.lecun_normal(seed = 451761), metrics=[\"accuracy\"])\n",
    "\n",
    "    # train the model several epochs, and test on the validation set. Plot the loss for train and validation sets\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)\n",
    "\n",
    "    history = modl.fit(train_data, train_labels, batch_size = 1000, epochs = 2500, \n",
    "                    validation_data=(valid_data,valid_labels), verbose = 0, callbacks=[early_stopping])\n",
    "\n",
    "    models_list.append(modl)\n",
    "    print('Model {} created. Current run time = {:0.1f} minutes.'.format(i, (time.time()-t_init)/60))\n",
    "    del modl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for i in np.arange(10):\n",
    "    pred_list.append(models_list[i].predict(valid_data, batch_size = 10000, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96872999999999998"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds = pred_list[0]\n",
    "for i in np.arange(1,10):\n",
    "    avg_preds = avg_preds + pred_list[i]\n",
    "avg_preds = avg_preds/14\n",
    "np.sum(np.all(to_categorical(np.argmax(avg_preds,axis=1),7)==valid_labels,axis=1))/avg_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n",
      "111012/111012 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for i in np.arange(10):\n",
    "    pred_list.append(models_list[i].predict(test_data, batch_size = 10000, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96688646272475043"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds = pred_list[0]\n",
    "for i in np.arange(1,10):\n",
    "    avg_preds = avg_preds + pred_list[i]\n",
    "avg_preds = avg_preds/10\n",
    "np.sum(np.all(to_categorical(np.argmax(avg_preds,axis=1),7)==test_labels,axis=1))/avg_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-17c840b99ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodels_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/ground_cover_classifier_natural_deep_{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;31m# If file exists and should not be overwritten:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "for i in np.arange(10):\n",
    "    models_list[i].save_weights('models/ground_cover_classifier_natural_deep_{}.h5'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
